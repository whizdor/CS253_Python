{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_style('darkgrid')\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Candidate</th>\n",
       "      <th>Constituency ∇</th>\n",
       "      <th>Party</th>\n",
       "      <th>Criminal Case</th>\n",
       "      <th>Total Assets</th>\n",
       "      <th>Liabilities</th>\n",
       "      <th>state</th>\n",
       "      <th>Education</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>M.K. Mohan</td>\n",
       "      <td>ANNA NAGAR</td>\n",
       "      <td>DMK</td>\n",
       "      <td>4</td>\n",
       "      <td>211 Crore+</td>\n",
       "      <td>2 Crore+</td>\n",
       "      <td>TAMIL NADU</td>\n",
       "      <td>8th Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Khatik Ramesh Prasad</td>\n",
       "      <td>KARERA (SC)</td>\n",
       "      <td>BJP</td>\n",
       "      <td>0</td>\n",
       "      <td>1 Crore+</td>\n",
       "      <td>0</td>\n",
       "      <td>MADHYA PRADESH</td>\n",
       "      <td>12th Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Dr. Mantar Gowda</td>\n",
       "      <td>MADIKERI</td>\n",
       "      <td>INC</td>\n",
       "      <td>0</td>\n",
       "      <td>7 Crore+</td>\n",
       "      <td>22 Lac+</td>\n",
       "      <td>KARNATAKA</td>\n",
       "      <td>Post Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Kundan Kumar</td>\n",
       "      <td>BEGUSARAI</td>\n",
       "      <td>BJP</td>\n",
       "      <td>0</td>\n",
       "      <td>9 Crore+</td>\n",
       "      <td>24 Lac+</td>\n",
       "      <td>BIHAR</td>\n",
       "      <td>Post Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Swapan Majumder</td>\n",
       "      <td>BANGAON DAKSHIN (SC)</td>\n",
       "      <td>BJP</td>\n",
       "      <td>2</td>\n",
       "      <td>2 Crore+</td>\n",
       "      <td>61 Lac+</td>\n",
       "      <td>WEST BENGAL</td>\n",
       "      <td>8th Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Arup Roy</td>\n",
       "      <td>HOWRAH MADHYA</td>\n",
       "      <td>AITC</td>\n",
       "      <td>0</td>\n",
       "      <td>3 Crore+</td>\n",
       "      <td>29 Lac+</td>\n",
       "      <td>WEST BENGAL</td>\n",
       "      <td>Graduate Professional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Baby Rani Maurya</td>\n",
       "      <td>AGRA RURAL (SC)</td>\n",
       "      <td>BJP</td>\n",
       "      <td>0</td>\n",
       "      <td>2 Crore+</td>\n",
       "      <td>0</td>\n",
       "      <td>UTTAR PRADESH</td>\n",
       "      <td>Post Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Neena Mittal</td>\n",
       "      <td>RAJPURA</td>\n",
       "      <td>AAP</td>\n",
       "      <td>1</td>\n",
       "      <td>9 Crore+</td>\n",
       "      <td>2 Crore+</td>\n",
       "      <td>PUNJAB</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Fareed Mahfooz Kidwai</td>\n",
       "      <td>RAM NAGAR</td>\n",
       "      <td>SP</td>\n",
       "      <td>1</td>\n",
       "      <td>5 Crore+</td>\n",
       "      <td>35 Lac+</td>\n",
       "      <td>UTTAR PRADESH</td>\n",
       "      <td>Post Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Atul Moreshwar Save</td>\n",
       "      <td>AURANGBAD (EAST)</td>\n",
       "      <td>BJP</td>\n",
       "      <td>6</td>\n",
       "      <td>22 Crore+</td>\n",
       "      <td>2 Crore+</td>\n",
       "      <td>MAHARASHTRA</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID              Candidate        Constituency ∇ Party  Criminal Case  \\\n",
       "0   0             M.K. Mohan            ANNA NAGAR   DMK              4   \n",
       "1   1   Khatik Ramesh Prasad           KARERA (SC)   BJP              0   \n",
       "2   2       Dr. Mantar Gowda              MADIKERI   INC              0   \n",
       "3   3           Kundan Kumar             BEGUSARAI   BJP              0   \n",
       "4   4        Swapan Majumder  BANGAON DAKSHIN (SC)   BJP              2   \n",
       "5   5               Arup Roy         HOWRAH MADHYA  AITC              0   \n",
       "6   6       Baby Rani Maurya       AGRA RURAL (SC)   BJP              0   \n",
       "7   7           Neena Mittal               RAJPURA   AAP              1   \n",
       "8   8  Fareed Mahfooz Kidwai             RAM NAGAR    SP              1   \n",
       "9   9    Atul Moreshwar Save      AURANGBAD (EAST)   BJP              6   \n",
       "\n",
       "  Total Assets Liabilities           state              Education  \n",
       "0   211 Crore+    2 Crore+      TAMIL NADU               8th Pass  \n",
       "1     1 Crore+           0  MADHYA PRADESH              12th Pass  \n",
       "2     7 Crore+     22 Lac+       KARNATAKA          Post Graduate  \n",
       "3     9 Crore+     24 Lac+           BIHAR          Post Graduate  \n",
       "4     2 Crore+     61 Lac+     WEST BENGAL               8th Pass  \n",
       "5     3 Crore+     29 Lac+     WEST BENGAL  Graduate Professional  \n",
       "6     2 Crore+           0   UTTAR PRADESH          Post Graduate  \n",
       "7     9 Crore+    2 Crore+          PUNJAB               Graduate  \n",
       "8     5 Crore+     35 Lac+   UTTAR PRADESH          Post Graduate  \n",
       "9    22 Crore+    2 Crore+     MAHARASHTRA               Graduate  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the train data\n",
    "df = pd.read_csv('./train.csv')\n",
    "# Looking top 10 rows\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df\n",
    "y = df['Education']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop('Candidate',axis=1)\n",
    "X = X.drop('Constituency ∇',axis=1)\n",
    "X.drop('ID',axis=1,inplace=True)\n",
    "for row in X.index:\n",
    "    #Remove WhiteSpaces in State in the middle of the string.\n",
    "    X.loc[row, \"state\"] = X.loc[row, \"state\"].replace(\" \", \"\")\n",
    "    # print(X.loc[row, \"Total Assets\"][-4:])\n",
    "    if(X.loc[row, \"Total Assets\"][-4:] == \"Lac+\"):\n",
    "        X.loc[row, \"Total Assets\"] = X.loc[row, \"Total Assets\"][:-4]\n",
    "        X.loc[row, \"Total Assets\"] = str(int(X.loc[row, \"Total Assets\"]) * 100)\n",
    "    elif(X.loc[row, \"Total Assets\"][-6:] == \"Crore+\"):\n",
    "        X.loc[row, \"Total Assets\"] = X.loc[row, \"Total Assets\"][:-6]\n",
    "        X.loc[row, \"Total Assets\"] = str(int(X.loc[row, \"Total Assets\"]) * 10000)\n",
    "    elif(X.loc[row,  \"Total Assets\"][-5:] == \"Thou+\"):\n",
    "        X.loc[row,  \"Total Assets\"] = X.loc[row,  \"Total Assets\"][:-5]\n",
    "        X.loc[row,  \"Total Assets\"] = str(int(X.loc[row,  \"Total Assets\"]))\n",
    "    elif(X.loc[row,  \"Total Assets\"][-5:] == \"Hund+\"):\n",
    "        X.loc[row,  \"Total Assets\"] = \"0\"\n",
    "for row in X.index:\n",
    "    if(isinstance(X.loc[row, \"Liabilities\"], float)):\n",
    "        X.loc[row, \"Liabilities\"] = \"0\"\n",
    "    elif(X.loc[row, \"Liabilities\"][-4:] == \"Lac+\"):\n",
    "        X.loc[row, \"Liabilities\"] = X.loc[row, \"Liabilities\"][:-4]\n",
    "        X.loc[row, \"Liabilities\"] = str(int(X.loc[row, \"Liabilities\"]) * 100)\n",
    "    elif(X.loc[row, \"Liabilities\"][-6:] == \"Crore+\"):\n",
    "        X.loc[row, \"Liabilities\"] = X.loc[row, \"Liabilities\"][:-6]\n",
    "        X.loc[row, \"Liabilities\"] = str(int(X.loc[row, \"Liabilities\"]) * 10000)\n",
    "    elif(X.loc[row, \"Liabilities\"][-5:] == \"Thou+\"):\n",
    "        X.loc[row, \"Liabilities\"] = X.loc[row, \"Liabilities\"][:-5]\n",
    "        X.loc[row, \"Liabilities\"] = str(int(X.loc[row, \"Liabilities\"]))\n",
    "    elif(X.loc[row, \"Liabilities\"][-5:] == \"Hund+\"):\n",
    "        X.loc[row, \"Liabilities\"] = \"0\"\n",
    "# Mapping Parties to unique values in the dataframe using map function\n",
    "# Create a dictionary of the parties and their corresponding unique values\n",
    "party = X['Party'].unique()\n",
    "party = {value: idx for idx, value in enumerate(party)}\n",
    "# Add a value for nan parties\n",
    "party[\"\"] = -1\n",
    "# Mapping the values to the dataframe\n",
    "X['Party'] = X['Party'].map(party)\n",
    "state = X['state'].unique()\n",
    "state = {value: idx for idx, value in enumerate(state)}\n",
    "# Mapping the values to the dataframe\n",
    "X['state'] = X['state'].map(state)\n",
    "education = y.unique()\n",
    "education = {value: idx for idx, value in enumerate(education)}\n",
    "# Mapping the values to the dataframe\n",
    "y = y.map(education)\n",
    "X['Education'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Party</th>\n",
       "      <th>Criminal Case</th>\n",
       "      <th>Total Assets</th>\n",
       "      <th>Liabilities</th>\n",
       "      <th>state</th>\n",
       "      <th>Education</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1430000</td>\n",
       "      <td>10000</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10000</td>\n",
       "      <td>600</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10000</td>\n",
       "      <td>400</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>400</td>\n",
       "      <td>2100</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>10000</td>\n",
       "      <td>1600</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130000</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "      <td>10000</td>\n",
       "      <td>1900</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>50000</td>\n",
       "      <td>110000</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6900</td>\n",
       "      <td>1200</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>5200</td>\n",
       "      <td>140000</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Party  Criminal Case  Total Assets  Liabilities  state  Education\n",
       "0         5              4       1430000        10000      5          2\n",
       "1         1              1         10000          600     22          2\n",
       "2         1              0         10000          400     16          4\n",
       "3         1              2           400         2100     19          4\n",
       "4         6              0         10000         1600     10          2\n",
       "...     ...            ...           ...          ...    ...        ...\n",
       "7995      1              0        130000            0     18          4\n",
       "7996     13             23         10000         1900     11          1\n",
       "7997      1              0         50000       110000      4          3\n",
       "7998      1              2          6900         1200      5          2\n",
       "7999      8              1          5200       140000      7          5\n",
       "\n",
       "[8000 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Synthetic Data\n",
    "df = pd.read_csv('./synthetic_data_best.csv')\n",
    "X_Synthetic = df\n",
    "X_Synthetic['state'] = X_Synthetic['state'].map(state)\n",
    "X_Synthetic['Party'] = X_Synthetic['Party'].map(party)\n",
    "X_Synthetic['Education'] = X_Synthetic['Education'].map(education)\n",
    "X_Synthetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append the synthetic data to the original data\n",
    "df_combined = pd.concat([X, X_Synthetic], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Train_StateWise = []\n",
    "Y_Train_StateWise = []\n",
    "for i in range(len(state)):\n",
    "\tX_Train_StateWise.append(X[X['state'] == i].drop('Education', axis = 1).drop(['Total Assets', 'Liabilities'], axis = 1))\n",
    "\tY_Train_StateWise.append(X[X['state'] == i]['Education'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = X['Education']\n",
    "X = X.drop('Education', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_preprocessing(X, state, party):\n",
    "\tX = X.drop('Candidate',axis=1)\n",
    "\tX = X.drop('Constituency ∇',axis=1)\n",
    "\tX.drop('ID',axis=1,inplace=True)\n",
    "\tfor row in X.index:\n",
    "\t\tX.loc[row, \"state\"] = X.loc[row, \"state\"].replace(\" \", \"\")\n",
    "\t\t# print(X.loc[row, \"Total Assets\"][-4:])\n",
    "\t\tif(X.loc[row, \"Total Assets\"][-4:] == \"Lac+\"):\n",
    "\t\t\tX.loc[row, \"Total Assets\"] = X.loc[row, \"Total Assets\"][:-4]\n",
    "\t\t\tX.loc[row, \"Total Assets\"] = str(int(X.loc[row, \"Total Assets\"]) * 100)\n",
    "\t\telif(X.loc[row, \"Total Assets\"][-6:] == \"Crore+\"):\n",
    "\t\t\tX.loc[row, \"Total Assets\"] = X.loc[row, \"Total Assets\"][:-6]\n",
    "\t\t\tX.loc[row, \"Total Assets\"] = str(int(X.loc[row, \"Total Assets\"]) * 10000)\n",
    "\t\telif(X.loc[row,  \"Total Assets\"][-5:] == \"Thou+\"):\n",
    "\t\t\tX.loc[row,  \"Total Assets\"] = X.loc[row,  \"Total Assets\"][:-5]\n",
    "\t\t\tX.loc[row,  \"Total Assets\"] = str(int(X.loc[row,  \"Total Assets\"]))\n",
    "\t\telif(X.loc[row,  \"Total Assets\"][-5:] == \"Hund+\"):\n",
    "\t\t\tX.loc[row,  \"Total Assets\"] = \"0\"\n",
    "\tfor row in X.index:\n",
    "\t\tif(X.loc[row, \"Liabilities\"][-4:] == \"Lac+\"):\n",
    "\t\t\tX.loc[row, \"Liabilities\"] = X.loc[row, \"Liabilities\"][:-4]\n",
    "\t\t\tX.loc[row, \"Liabilities\"] = str(int(X.loc[row, \"Liabilities\"]) * 100)\n",
    "\t\telif(X.loc[row, \"Liabilities\"][-6:] == \"Crore+\"):\n",
    "\t\t\tX.loc[row, \"Liabilities\"] = X.loc[row, \"Liabilities\"][:-6]\n",
    "\t\t\tX.loc[row, \"Liabilities\"] = str(int(X.loc[row, \"Liabilities\"]) * 10000)\n",
    "\t\telif(X.loc[row, \"Liabilities\"][-5:] == \"Thou+\"):\n",
    "\t\t\tX.loc[row, \"Liabilities\"] = X.loc[row, \"Liabilities\"][:-5]\n",
    "\t\t\tX.loc[row, \"Liabilities\"] = str(int(X.loc[row, \"Liabilities\"]))\n",
    "\t\telif(X.loc[row, \"Liabilities\"][-5:] == \"Hund+\"):\n",
    "\t\t\tX.loc[row, \"Liabilities\"] = \"0\"\n",
    "\tX['Party'] = X['Party'].map(party)\n",
    "\tX['state'] = X['state'].map(state)\n",
    "\treturn X\n",
    "\n",
    "def answer_preprocessing(X, state, party, education):\n",
    "\tX = X.drop('Candidate',axis=1)\n",
    "\tX = X.drop('Constituency ∇',axis=1)\n",
    "\tX.drop('ID',axis=1,inplace=True)\n",
    "\tfor row in X.index:\n",
    "\t\tX.loc[row, \"state\"] = X.loc[row, \"state\"].replace(\" \", \"\")\n",
    "\t\t# print(X.loc[row, \"Total Assets\"][-4:])\n",
    "\t\tif(X.loc[row, \"Total Assets\"][-4:] == \"Lac+\"):\n",
    "\t\t\tX.loc[row, \"Total Assets\"] = X.loc[row, \"Total Assets\"][:-4]\n",
    "\t\t\tX.loc[row, \"Total Assets\"] = str(int(X.loc[row, \"Total Assets\"]) * 100)\n",
    "\t\telif(X.loc[row, \"Total Assets\"][-6:] == \"Crore+\"):\n",
    "\t\t\tX.loc[row, \"Total Assets\"] = X.loc[row, \"Total Assets\"][:-6]\n",
    "\t\t\tX.loc[row, \"Total Assets\"] = str(int(X.loc[row, \"Total Assets\"]) * 10000)\n",
    "\t\telif(X.loc[row,  \"Total Assets\"][-5:] == \"Thou+\"):\n",
    "\t\t\tX.loc[row,  \"Total Assets\"] = X.loc[row,  \"Total Assets\"][:-5]\n",
    "\t\t\tX.loc[row,  \"Total Assets\"] = str(int(X.loc[row,  \"Total Assets\"]))\n",
    "\t\telif(X.loc[row,  \"Total Assets\"][-5:] == \"Hund+\"):\n",
    "\t\t\tX.loc[row,  \"Total Assets\"] = \"0\"\n",
    "\tfor row in X.index:\n",
    "\t\tif(X.loc[row, \"Liabilities\"][-4:] == \"Lac+\"):\n",
    "\t\t\tX.loc[row, \"Liabilities\"] = X.loc[row, \"Liabilities\"][:-4]\n",
    "\t\t\tX.loc[row, \"Liabilities\"] = str(int(X.loc[row, \"Liabilities\"]) * 100)\n",
    "\t\telif(X.loc[row, \"Liabilities\"][-6:] == \"Crore+\"):\n",
    "\t\t\tX.loc[row, \"Liabilities\"] = X.loc[row, \"Liabilities\"][:-6]\n",
    "\t\t\tX.loc[row, \"Liabilities\"] = str(int(X.loc[row, \"Liabilities\"]) * 10000)\n",
    "\t\telif(X.loc[row, \"Liabilities\"][-5:] == \"Thou+\"):\n",
    "\t\t\tX.loc[row, \"Liabilities\"] = X.loc[row, \"Liabilities\"][:-5]\n",
    "\t\t\tX.loc[row, \"Liabilities\"] = str(int(X.loc[row, \"Liabilities\"]))\n",
    "\t\telif(X.loc[row, \"Liabilities\"][-5:] == \"Hund+\"):\n",
    "\t\t\tX.loc[row, \"Liabilities\"] = \"0\"\n",
    "\tX['Party'] = X['Party'].map(party)\n",
    "\tX['state'] = X['state'].map(state)\n",
    "\tX['Education'] = X['Education'].map(education)\n",
    "\treturn X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth of the Decision Tree:  19\n",
      "Accuracy on training:  0.47917288000795305\n"
     ]
    }
   ],
   "source": [
    "train_dt2_x = X.copy()\n",
    "train_dt2_y = Y.copy()\n",
    "train_dt2_x = train_dt2_x.drop('Total Assets',axis=1)\n",
    "train_dt2_x = train_dt2_x.drop('Liabilities',axis=1)\n",
    "train_dt2_y.head()\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# creating the decision tree function\n",
    "model_dt_ak = DecisionTreeClassifier(random_state=10,criterion='entropy')\n",
    "\n",
    "#fitting the model\n",
    "model_dt_ak.fit(train_dt2_x, train_dt2_y)\n",
    "\n",
    "# depth of the decision tree\n",
    "print('Depth of the Decision Tree: ', model_dt_ak.get_depth())\n",
    "\n",
    "#checking the training score\n",
    "print('Accuracy on training: ',model_dt_ak.score(train_dt2_x, train_dt2_y))\n",
    "\n",
    "# predict the target on the train dataset\n",
    "yhat1 = model_dt_ak.predict(train_dt2_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 7344 candidates, totalling 36720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "4590 fits failed out of a total of 36720.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "4590 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan 0.30052692 0.30052692 ... 0.37538775 0.37538775 0.37538775]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=DecisionTreeClassifier(random_state=10),\n",
       "             param_grid={&#x27;ccp_alpha&#x27;: [0.1, 0.01, 0.001],\n",
       "                         &#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
       "                         &#x27;max_depth&#x27;: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
       "                                       13, 14, 15, 16, 17],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "                         &#x27;min_samples_split&#x27;: [1, 2, 3, 4, 5, 6, 7, 10]},\n",
       "             verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=DecisionTreeClassifier(random_state=10),\n",
       "             param_grid={&#x27;ccp_alpha&#x27;: [0.1, 0.01, 0.001],\n",
       "                         &#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
       "                         &#x27;max_depth&#x27;: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
       "                                       13, 14, 15, 16, 17],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "                         &#x27;min_samples_split&#x27;: [1, 2, 3, 4, 5, 6, 7, 10]},\n",
       "             verbose=True)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=10)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=10)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(random_state=10),\n",
       "             param_grid={'ccp_alpha': [0.1, 0.01, 0.001],\n",
       "                         'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
       "                                       13, 14, 15, 16, 17],\n",
       "                         'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "                         'min_samples_split': [1, 2, 3, 4, 5, 6, 7, 10]},\n",
       "             verbose=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grid Search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Create the parameter grid based on the results of random search\n",
    "param_grid = {\n",
    "    'max_depth': [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17],\n",
    "    'min_samples_leaf': [1, 2, 3, 4, 5,6,7,8,9],\n",
    "\t'ccp_alpha': [0.1, .01, .001],\n",
    "    'min_samples_split': [1,2,3,4, 5,6,7,10],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "tree_clas = DecisionTreeClassifier(random_state=10)\n",
    "grid_search = GridSearchCV(estimator=tree_clas, param_grid=param_grid, cv=5, verbose=True)\n",
    "grid_search.fit(train_dt2_x, train_dt2_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(ccp_alpha=0.001, criterion=&#x27;entropy&#x27;, max_depth=13,\n",
       "                       min_samples_leaf=6, random_state=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(ccp_alpha=0.001, criterion=&#x27;entropy&#x27;, max_depth=13,\n",
       "                       min_samples_leaf=6, random_state=10)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.001, criterion='entropy', max_depth=13,\n",
       "                       min_samples_leaf=6, random_state=10)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model = grid_search.best_estimator_\n",
    "final_model.fit(train_dt2_x, train_dt2_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth of the Decision Tree:  26\n",
      "Accuracy on training:  0.9150014912019088\n"
     ]
    }
   ],
   "source": [
    "train_dt1_x = X.copy()\n",
    "train_dt1_y = Y.copy()\n",
    "train_dt1_y.head()\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# creating the decision tree function\n",
    "model_dt = DecisionTreeClassifier(random_state=10,criterion='entropy')\n",
    "\n",
    "#fitting the model\n",
    "model_dt.fit(train_dt1_x, train_dt1_y)\n",
    "\n",
    "# depth of the decision tree\n",
    "print('Depth of the Decision Tree: ', model_dt.get_depth())\n",
    "\n",
    "#checking the training score\n",
    "print('Accuracy on training: ',model_dt.score(train_dt1_x, train_dt1_y))\n",
    "\n",
    "# predict the target on the train dataset\n",
    "yhat1 = model_dt.predict(train_dt1_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Test = test_preprocessing(pd.read_csv('./test.csv'), state, party)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0, ..., 5, 2, 4])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dt1_x = X_Test.copy()\n",
    "y_dt1 = model_dt.predict(test_dt1_x)\n",
    "y_dt1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dt2_x = X_Test.copy()\n",
    "test_dt2_x = test_dt2_x.drop('Total Assets',axis=1)\n",
    "test_dt2_x = test_dt2_x.drop('Liabilities',axis=1)\n",
    "yy = final_model.predict(test_dt2_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "415\n"
     ]
    }
   ],
   "source": [
    "answer = pd.read_csv('./answers.csv')\n",
    "answer['Education'] = answer['Education'].map(education)\n",
    "correct_count = 0\n",
    "for i in range(len(answer)):\n",
    "    if(answer.loc[i, 'Education'] == yy[i]):\n",
    "        correct_count += 1\n",
    "\n",
    "print(correct_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  30.2037845705968\n",
      "F1 Score :  0.2551107186506989\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: ', correct_count/len(answer) * 100)\n",
    "#Calculat the F1 Score\n",
    "from sklearn.metrics import f1_score\n",
    "f1 = f1_score(answer['Education'], yy, average='weighted')\n",
    "#Print the f1_score\n",
    "print(\"F1 Score : \", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(Y_Test_StateWise, answer_statewise):\n",
    "\t#convert this to an array\n",
    "    temp = np.array(answer_statewise['Education'])\n",
    "    correct_count = 0\n",
    "    for i in range(len(Y_Test_StateWise)):\n",
    "        if(temp[i] == Y_Test_StateWise[i]):\n",
    "            correct_count += 1\n",
    "    f1 = f1_score(Y_Test_StateWise, temp, average='weighted')\n",
    "    return [correct_count/len(Y_Test_StateWise) * 100, correct_count, f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = answer_preprocessing(pd.read_csv('./answers.csv'), state, party, education)\n",
    "for i in range(len(answer)):\n",
    "    if(pd.notnull(answer.loc[i, 'Party'])):\n",
    "        continue\n",
    "    else :\n",
    "        print(answer.loc[i])\n",
    "\n",
    "X_Test_StateWise = []\n",
    "answer_statewise = []\n",
    "Y_Test_StateWise = []\n",
    "X_Train_StateWise_Dropped = []\n",
    "for i in range(len(state)):\n",
    "    # X_Train_StateWise_Dropped.append(X_Train_StateWise[i].drop(['Total Assets','Liabilities'], axis = 1))\n",
    "    answer_statewise.append(answer[answer['state'] == i])\n",
    "    X_Test_StateWise.append(X_Test[X_Test['state'] == i].drop(['Total Assets','Liabilities'], axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Party</th>\n",
       "      <th>Criminal Case</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9956</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9986</th>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10010</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>689 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Party  Criminal Case  state\n",
       "0          0              4      0\n",
       "27         0              0      0\n",
       "36        12              0      0\n",
       "42         0              6      0\n",
       "76         0              3      0\n",
       "...      ...            ...    ...\n",
       "9956      12              0      0\n",
       "9986      12              3      0\n",
       "9999       0              3      0\n",
       "10000     12              0      0\n",
       "10010     12              0      0\n",
       "\n",
       "[689 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_Train_StateWise[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc(yhat):\n",
    "\tanswer = pd.read_csv('./answers.csv')\n",
    "\tanswer['Education'] = answer['Education'].map(education)\n",
    "\tcorrect_count = 0\n",
    "\tfor i in range(len(answer)):\n",
    "\t\tif(answer.loc[i, 'Education'] == yhat[i]):\n",
    "\t\t\tcorrect_count += 1\n",
    "\tprint(correct_count)\n",
    "\tprint('Accuracy: ', correct_count/len(answer) * 100)\n",
    "\t#Calculate the F1 Score\n",
    "\tf1 = f1_score(answer['Education'], y_dt1, average='weighted')\n",
    "\t#Print the f1_score\n",
    "\tprint(\"F1 Score : \", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Accuracy on training:  0.9150014912019088\n",
      "kNN\n",
      "Accuracy on training:  0.9008847797991848\n",
      "AdaBoost\n",
      "Accuracy on training:  0.3197136892335222\n",
      "{'learning_rate': 0.1, 'n_estimators': 200}\n",
      "0.3189183815488617\n",
      "Naive Bayes\n",
      "Accuracy on training:  0.08430261457401332\n",
      "Decision Tree\n",
      "Accuracy on training:  0.9150014912019088\n",
      "306\n",
      "Accuracy:  22.270742358078603\n",
      "F1 Score :  0.22028799518773245\n",
      "317\n",
      "Accuracy:  23.071324599708877\n",
      "F1 Score :  0.22028799518773245\n",
      "318\n",
      "Accuracy:  23.144104803493452\n",
      "F1 Score :  0.22028799518773245\n",
      "368\n",
      "Accuracy:  26.78311499272198\n",
      "F1 Score :  0.22028799518773245\n",
      "77\n",
      "Accuracy:  5.604075691411936\n",
      "F1 Score :  0.22028799518773245\n"
     ]
    }
   ],
   "source": [
    "model_dt = DecisionTreeClassifier(random_state=10,criterion='entropy')\n",
    "model_dt.fit(train_dt1_x, train_dt1_y)\n",
    "\n",
    "# Random Forest\n",
    "print('Random Forest')\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model_rf = RandomForestClassifier(n_estimators=100, random_state=10)\n",
    "model_rf.fit(train_dt1_x, train_dt1_y)\n",
    "print('Accuracy on training: ',model_rf.score(train_dt1_x, train_dt1_y))\n",
    "#kNN\n",
    "print('kNN')\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model_knn = KNeighborsClassifier(n_neighbors=1)\n",
    "model_knn.fit(train_dt1_x, train_dt1_y)\n",
    "print('Accuracy on training: ',model_knn.score(train_dt1_x, train_dt1_y))\n",
    "\n",
    "#AdaBoost\n",
    "print('AdaBoost')\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "model_knt = AdaBoostClassifier(n_estimators=100, random_state=10)\n",
    "model_knt.fit(train_dt1_x, train_dt1_y)\n",
    "print('Accuracy on training: ',model_knt.score(train_dt1_x, train_dt1_y))\n",
    "# Grid Search on AdaBoost\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.1, 0.01, 0.001]\n",
    "}\n",
    "grid_search = GridSearchCV(AdaBoostClassifier(), param_grid, cv=3)\n",
    "grid_search.fit(train_dt1_x, train_dt1_y)\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)\n",
    "\n",
    "\n",
    "#Naive Bayes\n",
    "print('Naive Bayes')\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "model_nb = GaussianNB()\n",
    "model_nb.fit(train_dt1_x, train_dt1_y)\n",
    "print('Accuracy on training: ',model_nb.score(train_dt1_x, train_dt1_y))\n",
    "\n",
    "# #Logistic Regression\n",
    "# print('Logistic Regression')\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# model_lr = LogisticRegression()\n",
    "# model_lr.fit(train_dt1_x, train_dt1_y)\n",
    "# print('Accuracy on training: ',model_lr.score(train_dt1_x, train_dt1_y))\n",
    "\n",
    "#Decision Tree\n",
    "print('Decision Tree')\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model_dt = DecisionTreeClassifier(random_state=10,criterion='entropy')\n",
    "model_dt.fit(train_dt1_x, train_dt1_y)\n",
    "print('Accuracy on training: ',model_dt.score(train_dt1_x, train_dt1_y))\n",
    "\n",
    "#predict the target on the test dataset\n",
    "yhat1 = model_dt.predict(X_Test)\n",
    "yhat2 = model_rf.predict(X_Test)\n",
    "yhat3 = model_knn.predict(X_Test)\n",
    "yhat4 = model_knt.predict(X_Test)\n",
    "yhat5 = model_nb.predict(X_Test)\n",
    "# yhat6 = model_lr.predict(X_Test)\n",
    "\n",
    "acc(yhat1)\n",
    "acc(yhat2)\n",
    "acc(yhat3)\n",
    "acc(yhat4)\n",
    "acc(yhat5)\n",
    "# acc(yhat6)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMeans\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "Accuracy:  3.6390101892285296\n",
      "F1 Score :  0.22028799518773245\n",
      "Agglomerative Clustering\n",
      "227\n",
      "Accuracy:  16.521106259097525\n",
      "F1 Score :  0.22028799518773245\n",
      "DBSCAN\n",
      "0\n",
      "Accuracy:  0.0\n",
      "F1 Score :  0.22028799518773245\n",
      "Birch\n",
      "50\n",
      "Accuracy:  3.6390101892285296\n",
      "F1 Score :  0.22028799518773245\n",
      "MiniBatchKMeans\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1934: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219\n",
      "Accuracy:  15.938864628820962\n",
      "F1 Score :  0.22028799518773245\n",
      "MeanShift\n",
      "56\n",
      "Accuracy:  4.075691411935954\n",
      "F1 Score :  0.22028799518773245\n",
      "Spectral Clustering\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/manifold/_spectral_embedding.py:273: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 46\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSpectral Clustering\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     45\u001b[0m model_spectral \u001b[38;5;241m=\u001b[39m SpectralClustering(n_clusters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m---> 46\u001b[0m \u001b[43mmodel_spectral\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dt1_x\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m yhat13 \u001b[38;5;241m=\u001b[39m model_spectral\u001b[38;5;241m.\u001b[39mfit_predict(X_Test)\n\u001b[1;32m     48\u001b[0m acc(yhat13)\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_spectral.py:730\u001b[0m, in \u001b[0;36mSpectralClustering.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    721\u001b[0m n_components \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    722\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_clusters \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components\n\u001b[1;32m    723\u001b[0m )\n\u001b[1;32m    724\u001b[0m \u001b[38;5;66;03m# We now obtain the real valued solution matrix to the\u001b[39;00m\n\u001b[1;32m    725\u001b[0m \u001b[38;5;66;03m# relaxed Ncut problem, solving the eigenvalue problem\u001b[39;00m\n\u001b[1;32m    726\u001b[0m \u001b[38;5;66;03m# L_sym x = lambda x  and recovering u = D^-1/2 x.\u001b[39;00m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;66;03m# The first eigenvector is constant only for fully connected graphs\u001b[39;00m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;66;03m# and should be kept for spectral clustering (drop_first = False)\u001b[39;00m\n\u001b[1;32m    729\u001b[0m \u001b[38;5;66;03m# See spectral_embedding documentation.\u001b[39;00m\n\u001b[0;32m--> 730\u001b[0m maps \u001b[38;5;241m=\u001b[39m \u001b[43mspectral_embedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    731\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maffinity_matrix_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    732\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_components\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_components\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    733\u001b[0m \u001b[43m    \u001b[49m\u001b[43meigen_solver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meigen_solver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    735\u001b[0m \u001b[43m    \u001b[49m\u001b[43meigen_tol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meigen_tol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdrop_first\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    737\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    738\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose:\n\u001b[1;32m    739\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComputing label assignment using \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massign_labels\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/manifold/_spectral_embedding.py:313\u001b[0m, in \u001b[0;36mspectral_embedding\u001b[0;34m(adjacency, n_components, eigen_solver, random_state, eigen_tol, norm_laplacian, drop_first)\u001b[0m\n\u001b[1;32m    311\u001b[0m laplacian \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    312\u001b[0m v0 \u001b[38;5;241m=\u001b[39m _init_arpack_v0(laplacian\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], random_state)\n\u001b[0;32m--> 313\u001b[0m _, diffusion_map \u001b[38;5;241m=\u001b[39m \u001b[43meigsh\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlaplacian\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_components\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhich\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLM\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mv0\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    316\u001b[0m embedding \u001b[38;5;241m=\u001b[39m diffusion_map\u001b[38;5;241m.\u001b[39mT[n_components::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m norm_laplacian:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;66;03m# recover u = D^-1/2 x from the eigenvector output x\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py:1697\u001b[0m, in \u001b[0;36meigsh\u001b[0;34m(A, k, M, sigma, which, v0, ncv, maxiter, tol, return_eigenvectors, Minv, OPinv, mode)\u001b[0m\n\u001b[1;32m   1695\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _ARPACK_LOCK:\n\u001b[1;32m   1696\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m params\u001b[38;5;241m.\u001b[39mconverged:\n\u001b[0;32m-> 1697\u001b[0m         \u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1699\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m params\u001b[38;5;241m.\u001b[39mextract(return_eigenvectors)\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py:560\u001b[0m, in \u001b[0;36m_SymmetricArpackParams.iterate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    558\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    559\u001b[0m         Bxslice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mipntr[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mipntr[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn)\n\u001b[0;32m--> 560\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworkd[yslice] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOPa\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mworkd\u001b[49m\u001b[43m[\u001b[49m\u001b[43mBxslice\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mido \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    562\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworkd[yslice] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mB(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworkd[xslice])\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/scipy/sparse/linalg/_interface.py:234\u001b[0m, in \u001b[0;36mLinearOperator.matvec\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m (N,) \u001b[38;5;129;01mand\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m (N,\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdimension mismatch\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 234\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_matvec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, np\u001b[38;5;241m.\u001b[39mmatrix):\n\u001b[1;32m    237\u001b[0m     y \u001b[38;5;241m=\u001b[39m asmatrix(y)\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py:944\u001b[0m, in \u001b[0;36mLuInv._matvec\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    943\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_matvec\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 944\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlu_solve\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mM_lu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/scipy/linalg/_decomp_lu.py:152\u001b[0m, in \u001b[0;36mlu_solve\u001b[0;34m(lu_and_piv, b, trans, overwrite_b, check_finite)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShapes of lu \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and b \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m are incompatible\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    149\u001b[0m                      \u001b[38;5;241m.\u001b[39mformat(lu\u001b[38;5;241m.\u001b[39mshape, b1\u001b[38;5;241m.\u001b[39mshape))\n\u001b[1;32m    151\u001b[0m getrs, \u001b[38;5;241m=\u001b[39m get_lapack_funcs((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgetrs\u001b[39m\u001b[38;5;124m'\u001b[39m,), (lu, b1))\n\u001b[0;32m--> 152\u001b[0m x, info \u001b[38;5;241m=\u001b[39m \u001b[43mgetrs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpiv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrans\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrans\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite_b\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite_b\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "print('KMeans')\n",
    "model_kmc = KMeans(n_clusters=2, random_state=10)\n",
    "model_kmc.fit(train_dt1_x)\n",
    "yhat7 = model_kmc.predict(X_Test)\n",
    "acc(yhat7)\n",
    "\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "print('Agglomerative Clustering')\n",
    "model_agg = AgglomerativeClustering(n_clusters=2)\n",
    "model_agg.fit(train_dt1_x)\n",
    "yhat8 = model_agg.fit_predict(X_Test)\n",
    "acc(yhat8)\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "print('DBSCAN')\n",
    "model_dbscan = DBSCAN(eps=0.30, min_samples=9)\n",
    "model_dbscan.fit(train_dt1_x)\n",
    "yhat9 = model_dbscan.fit_predict(X_Test)\n",
    "acc(yhat9)\n",
    "\n",
    "from sklearn.cluster import Birch\n",
    "print('Birch')\n",
    "model_birch = Birch(n_clusters=2)\n",
    "model_birch.fit(train_dt1_x)\n",
    "yhat10 = model_birch.predict(X_Test)\n",
    "acc(yhat10)\n",
    "\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "print('MiniBatchKMeans')\n",
    "model_minibatch = MiniBatchKMeans(n_clusters=2)\n",
    "model_minibatch.fit(train_dt1_x)\n",
    "yhat11 = model_minibatch.predict(X_Test)\n",
    "acc(yhat11)\n",
    "\n",
    "from sklearn.cluster import MeanShift\n",
    "print('MeanShift')\n",
    "model_meanshift = MeanShift()\n",
    "model_meanshift.fit(train_dt1_x)\n",
    "yhat12 = model_meanshift.predict(X_Test)\n",
    "acc(yhat12)\n",
    "\n",
    "from sklearn.cluster import SpectralClustering\n",
    "print('Spectral Clustering')\n",
    "model_spectral = SpectralClustering(n_clusters=2)\n",
    "model_spectral.fit(train_dt1_x)\n",
    "yhat13 = model_spectral.fit_predict(X_Test)\n",
    "acc(yhat13)\n",
    "\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "print('Affinity Propagation')\n",
    "model_affinity = AffinityPropagation()\n",
    "model_affinity.fit(train_dt1_x)\n",
    "yhat14 = model_affinity.predict(X_Test)\n",
    "acc(yhat14)\n",
    "\n",
    "from sklearn.cluster import OPTICS\n",
    "print('OPTICS')\n",
    "model_optics = OPTICS()\n",
    "model_optics.fit(train_dt1_x)\n",
    "yhat15 = model_optics.fit_predict(X_Test)\n",
    "acc(yhat15)\n",
    "\n",
    "from sklearn.cluster import GaussianMixture\n",
    "print('Gaussian Mixture')\n",
    "model_gaussian = GaussianMixture(n_components=2)\n",
    "model_gaussian.fit(train_dt1_x)\n",
    "yhat16 = model_gaussian.predict(X_Test)\n",
    "acc(yhat16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(Y_Test_StateWise, answer_statewise):\n",
    "\t#convert this to an array\n",
    "    temp = np.array(answer_statewise['Education'])\n",
    "    correct_count = 0\n",
    "    for i in range(len(Y_Test_StateWise)):\n",
    "        if(temp[i] == Y_Test_StateWise[i]):\n",
    "            correct_count += 1\n",
    "    f1 = f1_score(Y_Test_StateWise, temp, average='weighted')\n",
    "    return [correct_count/len(Y_Test_StateWise) * 100, correct_count, f1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN State Wise Bakchodi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implement KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "models_KNN = []\n",
    "Y_Test_StateWise = []\n",
    "neighbours_calculated = dict()\n",
    "f1_KNN = dict()\n",
    "\n",
    "# Grid Search\n",
    "for i in range(len(state)):\n",
    "\tmodel = KNeighborsClassifier()\n",
    "\tif(len(X_Train_StateWise[i]) <= 15):\n",
    "\t\tmodel.fit(X_Train_StateWise[i], Y_Train_StateWise[i])\n",
    "\t\tmodels_KNN.append(model)\n",
    "\t\tY_Test_StateWise.append(model.predict(X_Test_StateWise[i]))\n",
    "\telse:\n",
    "\t\tf1 = []\n",
    "\t\tfor j in range(1, 15):\n",
    "\t\t\tmodel = KNeighborsClassifier(n_neighbors=j)\n",
    "\t\t\tmodel.fit(X_Train_StateWise[i], Y_Train_StateWise[i])\n",
    "\t\t\t# f1.append(f1_score(Y_Train_StateWise[i], model.predict(X_Train_StateWise[i]), average='weighted'))\n",
    "\t\t\t\n",
    "\t\t\ty = model.predict(X_Test_StateWise[i])\n",
    "\t\t\tt = calculate_accuracy(y, answer_statewise[i])[2]\n",
    "\t\t\tf1.append(t)\n",
    "\t\t\n",
    "\t\tneighbours_calculated[i] = (f1.index(max(f1)) + 1)\n",
    "\t\tmodel = KNeighborsClassifier(n_neighbors=f1.index(max(f1)) + 1)\n",
    "\t\tmodel.fit(X_Train_StateWise[i], Y_Train_StateWise[i])\n",
    "\t\tmodels_KNN.append(model)\n",
    "\t\tY_Test_StateWise.append(model.predict(X_Test_StateWise[i]))\n",
    "\tf1 = calculate_accuracy(Y_Test_StateWise[i], answer_statewise[i])[2]\n",
    "\tf1_KNN[i] = f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    }
   ],
   "source": [
    "#Implement KNN\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "models_KMC = []\n",
    "Y_Test_StateWise = []\n",
    "neighbours_calculated = dict()\n",
    "f1_KMC = dict()\n",
    "\n",
    "# Grid Search\n",
    "for i in range(len(state)):\n",
    "\tmodel = AgglomerativeClustering(n_clusters=2)\n",
    "\tif(len(X_Train_StateWise[i]) <= 15):\n",
    "\t\tmodel.fit(X_Train_StateWise[i], Y_Train_StateWise[i])\n",
    "\t\tmodels_KMC.append(model)\n",
    "\t\tY_Test_StateWise.append(model.predict(X_Test_StateWise[i]))\n",
    "\telse:\n",
    "\t\tf1 = []\n",
    "\t\tfor j in range(1, 15):\n",
    "\t\t\tmodel = AgglomerativeClustering(j_clusters=2)\n",
    "\t\t\tmodel.fit(X_Train_StateWise[i], Y_Train_StateWise[i])\n",
    "\t\t\t# f1.append(f1_score(Y_Train_StateWise[i], model.predict(X_Train_StateWise[i]), average='weighted'))\n",
    "\t\t\t\n",
    "\t\t\ty = model.predict(X_Test_StateWise[i])\n",
    "\t\t\tt = calculate_accuracy(y, answer_statewise[i])[2]\n",
    "\t\t\tf1.append(t)\n",
    "\t\t\n",
    "\t\tneighbours_calculated[i] = (f1.index(max(f1)) + 1)\n",
    "\t\tmodel = AgglomerativeClustering(n_clusters=f1.index(max(f1)) + 1)\n",
    "\t\tmodel.fit(X_Train_StateWise[i], Y_Train_StateWise[i])\n",
    "\t\tmodels_KMC.append(model)\n",
    "\t\tY_Test_StateWise.append(model.predict(X_Test_StateWise[i]))\n",
    "\tf1 = calculate_accuracy(Y_Test_StateWise[i], answer_statewise[i])[2]\n",
    "\tf1_KMC[i] = f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF StateWise Bakchodi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Implement Random Forest\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# models_RF = []\n",
    "# Y_Test_StateWise = []\n",
    "\n",
    "# # Grid Search\n",
    "# for i in range(len(state)):\n",
    "# \tmodel = RandomForestClassifier()\n",
    "# \tif(len(X_Train_StateWise[i]) <= 12):\n",
    "# \t\tmodel.fit(X_Train_StateWise[i], Y_Train_StateWise[i])\n",
    "# \t\tmodels_RF.append(model)\n",
    "# \t\tY_Test_StateWise.append(model.predict(X_Test_StateWise[i]))\n",
    "# \telse:\n",
    "# \t\tf1 = []\n",
    "# \t\tfor j in range(1, 40):\n",
    "# \t\t\tmodel = RandomForestClassifier(n_estimators=j)\n",
    "# \t\t\tmodel.fit(X_Train_StateWise[i], Y_Train_StateWise[i])\n",
    "# \t\t\ty = model.predict(X_Test_StateWise[i])\n",
    "# \t\t\tt = calculate_accuracy(y, answer_statewise[i])[2]\n",
    "# \t\t\tf1.append(t)\n",
    "\t\t\n",
    "# \t\tmodel = RandomForestClassifier(n_estimators=f1.index(max(f1)) + 1)\n",
    "# \t\tmodel.fit(X_Train_StateWise[i], Y_Train_StateWise[i])\n",
    "# \t\tmodels_KNN.append(model)\n",
    "# \t\tY_Test_StateWise.append(model.predict(X_Test_StateWise[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DT StateWise Bakchodi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Fitting 5 folds for each of 640 candidates, totalling 3200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "640 fits failed out of a total of 3200.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "640 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan 0.32076589 0.32076589 0.32076589 0.32076589        nan\n",
      " 0.32076589 0.32076589 0.32076589 0.32076589        nan 0.32076589\n",
      " 0.32076589 0.32076589 0.32076589        nan 0.32076589 0.32076589\n",
      " 0.32076589 0.32076589        nan 0.32076589 0.32076589 0.32076589\n",
      " 0.32076589        nan 0.32076589 0.32076589 0.32076589 0.32076589\n",
      "        nan 0.32076589 0.32076589 0.32076589 0.32076589        nan\n",
      " 0.32076589 0.32076589 0.32076589 0.32076589        nan 0.34834444\n",
      " 0.34834444 0.34834444 0.34834444        nan 0.34689517 0.34689517\n",
      " 0.34689517 0.34689517        nan 0.34689517 0.34689517 0.34689517\n",
      " 0.34689517        nan 0.34689517 0.34689517 0.34689517 0.34689517\n",
      "        nan 0.34689517 0.34689517 0.34689517 0.34689517        nan\n",
      " 0.34689517 0.34689517 0.34689517 0.34689517        nan 0.34689517\n",
      " 0.34689517 0.34689517 0.34689517        nan 0.34689517 0.34689517\n",
      " 0.34689517 0.34689517        nan 0.35408865 0.35408865 0.35408865\n",
      " 0.35408865        nan 0.3511901  0.3511901  0.3511901  0.3511901\n",
      "        nan 0.34829155 0.34829155 0.34829155 0.34829155        nan\n",
      " 0.3511901  0.3511901  0.3511901  0.3511901         nan 0.3511901\n",
      " 0.3511901  0.3511901  0.3511901         nan 0.3511901  0.3511901\n",
      " 0.3511901  0.3511901         nan 0.3511901  0.3511901  0.3511901\n",
      " 0.3511901         nan 0.3511901  0.3511901  0.3511901  0.3511901\n",
      "        nan 0.38752777 0.38752777 0.38752777 0.38752777        nan\n",
      " 0.38462922 0.38462922 0.38462922 0.38462922        nan 0.38173067\n",
      " 0.38173067 0.38173067 0.38173067        nan 0.38462922 0.38462922\n",
      " 0.38462922 0.38462922        nan 0.38462922 0.38462922 0.38462922\n",
      " 0.38462922        nan 0.38462922 0.38462922 0.38462922 0.38462922\n",
      "        nan 0.38462922 0.38462922 0.38462922 0.38462922        nan\n",
      " 0.38028139 0.38028139 0.38028139 0.38028139        nan 0.39189675\n",
      " 0.39189675 0.39189675 0.39189675        nan 0.3889982  0.3889982\n",
      " 0.3889982  0.3889982         nan 0.38609965 0.38609965 0.38609965\n",
      " 0.38609965        nan 0.3889982  0.3889982  0.3889982  0.3889982\n",
      "        nan 0.3889982  0.3889982  0.3889982  0.3889982         nan\n",
      " 0.38754893 0.38754893 0.38754893 0.38754893        nan 0.38175182\n",
      " 0.38175182 0.38175182 0.38175182        nan 0.36722734 0.36722734\n",
      " 0.36722734 0.36722734        nan 0.47324659 0.47469586 0.47323601\n",
      " 0.47614514        nan 0.47179731 0.47179731 0.47179731 0.47324659\n",
      "        nan 0.46744949 0.46744949 0.46744949 0.46889876        nan\n",
      " 0.47760499 0.47760499 0.47760499 0.47760499        nan 0.47615572\n",
      " 0.47615572 0.47615572 0.47615572        nan 0.48050354 0.48050354\n",
      " 0.48050354 0.48050354        nan 0.47325717 0.47325717 0.47325717\n",
      " 0.47325717        nan 0.45873268 0.45873268 0.45873268 0.45873268\n",
      "        nan 0.47470644 0.47615572 0.47324659 0.47761557        nan\n",
      " 0.47180789 0.47180789 0.46890934 0.47181847        nan 0.46890934\n",
      " 0.46890934 0.46601079 0.46747064        nan 0.47617688 0.47617688\n",
      " 0.47617688 0.47617688        nan 0.4747276  0.4747276  0.4747276\n",
      " 0.4747276         nan 0.47907543 0.47907543 0.47907543 0.47907543\n",
      "        nan 0.47037977 0.47037977 0.47037977 0.47037977        nan\n",
      " 0.45440601 0.45440601 0.45440601 0.45440601        nan 0.46885645\n",
      " 0.47030572 0.47465355 0.47902253        nan 0.47320427 0.47320427\n",
      " 0.47176558 0.47467471        nan 0.46886703 0.46886703 0.46596848\n",
      " 0.46742833        nan 0.47178673 0.47178673 0.47178673 0.47178673\n",
      "        nan 0.47178673 0.47178673 0.47178673 0.47178673        nan\n",
      " 0.47178673 0.47178673 0.47178673 0.47178673        nan 0.46309108\n",
      " 0.46309108 0.46309108 0.46309108        nan 0.44856659 0.44856659\n",
      " 0.44856659 0.44856659        nan 0.4630805  0.46452978 0.4688776\n",
      " 0.47324659        nan 0.46449804 0.46449804 0.46305935 0.46596848\n",
      "        nan 0.46743891 0.46743891 0.46454036 0.46600021        nan\n",
      " 0.46742833 0.46742833 0.46742833 0.46742833        nan 0.47032688\n",
      " 0.47032688 0.47032688 0.47032688        nan 0.47032688 0.47032688\n",
      " 0.47032688 0.47032688        nan 0.46163123 0.46163123 0.46163123\n",
      " 0.46163123        nan 0.44710674 0.44710674 0.44710674 0.44710674\n",
      "        nan 0.4630805  0.46452978 0.4688776  0.47324659        nan\n",
      " 0.46449804 0.46449804 0.46305935 0.46596848        nan 0.46743891\n",
      " 0.46743891 0.46454036 0.46600021        nan 0.46742833 0.46742833\n",
      " 0.46742833 0.46742833        nan 0.47032688 0.47032688 0.47032688\n",
      " 0.47032688        nan 0.47032688 0.47032688 0.47032688 0.47032688\n",
      "        nan 0.46163123 0.46163123 0.46163123 0.46163123        nan\n",
      " 0.44710674 0.44710674 0.44710674 0.44710674        nan 0.4630805\n",
      " 0.46452978 0.4688776  0.47324659        nan 0.46449804 0.46449804\n",
      " 0.46305935 0.46596848        nan 0.46743891 0.46743891 0.46454036\n",
      " 0.46600021        nan 0.46742833 0.46742833 0.46742833 0.46742833\n",
      "        nan 0.47032688 0.47032688 0.47032688 0.47032688        nan\n",
      " 0.47032688 0.47032688 0.47032688 0.47032688        nan 0.46163123\n",
      " 0.46163123 0.46163123 0.46163123        nan 0.44710674 0.44710674\n",
      " 0.44710674 0.44710674        nan 0.4630805  0.46452978 0.4688776\n",
      " 0.47324659        nan 0.46449804 0.46449804 0.46305935 0.46596848\n",
      "        nan 0.46743891 0.46743891 0.46454036 0.46600021        nan\n",
      " 0.46742833 0.46742833 0.46742833 0.46742833        nan 0.47032688\n",
      " 0.47032688 0.47032688 0.47032688        nan 0.47032688 0.47032688\n",
      " 0.47032688 0.47032688        nan 0.46163123 0.46163123 0.46163123\n",
      " 0.46163123        nan 0.44710674 0.44710674 0.44710674 0.44710674\n",
      "        nan 0.4630805  0.46452978 0.4688776  0.47324659        nan\n",
      " 0.46449804 0.46449804 0.46305935 0.46596848        nan 0.46743891\n",
      " 0.46743891 0.46454036 0.46600021        nan 0.46742833 0.46742833\n",
      " 0.46742833 0.46742833        nan 0.47032688 0.47032688 0.47032688\n",
      " 0.47032688        nan 0.47032688 0.47032688 0.47032688 0.47032688\n",
      "        nan 0.46163123 0.46163123 0.46163123 0.46163123        nan\n",
      " 0.44710674 0.44710674 0.44710674 0.44710674        nan 0.4630805\n",
      " 0.46452978 0.4688776  0.47324659        nan 0.46449804 0.46449804\n",
      " 0.46305935 0.46596848        nan 0.46743891 0.46743891 0.46454036\n",
      " 0.46600021        nan 0.46742833 0.46742833 0.46742833 0.46742833\n",
      "        nan 0.47032688 0.47032688 0.47032688 0.47032688        nan\n",
      " 0.47032688 0.47032688 0.47032688 0.47032688        nan 0.46163123\n",
      " 0.46163123 0.46163123 0.46163123        nan 0.44710674 0.44710674\n",
      " 0.44710674 0.44710674        nan 0.4630805  0.46452978 0.4688776\n",
      " 0.47324659        nan 0.46449804 0.46449804 0.46305935 0.46596848\n",
      "        nan 0.46743891 0.46743891 0.46454036 0.46600021        nan\n",
      " 0.46742833 0.46742833 0.46742833 0.46742833        nan 0.47032688\n",
      " 0.47032688 0.47032688 0.47032688        nan 0.47032688 0.47032688\n",
      " 0.47032688 0.47032688        nan 0.46163123 0.46163123 0.46163123\n",
      " 0.46163123        nan 0.44710674 0.44710674 0.44710674 0.44710674\n",
      "        nan 0.4630805  0.46452978 0.4688776  0.47324659        nan\n",
      " 0.46449804 0.46449804 0.46305935 0.46596848        nan 0.46743891\n",
      " 0.46743891 0.46454036 0.46600021        nan 0.46742833 0.46742833\n",
      " 0.46742833 0.46742833        nan 0.47032688 0.47032688 0.47032688\n",
      " 0.47032688        nan 0.47032688 0.47032688 0.47032688 0.47032688\n",
      "        nan 0.46163123 0.46163123 0.46163123 0.46163123        nan\n",
      " 0.44710674 0.44710674 0.44710674 0.44710674]\n",
      "  warnings.warn(\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training:  0.5065312046444121\n",
      "1\n",
      "Fitting 5 folds for each of 640 candidates, totalling 3200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "640 fits failed out of a total of 3200.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "640 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan 0.44634146 0.44634146 0.44634146 0.44634146        nan\n",
      " 0.44634146 0.44634146 0.44634146 0.44634146        nan 0.44634146\n",
      " 0.44634146 0.44634146 0.44634146        nan 0.44634146 0.44634146\n",
      " 0.44634146 0.44634146        nan 0.44634146 0.44634146 0.44634146\n",
      " 0.44634146        nan 0.44634146 0.44634146 0.44634146 0.44634146\n",
      "        nan 0.44634146 0.44634146 0.44634146 0.44634146        nan\n",
      " 0.44634146 0.44634146 0.44634146 0.44634146        nan 0.45853659\n",
      " 0.45853659 0.45853659 0.45853659        nan 0.46097561 0.46097561\n",
      " 0.46097561 0.46097561        nan 0.46097561 0.46097561 0.46097561\n",
      " 0.46097561        nan 0.46097561 0.46097561 0.46097561 0.46097561\n",
      "        nan 0.46097561 0.46097561 0.46097561 0.46097561        nan\n",
      " 0.46097561 0.46097561 0.46097561 0.46097561        nan 0.46097561\n",
      " 0.46097561 0.46097561 0.46097561        nan 0.46097561 0.46097561\n",
      " 0.46097561 0.46097561        nan 0.44146341 0.44146341 0.44146341\n",
      " 0.44146341        nan 0.44390244 0.44390244 0.44390244 0.44390244\n",
      "        nan 0.44390244 0.44390244 0.44390244 0.44390244        nan\n",
      " 0.44390244 0.44390244 0.44390244 0.44390244        nan 0.44390244\n",
      " 0.44390244 0.44390244 0.44390244        nan 0.45609756 0.45609756\n",
      " 0.45609756 0.45609756        nan 0.45609756 0.45609756 0.45609756\n",
      " 0.45609756        nan 0.45853659 0.45853659 0.45853659 0.45853659\n",
      "        nan 0.45609756 0.45609756 0.45121951 0.45121951        nan\n",
      " 0.45609756 0.45609756 0.45365854 0.45365854        nan 0.45365854\n",
      " 0.45365854 0.45365854 0.45365854        nan 0.45609756 0.45609756\n",
      " 0.45609756 0.45609756        nan 0.45365854 0.45365854 0.45365854\n",
      " 0.45365854        nan 0.45609756 0.45609756 0.45609756 0.45609756\n",
      "        nan 0.45609756 0.45609756 0.45609756 0.45609756        nan\n",
      " 0.45609756 0.45609756 0.45609756 0.45609756        nan 0.45365854\n",
      " 0.45365854 0.44878049 0.44878049        nan 0.45121951 0.45121951\n",
      " 0.44878049 0.44878049        nan 0.44634146 0.44634146 0.44634146\n",
      " 0.44634146        nan 0.44634146 0.44634146 0.44634146 0.44634146\n",
      "        nan 0.44878049 0.44878049 0.44878049 0.44878049        nan\n",
      " 0.45365854 0.45365854 0.45365854 0.45365854        nan 0.45609756\n",
      " 0.45609756 0.45609756 0.45609756        nan 0.45609756 0.45609756\n",
      " 0.45609756 0.45609756        nan 0.43414634 0.43658537 0.43414634\n",
      " 0.43658537        nan 0.43658537 0.43658537 0.43414634 0.43658537\n",
      "        nan 0.42926829 0.42926829 0.43170732 0.43414634        nan\n",
      " 0.44390244 0.44390244 0.44390244 0.44390244        nan 0.44878049\n",
      " 0.44878049 0.44878049 0.44878049        nan 0.45365854 0.45365854\n",
      " 0.45365854 0.45365854        nan 0.45609756 0.45609756 0.45609756\n",
      " 0.45609756        nan 0.45609756 0.45609756 0.45609756 0.45609756\n",
      "        nan 0.43902439 0.43658537 0.43414634 0.43658537        nan\n",
      " 0.43658537 0.43658537 0.43414634 0.43658537        nan 0.42926829\n",
      " 0.42926829 0.43170732 0.43414634        nan 0.44390244 0.44390244\n",
      " 0.44390244 0.44390244        nan 0.44878049 0.44878049 0.44878049\n",
      " 0.44878049        nan 0.45365854 0.45365854 0.45365854 0.45365854\n",
      "        nan 0.45609756 0.45609756 0.45609756 0.45609756        nan\n",
      " 0.45609756 0.45609756 0.45609756 0.45609756        nan 0.43902439\n",
      " 0.43658537 0.43414634 0.43658537        nan 0.43658537 0.43658537\n",
      " 0.43414634 0.43658537        nan 0.42926829 0.42926829 0.43170732\n",
      " 0.43414634        nan 0.44390244 0.44390244 0.44390244 0.44390244\n",
      "        nan 0.44878049 0.44878049 0.44878049 0.44878049        nan\n",
      " 0.45365854 0.45365854 0.45365854 0.45365854        nan 0.45609756\n",
      " 0.45609756 0.45609756 0.45609756        nan 0.45609756 0.45609756\n",
      " 0.45609756 0.45609756        nan 0.43902439 0.43658537 0.43414634\n",
      " 0.43658537        nan 0.43658537 0.43658537 0.43414634 0.43658537\n",
      "        nan 0.42926829 0.42926829 0.43170732 0.43414634        nan\n",
      " 0.44390244 0.44390244 0.44390244 0.44390244        nan 0.44878049\n",
      " 0.44878049 0.44878049 0.44878049        nan 0.45365854 0.45365854\n",
      " 0.45365854 0.45365854        nan 0.45609756 0.45609756 0.45609756\n",
      " 0.45609756        nan 0.45609756 0.45609756 0.45609756 0.45609756\n",
      "        nan 0.43902439 0.43658537 0.43414634 0.43658537        nan\n",
      " 0.43658537 0.43658537 0.43414634 0.43658537        nan 0.42926829\n",
      " 0.42926829 0.43170732 0.43414634        nan 0.44390244 0.44390244\n",
      " 0.44390244 0.44390244        nan 0.44878049 0.44878049 0.44878049\n",
      " 0.44878049        nan 0.45365854 0.45365854 0.45365854 0.45365854\n",
      "        nan 0.45609756 0.45609756 0.45609756 0.45609756        nan\n",
      " 0.45609756 0.45609756 0.45609756 0.45609756        nan 0.43902439\n",
      " 0.43658537 0.43414634 0.43658537        nan 0.43658537 0.43658537\n",
      " 0.43414634 0.43658537        nan 0.42926829 0.42926829 0.43170732\n",
      " 0.43414634        nan 0.44390244 0.44390244 0.44390244 0.44390244\n",
      "        nan 0.44878049 0.44878049 0.44878049 0.44878049        nan\n",
      " 0.45365854 0.45365854 0.45365854 0.45365854        nan 0.45609756\n",
      " 0.45609756 0.45609756 0.45609756        nan 0.45609756 0.45609756\n",
      " 0.45609756 0.45609756        nan 0.43902439 0.43658537 0.43414634\n",
      " 0.43658537        nan 0.43658537 0.43658537 0.43414634 0.43658537\n",
      "        nan 0.42926829 0.42926829 0.43170732 0.43414634        nan\n",
      " 0.44390244 0.44390244 0.44390244 0.44390244        nan 0.44878049\n",
      " 0.44878049 0.44878049 0.44878049        nan 0.45365854 0.45365854\n",
      " 0.45365854 0.45365854        nan 0.45609756 0.45609756 0.45609756\n",
      " 0.45609756        nan 0.45609756 0.45609756 0.45609756 0.45609756\n",
      "        nan 0.43902439 0.43658537 0.43414634 0.43658537        nan\n",
      " 0.43658537 0.43658537 0.43414634 0.43658537        nan 0.42926829\n",
      " 0.42926829 0.43170732 0.43414634        nan 0.44390244 0.44390244\n",
      " 0.44390244 0.44390244        nan 0.44878049 0.44878049 0.44878049\n",
      " 0.44878049        nan 0.45365854 0.45365854 0.45365854 0.45365854\n",
      "        nan 0.45609756 0.45609756 0.45609756 0.45609756        nan\n",
      " 0.45609756 0.45609756 0.45609756 0.45609756        nan 0.43902439\n",
      " 0.43658537 0.43414634 0.43658537        nan 0.43658537 0.43658537\n",
      " 0.43414634 0.43658537        nan 0.42926829 0.42926829 0.43170732\n",
      " 0.43414634        nan 0.44390244 0.44390244 0.44390244 0.44390244\n",
      "        nan 0.44878049 0.44878049 0.44878049 0.44878049        nan\n",
      " 0.45365854 0.45365854 0.45365854 0.45365854        nan 0.45609756\n",
      " 0.45609756 0.45609756 0.45609756        nan 0.45609756 0.45609756\n",
      " 0.45609756 0.45609756        nan 0.43902439 0.43658537 0.43414634\n",
      " 0.43658537        nan 0.43658537 0.43658537 0.43414634 0.43658537\n",
      "        nan 0.42926829 0.42926829 0.43170732 0.43414634        nan\n",
      " 0.44390244 0.44390244 0.44390244 0.44390244        nan 0.44878049\n",
      " 0.44878049 0.44878049 0.44878049        nan 0.45365854 0.45365854\n",
      " 0.45365854 0.45365854        nan 0.45609756 0.45609756 0.45609756\n",
      " 0.45609756        nan 0.45609756 0.45609756 0.45609756 0.45609756\n",
      "        nan 0.43902439 0.43658537 0.43414634 0.43658537        nan\n",
      " 0.43658537 0.43658537 0.43414634 0.43658537        nan 0.42926829\n",
      " 0.42926829 0.43170732 0.43414634        nan 0.44390244 0.44390244\n",
      " 0.44390244 0.44390244        nan 0.44878049 0.44878049 0.44878049\n",
      " 0.44878049        nan 0.45365854 0.45365854 0.45365854 0.45365854\n",
      "        nan 0.45609756 0.45609756 0.45609756 0.45609756        nan\n",
      " 0.45609756 0.45609756 0.45609756 0.45609756]\n",
      "  warnings.warn(\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training:  0.4609756097560976\n",
      "2\n",
      "Fitting 5 folds for each of 640 candidates, totalling 3200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "640 fits failed out of a total of 3200.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "640 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan 0.36980322 0.36980322 0.36980322 0.36980322        nan\n",
      " 0.36980322 0.36980322 0.36980322 0.36980322        nan 0.36980322\n",
      " 0.36980322 0.36980322 0.36980322        nan 0.36980322 0.36980322\n",
      " 0.36980322 0.36980322        nan 0.36980322 0.36980322 0.36980322\n",
      " 0.36980322        nan 0.36980322 0.36980322 0.36980322 0.36980322\n",
      "        nan 0.36980322 0.36980322 0.36980322 0.36980322        nan\n",
      " 0.36980322 0.36980322 0.36980322 0.36980322        nan 0.3836613\n",
      " 0.3836613  0.3836613  0.3836613         nan 0.3836613  0.3836613\n",
      " 0.3836613  0.3836613         nan 0.3836613  0.3836613  0.3836613\n",
      " 0.3836613         nan 0.3836613  0.3836613  0.3836613  0.3836613\n",
      "        nan 0.3836613  0.3836613  0.3836613  0.3836613         nan\n",
      " 0.3836613  0.3836613  0.3836613  0.3836613         nan 0.3836613\n",
      " 0.3836613  0.3836613  0.3836613         nan 0.3836613  0.3836613\n",
      " 0.3836613  0.3836613         nan 0.39904592 0.39904592 0.39904592\n",
      " 0.39904592        nan 0.39904592 0.39904592 0.39904592 0.39904592\n",
      "        nan 0.39904592 0.39904592 0.39904592 0.39904592        nan\n",
      " 0.39904592 0.39904592 0.39904592 0.39904592        nan 0.39904592\n",
      " 0.39904592 0.39904592 0.39904592        nan 0.39904592 0.39904592\n",
      " 0.39904592 0.39904592        nan 0.39596899 0.39596899 0.39596899\n",
      " 0.39596899        nan 0.39289207 0.39289207 0.39289207 0.39289207\n",
      "        nan 0.4005963  0.4005963  0.4005963  0.4005963         nan\n",
      " 0.4005963  0.4005963  0.4005963  0.4005963         nan 0.4005963\n",
      " 0.4005963  0.4005963  0.4005963         nan 0.39904592 0.39904592\n",
      " 0.39904592 0.39904592        nan 0.39904592 0.39904592 0.39904592\n",
      " 0.39904592        nan 0.39904592 0.39904592 0.39904592 0.39904592\n",
      "        nan 0.39596899 0.39596899 0.39596899 0.39596899        nan\n",
      " 0.39444246 0.39444246 0.39444246 0.39444246        nan 0.39596899\n",
      " 0.39596899 0.39596899 0.39596899        nan 0.39443053 0.39443053\n",
      " 0.39443053 0.39443053        nan 0.39443053 0.39443053 0.39443053\n",
      " 0.39443053        nan 0.39750745 0.39750745 0.39750745 0.39750745\n",
      "        nan 0.39750745 0.39750745 0.39750745 0.39750745        nan\n",
      " 0.39596899 0.39596899 0.39596899 0.39596899        nan 0.39289207\n",
      " 0.39289207 0.39289207 0.39289207        nan 0.39136553 0.39136553\n",
      " 0.39136553 0.39136553        nan 0.3774836  0.3774836  0.37595707\n",
      " 0.37749553        nan 0.36975552 0.36975552 0.36822898 0.36976744\n",
      "        nan 0.36976744 0.36976744 0.36976744 0.36822898        nan\n",
      " 0.37901014 0.37901014 0.37901014 0.37901014        nan 0.3805486\n",
      " 0.3805486  0.3805486  0.3805486         nan 0.38519976 0.38519976\n",
      " 0.38519976 0.38519976        nan 0.38058438 0.38058438 0.38058438\n",
      " 0.38058438        nan 0.38367323 0.38367323 0.38367323 0.38367323\n",
      "        nan 0.38364937 0.38209899 0.37903399 0.37595707        nan\n",
      " 0.36667859 0.36667859 0.36515206 0.36669052        nan 0.36822898\n",
      " 0.36822898 0.36822898 0.36669052        nan 0.37901014 0.37901014\n",
      " 0.37901014 0.37901014        nan 0.3805486  0.3805486  0.3805486\n",
      " 0.3805486         nan 0.38519976 0.38519976 0.38519976 0.38519976\n",
      "        nan 0.38058438 0.38058438 0.38058438 0.38058438        nan\n",
      " 0.38367323 0.38367323 0.38367323 0.38367323        nan 0.38211091\n",
      " 0.38056052 0.37903399 0.37595707        nan 0.36360167 0.36360167\n",
      " 0.3636136  0.36669052        nan 0.36669052 0.36669052 0.36669052\n",
      " 0.36669052        nan 0.37901014 0.37901014 0.37901014 0.37901014\n",
      "        nan 0.3805486  0.3805486  0.3805486  0.3805486         nan\n",
      " 0.38519976 0.38519976 0.38519976 0.38519976        nan 0.38058438\n",
      " 0.38058438 0.38058438 0.38058438        nan 0.38367323 0.38367323\n",
      " 0.38367323 0.38367323        nan 0.37745975 0.3743709  0.37592129\n",
      " 0.3713059         nan 0.36360167 0.36360167 0.3636136  0.36669052\n",
      "        nan 0.36669052 0.36669052 0.36669052 0.36669052        nan\n",
      " 0.37901014 0.37901014 0.37901014 0.37901014        nan 0.3805486\n",
      " 0.3805486  0.3805486  0.3805486         nan 0.38519976 0.38519976\n",
      " 0.38519976 0.38519976        nan 0.38058438 0.38058438 0.38058438\n",
      " 0.38058438        nan 0.38367323 0.38367323 0.38367323 0.38367323\n",
      "        nan 0.37745975 0.3743709  0.37592129 0.3713059         nan\n",
      " 0.36360167 0.36360167 0.3636136  0.36669052        nan 0.36669052\n",
      " 0.36669052 0.36669052 0.36669052        nan 0.37901014 0.37901014\n",
      " 0.37901014 0.37901014        nan 0.3805486  0.3805486  0.3805486\n",
      " 0.3805486         nan 0.38519976 0.38519976 0.38519976 0.38519976\n",
      "        nan 0.38058438 0.38058438 0.38058438 0.38058438        nan\n",
      " 0.38367323 0.38367323 0.38367323 0.38367323        nan 0.37745975\n",
      " 0.3743709  0.37592129 0.3713059         nan 0.36360167 0.36360167\n",
      " 0.3636136  0.36669052        nan 0.36669052 0.36669052 0.36669052\n",
      " 0.36669052        nan 0.37901014 0.37901014 0.37901014 0.37901014\n",
      "        nan 0.3805486  0.3805486  0.3805486  0.3805486         nan\n",
      " 0.38519976 0.38519976 0.38519976 0.38519976        nan 0.38058438\n",
      " 0.38058438 0.38058438 0.38058438        nan 0.38367323 0.38367323\n",
      " 0.38367323 0.38367323        nan 0.37745975 0.3743709  0.37592129\n",
      " 0.3713059         nan 0.36360167 0.36360167 0.3636136  0.36669052\n",
      "        nan 0.36669052 0.36669052 0.36669052 0.36669052        nan\n",
      " 0.37901014 0.37901014 0.37901014 0.37901014        nan 0.3805486\n",
      " 0.3805486  0.3805486  0.3805486         nan 0.38519976 0.38519976\n",
      " 0.38519976 0.38519976        nan 0.38058438 0.38058438 0.38058438\n",
      " 0.38058438        nan 0.38367323 0.38367323 0.38367323 0.38367323\n",
      "        nan 0.37745975 0.3743709  0.37592129 0.3713059         nan\n",
      " 0.36360167 0.36360167 0.3636136  0.36669052        nan 0.36669052\n",
      " 0.36669052 0.36669052 0.36669052        nan 0.37901014 0.37901014\n",
      " 0.37901014 0.37901014        nan 0.3805486  0.3805486  0.3805486\n",
      " 0.3805486         nan 0.38519976 0.38519976 0.38519976 0.38519976\n",
      "        nan 0.38058438 0.38058438 0.38058438 0.38058438        nan\n",
      " 0.38367323 0.38367323 0.38367323 0.38367323        nan 0.37745975\n",
      " 0.3743709  0.37592129 0.3713059         nan 0.36360167 0.36360167\n",
      " 0.3636136  0.36669052        nan 0.36669052 0.36669052 0.36669052\n",
      " 0.36669052        nan 0.37901014 0.37901014 0.37901014 0.37901014\n",
      "        nan 0.3805486  0.3805486  0.3805486  0.3805486         nan\n",
      " 0.38519976 0.38519976 0.38519976 0.38519976        nan 0.38058438\n",
      " 0.38058438 0.38058438 0.38058438        nan 0.38367323 0.38367323\n",
      " 0.38367323 0.38367323        nan 0.37745975 0.3743709  0.37592129\n",
      " 0.3713059         nan 0.36360167 0.36360167 0.3636136  0.36669052\n",
      "        nan 0.36669052 0.36669052 0.36669052 0.36669052        nan\n",
      " 0.37901014 0.37901014 0.37901014 0.37901014        nan 0.3805486\n",
      " 0.3805486  0.3805486  0.3805486         nan 0.38519976 0.38519976\n",
      " 0.38519976 0.38519976        nan 0.38058438 0.38058438 0.38058438\n",
      " 0.38058438        nan 0.38367323 0.38367323 0.38367323 0.38367323\n",
      "        nan 0.37745975 0.3743709  0.37592129 0.3713059         nan\n",
      " 0.36360167 0.36360167 0.3636136  0.36669052        nan 0.36669052\n",
      " 0.36669052 0.36669052 0.36669052        nan 0.37901014 0.37901014\n",
      " 0.37901014 0.37901014        nan 0.3805486  0.3805486  0.3805486\n",
      " 0.3805486         nan 0.38519976 0.38519976 0.38519976 0.38519976\n",
      "        nan 0.38058438 0.38058438 0.38058438 0.38058438        nan\n",
      " 0.38367323 0.38367323 0.38367323 0.38367323]\n",
      "  warnings.warn(\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training:  0.41448382126348227\n",
      "3\n",
      "Fitting 5 folds for each of 640 candidates, totalling 3200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "640 fits failed out of a total of 3200.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "640 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan 0.34593301 0.34593301 0.34593301 0.34593301        nan\n",
      " 0.34593301 0.34593301 0.34593301 0.34593301        nan 0.34593301\n",
      " 0.34593301 0.34593301 0.34593301        nan 0.34593301 0.34593301\n",
      " 0.34593301 0.34593301        nan 0.34593301 0.34593301 0.34593301\n",
      " 0.34593301        nan 0.34593301 0.34593301 0.34593301 0.34593301\n",
      "        nan 0.34593301 0.34593301 0.34593301 0.34593301        nan\n",
      " 0.34593301 0.34593301 0.34593301 0.34593301        nan 0.32930052\n",
      " 0.32930052 0.32930052 0.32930052        nan 0.32930052 0.32930052\n",
      " 0.32930052 0.32930052        nan 0.32930052 0.32930052 0.32930052\n",
      " 0.32930052        nan 0.32930052 0.32930052 0.32930052 0.32930052\n",
      "        nan 0.32930052 0.32930052 0.32930052 0.32930052        nan\n",
      " 0.32930052 0.32930052 0.32930052 0.32930052        nan 0.32930052\n",
      " 0.32930052 0.32930052 0.32930052        nan 0.32930052 0.32930052\n",
      " 0.32930052 0.32930052        nan 0.33840283 0.33840283 0.33840283\n",
      " 0.33840283        nan 0.33840283 0.33840283 0.33840283 0.33840283\n",
      "        nan 0.33840283 0.33840283 0.33840283 0.33840283        nan\n",
      " 0.33990658 0.33990658 0.33990658 0.33990658        nan 0.33990658\n",
      " 0.33990658 0.33990658 0.33990658        nan 0.33990658 0.33990658\n",
      " 0.33990658 0.33990658        nan 0.34748234 0.34748234 0.34748234\n",
      " 0.34748234        nan 0.34748234 0.34748234 0.34748234 0.34748234\n",
      "        nan 0.33238779 0.33238779 0.33389155 0.3323764         nan\n",
      " 0.33692185 0.33692185 0.33692185 0.3354067         nan 0.3354067\n",
      " 0.3354067  0.3354067  0.3354067         nan 0.33238779 0.33238779\n",
      " 0.33238779 0.33238779        nan 0.33390294 0.33390294 0.33390294\n",
      " 0.33390294        nan 0.33390294 0.33390294 0.33390294 0.33390294\n",
      "        nan 0.33541809 0.33541809 0.33541809 0.33541809        nan\n",
      " 0.33541809 0.33541809 0.33541809 0.33541809        nan 0.32936888\n",
      " 0.32936888 0.32936888 0.32935748        nan 0.33239918 0.33239918\n",
      " 0.33089542 0.33088403        nan 0.32787651 0.32787651 0.32938027\n",
      " 0.32938027        nan 0.32786512 0.32786512 0.32786512 0.32786512\n",
      "        nan 0.32936888 0.32936888 0.32936888 0.32936888        nan\n",
      " 0.33391433 0.33391433 0.33391433 0.33391433        nan 0.33542948\n",
      " 0.33542948 0.33542948 0.33542948        nan 0.33542948 0.33542948\n",
      " 0.33542948 0.33542948        nan 0.32031214 0.31578947 0.31880838\n",
      " 0.32030075        nan 0.32787651 0.32787651 0.3278879  0.32637275\n",
      "        nan 0.32941445 0.32941445 0.32941445 0.33242196        nan\n",
      " 0.32484621 0.32484621 0.32484621 0.32484621        nan 0.32637275\n",
      " 0.32637275 0.32637275 0.32637275        nan 0.3278879  0.3278879\n",
      " 0.3278879  0.3278879         nan 0.32638414 0.32638414 0.32638414\n",
      " 0.32638414        nan 0.3278879  0.3278879  0.3278879  0.3278879\n",
      "        nan 0.3218273  0.31880838 0.31881978 0.32031214        nan\n",
      " 0.32940305 0.32940305 0.32791069 0.32940305        nan 0.32789929\n",
      " 0.32789929 0.32789929 0.33090681        nan 0.32334245 0.32334245\n",
      " 0.32334245 0.32334245        nan 0.32637275 0.32637275 0.32637275\n",
      " 0.32637275        nan 0.3278879  0.3278879  0.3278879  0.3278879\n",
      "        nan 0.32638414 0.32638414 0.32638414 0.32638414        nan\n",
      " 0.3278879  0.3278879  0.3278879  0.3278879         nan 0.3187856\n",
      " 0.31426293 0.31730463 0.31729323        nan 0.3278879  0.3278879\n",
      " 0.32789929 0.3278879         nan 0.32789929 0.32789929 0.32789929\n",
      " 0.33090681        nan 0.32334245 0.32334245 0.32334245 0.32334245\n",
      "        nan 0.32637275 0.32637275 0.32637275 0.32637275        nan\n",
      " 0.3278879  0.3278879  0.3278879  0.3278879         nan 0.32638414\n",
      " 0.32638414 0.32638414 0.32638414        nan 0.3278879  0.3278879\n",
      " 0.3278879  0.3278879         nan 0.32030075 0.31577808 0.31880838\n",
      " 0.31729323        nan 0.3278879  0.3278879  0.32789929 0.3278879\n",
      "        nan 0.32789929 0.32789929 0.32789929 0.33090681        nan\n",
      " 0.32334245 0.32334245 0.32334245 0.32334245        nan 0.32637275\n",
      " 0.32637275 0.32637275 0.32637275        nan 0.3278879  0.3278879\n",
      " 0.3278879  0.3278879         nan 0.32638414 0.32638414 0.32638414\n",
      " 0.32638414        nan 0.3278879  0.3278879  0.3278879  0.3278879\n",
      "        nan 0.32030075 0.31577808 0.31880838 0.31729323        nan\n",
      " 0.3278879  0.3278879  0.32789929 0.3278879         nan 0.32789929\n",
      " 0.32789929 0.32789929 0.33090681        nan 0.32334245 0.32334245\n",
      " 0.32334245 0.32334245        nan 0.32637275 0.32637275 0.32637275\n",
      " 0.32637275        nan 0.3278879  0.3278879  0.3278879  0.3278879\n",
      "        nan 0.32638414 0.32638414 0.32638414 0.32638414        nan\n",
      " 0.3278879  0.3278879  0.3278879  0.3278879         nan 0.32030075\n",
      " 0.31577808 0.31880838 0.31729323        nan 0.3278879  0.3278879\n",
      " 0.32789929 0.3278879         nan 0.32789929 0.32789929 0.32789929\n",
      " 0.33090681        nan 0.32334245 0.32334245 0.32334245 0.32334245\n",
      "        nan 0.32637275 0.32637275 0.32637275 0.32637275        nan\n",
      " 0.3278879  0.3278879  0.3278879  0.3278879         nan 0.32638414\n",
      " 0.32638414 0.32638414 0.32638414        nan 0.3278879  0.3278879\n",
      " 0.3278879  0.3278879         nan 0.32030075 0.31577808 0.31880838\n",
      " 0.31729323        nan 0.3278879  0.3278879  0.32789929 0.3278879\n",
      "        nan 0.32789929 0.32789929 0.32789929 0.33090681        nan\n",
      " 0.32334245 0.32334245 0.32334245 0.32334245        nan 0.32637275\n",
      " 0.32637275 0.32637275 0.32637275        nan 0.3278879  0.3278879\n",
      " 0.3278879  0.3278879         nan 0.32638414 0.32638414 0.32638414\n",
      " 0.32638414        nan 0.3278879  0.3278879  0.3278879  0.3278879\n",
      "        nan 0.32030075 0.31577808 0.31880838 0.31729323        nan\n",
      " 0.3278879  0.3278879  0.32789929 0.3278879         nan 0.32789929\n",
      " 0.32789929 0.32789929 0.33090681        nan 0.32334245 0.32334245\n",
      " 0.32334245 0.32334245        nan 0.32637275 0.32637275 0.32637275\n",
      " 0.32637275        nan 0.3278879  0.3278879  0.3278879  0.3278879\n",
      "        nan 0.32638414 0.32638414 0.32638414 0.32638414        nan\n",
      " 0.3278879  0.3278879  0.3278879  0.3278879         nan 0.32030075\n",
      " 0.31577808 0.31880838 0.31729323        nan 0.3278879  0.3278879\n",
      " 0.32789929 0.3278879         nan 0.32789929 0.32789929 0.32789929\n",
      " 0.33090681        nan 0.32334245 0.32334245 0.32334245 0.32334245\n",
      "        nan 0.32637275 0.32637275 0.32637275 0.32637275        nan\n",
      " 0.3278879  0.3278879  0.3278879  0.3278879         nan 0.32638414\n",
      " 0.32638414 0.32638414 0.32638414        nan 0.3278879  0.3278879\n",
      " 0.3278879  0.3278879         nan 0.32030075 0.31577808 0.31880838\n",
      " 0.31729323        nan 0.3278879  0.3278879  0.32789929 0.3278879\n",
      "        nan 0.32789929 0.32789929 0.32789929 0.33090681        nan\n",
      " 0.32334245 0.32334245 0.32334245 0.32334245        nan 0.32637275\n",
      " 0.32637275 0.32637275 0.32637275        nan 0.3278879  0.3278879\n",
      " 0.3278879  0.3278879         nan 0.32638414 0.32638414 0.32638414\n",
      " 0.32638414        nan 0.3278879  0.3278879  0.3278879  0.3278879\n",
      "        nan 0.32030075 0.31577808 0.31880838 0.31729323        nan\n",
      " 0.3278879  0.3278879  0.32789929 0.3278879         nan 0.32789929\n",
      " 0.32789929 0.32789929 0.33090681        nan 0.32334245 0.32334245\n",
      " 0.32334245 0.32334245        nan 0.32637275 0.32637275 0.32637275\n",
      " 0.32637275        nan 0.3278879  0.3278879  0.3278879  0.3278879\n",
      "        nan 0.32638414 0.32638414 0.32638414 0.32638414        nan\n",
      " 0.3278879  0.3278879  0.3278879  0.3278879 ]\n",
      "  warnings.warn(\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training:  0.36253776435045315\n",
      "4\n",
      "Fitting 5 folds for each of 640 candidates, totalling 3200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "640 fits failed out of a total of 3200.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "640 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan 0.32367646 0.32367646 0.32367646 0.32367646        nan\n",
      " 0.32367646 0.32367646 0.32367646 0.32367646        nan 0.32367646\n",
      " 0.32367646 0.32367646 0.32367646        nan 0.32367646 0.32367646\n",
      " 0.32367646 0.32367646        nan 0.32367646 0.32367646 0.32367646\n",
      " 0.32367646        nan 0.32367646 0.32367646 0.32367646 0.32367646\n",
      "        nan 0.32367646 0.32367646 0.32367646 0.32367646        nan\n",
      " 0.32367646 0.32367646 0.32367646 0.32367646        nan 0.32493432\n",
      " 0.32493432 0.32493432 0.32493432        nan 0.32493432 0.32493432\n",
      " 0.32493432 0.32493432        nan 0.32493432 0.32493432 0.32493432\n",
      " 0.32493432        nan 0.32493432 0.32493432 0.32493432 0.32493432\n",
      "        nan 0.32493432 0.32493432 0.32493432 0.32493432        nan\n",
      " 0.32493432 0.32493432 0.32493432 0.32493432        nan 0.32493432\n",
      " 0.32493432 0.32493432 0.32493432        nan 0.32493432 0.32493432\n",
      " 0.32493432 0.32493432        nan 0.31483958 0.31483958 0.31483958\n",
      " 0.31609744        nan 0.31609744 0.31609744 0.31609744 0.31735531\n",
      "        nan 0.31735531 0.31735531 0.31735531 0.31735531        nan\n",
      " 0.31861317 0.31861317 0.31861317 0.31861317        nan 0.31609744\n",
      " 0.31609744 0.31609744 0.31609744        nan 0.31609744 0.31609744\n",
      " 0.31609744 0.31609744        nan 0.31735531 0.31735531 0.31735531\n",
      " 0.31735531        nan 0.31987103 0.31987103 0.31987103 0.31987103\n",
      "        nan 0.32871587 0.32871587 0.327458   0.32871587        nan\n",
      " 0.32618422 0.32618422 0.32492636 0.32618422        nan 0.3236685\n",
      " 0.3236685  0.3236685  0.3236685         nan 0.32744208 0.32744208\n",
      " 0.32744208 0.32744208        nan 0.32365258 0.32365258 0.32365258\n",
      " 0.32365258        nan 0.31987103 0.31987103 0.31987103 0.31987103\n",
      "        nan 0.32112889 0.32112889 0.32112889 0.32112889        nan\n",
      " 0.31987103 0.31987103 0.31987103 0.31987103        nan 0.32243452\n",
      " 0.32243452 0.31990287 0.32367646        nan 0.31990287 0.31990287\n",
      " 0.31611337 0.31988695        nan 0.30980814 0.30980814 0.30980814\n",
      " 0.31483958        nan 0.31861317 0.31861317 0.31861317 0.31861317\n",
      "        nan 0.31229201 0.31229201 0.31229201 0.31229201        nan\n",
      " 0.31104211 0.31104211 0.31104211 0.31104211        nan 0.3135658\n",
      " 0.3135658  0.3135658  0.3135658         nan 0.31736327 0.31736327\n",
      " 0.31736327 0.31736327        nan 0.29849534 0.29723748 0.2985033\n",
      " 0.29720564        nan 0.29599554 0.29599554 0.29597962 0.29468195\n",
      "        nan 0.29853515 0.29853515 0.29853515 0.2997532         nan\n",
      " 0.30224504 0.30224504 0.30224504 0.30224504        nan 0.29972136\n",
      " 0.29972136 0.29972136 0.29972136        nan 0.2984635  0.2984635\n",
      " 0.2984635  0.2984635         nan 0.29720564 0.29720564 0.29720564\n",
      " 0.29720564        nan 0.30101107 0.30101107 0.30101107 0.30101107\n",
      "        nan 0.29849534 0.29723748 0.29472972 0.29343205        nan\n",
      " 0.29222196 0.29222196 0.29220603 0.29090837        nan 0.29601943\n",
      " 0.29601943 0.29476156 0.29597962        nan 0.29972932 0.29972932\n",
      " 0.29972932 0.29972932        nan 0.29720564 0.29720564 0.29720564\n",
      " 0.29720564        nan 0.29594777 0.29594777 0.29594777 0.29594777\n",
      "        nan 0.29343205 0.29343205 0.29343205 0.29343205        nan\n",
      " 0.29723748 0.29723748 0.29723748 0.29723748        nan 0.29849534\n",
      " 0.29723748 0.29472972 0.29217419        nan 0.29347982 0.29347982\n",
      " 0.29220603 0.29090837        nan 0.29727729 0.29727729 0.29853515\n",
      " 0.29723748        nan 0.30098718 0.30098718 0.30098718 0.30098718\n",
      "        nan 0.2984635  0.2984635  0.2984635  0.2984635         nan\n",
      " 0.29594777 0.29594777 0.29594777 0.29594777        nan 0.29343205\n",
      " 0.29343205 0.29343205 0.29343205        nan 0.29723748 0.29723748\n",
      " 0.29723748 0.29723748        nan 0.2997532  0.29723748 0.29598758\n",
      " 0.29343205        nan 0.29473768 0.29473768 0.2934639  0.29216623\n",
      "        nan 0.29727729 0.29727729 0.29853515 0.29597962        nan\n",
      " 0.30098718 0.30098718 0.30098718 0.30098718        nan 0.2984635\n",
      " 0.2984635  0.2984635  0.2984635         nan 0.29594777 0.29594777\n",
      " 0.29594777 0.29594777        nan 0.29343205 0.29343205 0.29343205\n",
      " 0.29343205        nan 0.29723748 0.29723748 0.29723748 0.29723748\n",
      "        nan 0.2997532  0.29723748 0.29598758 0.29343205        nan\n",
      " 0.29473768 0.29473768 0.2934639  0.29216623        nan 0.29727729\n",
      " 0.29727729 0.29853515 0.29597962        nan 0.30098718 0.30098718\n",
      " 0.30098718 0.30098718        nan 0.2984635  0.2984635  0.2984635\n",
      " 0.2984635         nan 0.29594777 0.29594777 0.29594777 0.29594777\n",
      "        nan 0.29343205 0.29343205 0.29343205 0.29343205        nan\n",
      " 0.29723748 0.29723748 0.29723748 0.29723748        nan 0.2997532\n",
      " 0.29723748 0.29598758 0.29343205        nan 0.29473768 0.29473768\n",
      " 0.2934639  0.29216623        nan 0.29727729 0.29727729 0.29853515\n",
      " 0.29597962        nan 0.30098718 0.30098718 0.30098718 0.30098718\n",
      "        nan 0.2984635  0.2984635  0.2984635  0.2984635         nan\n",
      " 0.29594777 0.29594777 0.29594777 0.29594777        nan 0.29343205\n",
      " 0.29343205 0.29343205 0.29343205        nan 0.29723748 0.29723748\n",
      " 0.29723748 0.29723748        nan 0.2997532  0.29723748 0.29598758\n",
      " 0.29343205        nan 0.29473768 0.29473768 0.2934639  0.29216623\n",
      "        nan 0.29727729 0.29727729 0.29853515 0.29597962        nan\n",
      " 0.30098718 0.30098718 0.30098718 0.30098718        nan 0.2984635\n",
      " 0.2984635  0.2984635  0.2984635         nan 0.29594777 0.29594777\n",
      " 0.29594777 0.29594777        nan 0.29343205 0.29343205 0.29343205\n",
      " 0.29343205        nan 0.29723748 0.29723748 0.29723748 0.29723748\n",
      "        nan 0.2997532  0.29723748 0.29598758 0.29343205        nan\n",
      " 0.29473768 0.29473768 0.2934639  0.29216623        nan 0.29727729\n",
      " 0.29727729 0.29853515 0.29597962        nan 0.30098718 0.30098718\n",
      " 0.30098718 0.30098718        nan 0.2984635  0.2984635  0.2984635\n",
      " 0.2984635         nan 0.29594777 0.29594777 0.29594777 0.29594777\n",
      "        nan 0.29343205 0.29343205 0.29343205 0.29343205        nan\n",
      " 0.29723748 0.29723748 0.29723748 0.29723748        nan 0.2997532\n",
      " 0.29723748 0.29598758 0.29343205        nan 0.29473768 0.29473768\n",
      " 0.2934639  0.29216623        nan 0.29727729 0.29727729 0.29853515\n",
      " 0.29597962        nan 0.30098718 0.30098718 0.30098718 0.30098718\n",
      "        nan 0.2984635  0.2984635  0.2984635  0.2984635         nan\n",
      " 0.29594777 0.29594777 0.29594777 0.29594777        nan 0.29343205\n",
      " 0.29343205 0.29343205 0.29343205        nan 0.29723748 0.29723748\n",
      " 0.29723748 0.29723748        nan 0.2997532  0.29723748 0.29598758\n",
      " 0.29343205        nan 0.29473768 0.29473768 0.2934639  0.29216623\n",
      "        nan 0.29727729 0.29727729 0.29853515 0.29597962        nan\n",
      " 0.30098718 0.30098718 0.30098718 0.30098718        nan 0.2984635\n",
      " 0.2984635  0.2984635  0.2984635         nan 0.29594777 0.29594777\n",
      " 0.29594777 0.29594777        nan 0.29343205 0.29343205 0.29343205\n",
      " 0.29343205        nan 0.29723748 0.29723748 0.29723748 0.29723748\n",
      "        nan 0.2997532  0.29723748 0.29598758 0.29343205        nan\n",
      " 0.29473768 0.29473768 0.2934639  0.29216623        nan 0.29727729\n",
      " 0.29727729 0.29853515 0.29597962        nan 0.30098718 0.30098718\n",
      " 0.30098718 0.30098718        nan 0.2984635  0.2984635  0.2984635\n",
      " 0.2984635         nan 0.29594777 0.29594777 0.29594777 0.29594777\n",
      "        nan 0.29343205 0.29343205 0.29343205 0.29343205        nan\n",
      " 0.29723748 0.29723748 0.29723748 0.29723748]\n",
      "  warnings.warn(\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training:  0.3501259445843829\n",
      "5\n",
      "Fitting 5 folds for each of 640 candidates, totalling 3200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "640 fits failed out of a total of 3200.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "640 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan 0.40502566 0.40502566 0.40502566 0.40502566        nan\n",
      " 0.40502566 0.40502566 0.40502566 0.40502566        nan 0.40502566\n",
      " 0.40502566 0.40502566 0.40502566        nan 0.40502566 0.40502566\n",
      " 0.40502566 0.40502566        nan 0.40502566 0.40502566 0.40502566\n",
      " 0.40502566        nan 0.40502566 0.40502566 0.40502566 0.40502566\n",
      "        nan 0.40502566 0.40502566 0.40502566 0.40502566        nan\n",
      " 0.40502566 0.40502566 0.40502566 0.40502566        nan 0.40620901\n",
      " 0.40620901 0.40620901 0.40620901        nan 0.40620901 0.40620901\n",
      " 0.40620901 0.40620901        nan 0.40620901 0.40620901 0.40620901\n",
      " 0.40620901        nan 0.40620901 0.40620901 0.40620901 0.40620901\n",
      "        nan 0.40620901 0.40620901 0.40620901 0.40620901        nan\n",
      " 0.40620901 0.40620901 0.40620901 0.40620901        nan 0.40382806\n",
      " 0.40382806 0.40382806 0.40382806        nan 0.40382806 0.40382806\n",
      " 0.40382806 0.40382806        nan 0.40267322 0.40267322 0.40267322\n",
      " 0.40267322        nan 0.40267322 0.40267322 0.40267322 0.40267322\n",
      "        nan 0.40148275 0.40148275 0.40148275 0.40267322        nan\n",
      " 0.40267322 0.40267322 0.40267322 0.40267322        nan 0.40267322\n",
      " 0.40267322 0.40267322 0.40267322        nan 0.40147562 0.40147562\n",
      " 0.40147562 0.40147562        nan 0.39430425 0.39430425 0.39430425\n",
      " 0.39430425        nan 0.39190904 0.39190904 0.39190904 0.39190904\n",
      "        nan 0.40384944 0.40265897 0.40385657 0.40385657        nan\n",
      " 0.40146136 0.40146136 0.40265897 0.40265897        nan 0.39907328\n",
      " 0.39907328 0.40027089 0.40146136        nan 0.40146136 0.40146136\n",
      " 0.40146136 0.40146136        nan 0.40146136 0.40146136 0.40146136\n",
      " 0.40146136        nan 0.40026376 0.40026376 0.40026376 0.40026376\n",
      "        nan 0.40746364 0.40746364 0.40746364 0.40746364        nan\n",
      " 0.40744939 0.40744939 0.40744939 0.40744939        nan 0.40026376\n",
      " 0.39907328 0.40027089 0.40027089        nan 0.39908754 0.39908754\n",
      " 0.4026661  0.4026661         nan 0.39788281 0.39788281 0.39908041\n",
      " 0.40027089        nan 0.39907328 0.39907328 0.39907328 0.39907328\n",
      "        nan 0.40506131 0.40506131 0.40506131 0.40506131        nan\n",
      " 0.4038637  0.4038637  0.4038637  0.4038637         nan 0.40268035\n",
      " 0.40268035 0.40268035 0.40268035        nan 0.39909467 0.39909467\n",
      " 0.39909467 0.39909467        nan 0.41937553 0.41578985 0.41579698\n",
      " 0.41579698        nan 0.41221842 0.41221842 0.41579698 0.41579698\n",
      "        nan 0.407428   0.407428   0.40862561 0.40981608        nan\n",
      " 0.4038637  0.4038637  0.4038637  0.4038637         nan 0.4038637\n",
      " 0.4038637  0.4038637  0.4038637         nan 0.40625178 0.40625178\n",
      " 0.40625178 0.40625178        nan 0.40147562 0.40147562 0.40147562\n",
      " 0.40147562        nan 0.39312803 0.39312803 0.39312803 0.39312803\n",
      "        nan 0.41339464 0.41100656 0.41101369 0.41221129        nan\n",
      " 0.41220416 0.41220416 0.41340177 0.41340177        nan 0.407428\n",
      " 0.407428   0.40862561 0.40981608        nan 0.4038637  0.4038637\n",
      " 0.4038637  0.4038637         nan 0.4038637  0.4038637  0.4038637\n",
      " 0.4038637         nan 0.40625178 0.40625178 0.40625178 0.40625178\n",
      "        nan 0.40147562 0.40147562 0.40147562 0.40147562        nan\n",
      " 0.39312803 0.39312803 0.39312803 0.39312803        nan 0.41578985\n",
      " 0.41340177 0.4134089  0.4134089         nan 0.41220416 0.41220416\n",
      " 0.41340177 0.41340177        nan 0.407428   0.407428   0.40862561\n",
      " 0.40981608        nan 0.4038637  0.4038637  0.4038637  0.4038637\n",
      "        nan 0.4038637  0.4038637  0.4038637  0.4038637         nan\n",
      " 0.40625178 0.40625178 0.40625178 0.40625178        nan 0.40147562\n",
      " 0.40147562 0.40147562 0.40147562        nan 0.39312803 0.39312803\n",
      " 0.39312803 0.39312803        nan 0.41339464 0.41220416 0.4134089\n",
      " 0.4134089         nan 0.41220416 0.41220416 0.41340177 0.41340177\n",
      "        nan 0.407428   0.407428   0.40862561 0.40981608        nan\n",
      " 0.4038637  0.4038637  0.4038637  0.4038637         nan 0.4038637\n",
      " 0.4038637  0.4038637  0.4038637         nan 0.40625178 0.40625178\n",
      " 0.40625178 0.40625178        nan 0.40147562 0.40147562 0.40147562\n",
      " 0.40147562        nan 0.39312803 0.39312803 0.39312803 0.39312803\n",
      "        nan 0.41459224 0.41220416 0.4134089  0.4134089         nan\n",
      " 0.41220416 0.41220416 0.41340177 0.41340177        nan 0.407428\n",
      " 0.407428   0.40862561 0.40981608        nan 0.4038637  0.4038637\n",
      " 0.4038637  0.4038637         nan 0.4038637  0.4038637  0.4038637\n",
      " 0.4038637         nan 0.40625178 0.40625178 0.40625178 0.40625178\n",
      "        nan 0.40147562 0.40147562 0.40147562 0.40147562        nan\n",
      " 0.39312803 0.39312803 0.39312803 0.39312803        nan 0.41459224\n",
      " 0.41220416 0.4134089  0.4134089         nan 0.41220416 0.41220416\n",
      " 0.41340177 0.41340177        nan 0.407428   0.407428   0.40862561\n",
      " 0.40981608        nan 0.4038637  0.4038637  0.4038637  0.4038637\n",
      "        nan 0.4038637  0.4038637  0.4038637  0.4038637         nan\n",
      " 0.40625178 0.40625178 0.40625178 0.40625178        nan 0.40147562\n",
      " 0.40147562 0.40147562 0.40147562        nan 0.39312803 0.39312803\n",
      " 0.39312803 0.39312803        nan 0.41459224 0.41220416 0.4134089\n",
      " 0.4134089         nan 0.41220416 0.41220416 0.41340177 0.41340177\n",
      "        nan 0.407428   0.407428   0.40862561 0.40981608        nan\n",
      " 0.4038637  0.4038637  0.4038637  0.4038637         nan 0.4038637\n",
      " 0.4038637  0.4038637  0.4038637         nan 0.40625178 0.40625178\n",
      " 0.40625178 0.40625178        nan 0.40147562 0.40147562 0.40147562\n",
      " 0.40147562        nan 0.39312803 0.39312803 0.39312803 0.39312803\n",
      "        nan 0.41459224 0.41220416 0.4134089  0.4134089         nan\n",
      " 0.41220416 0.41220416 0.41340177 0.41340177        nan 0.407428\n",
      " 0.407428   0.40862561 0.40981608        nan 0.4038637  0.4038637\n",
      " 0.4038637  0.4038637         nan 0.4038637  0.4038637  0.4038637\n",
      " 0.4038637         nan 0.40625178 0.40625178 0.40625178 0.40625178\n",
      "        nan 0.40147562 0.40147562 0.40147562 0.40147562        nan\n",
      " 0.39312803 0.39312803 0.39312803 0.39312803        nan 0.41459224\n",
      " 0.41220416 0.4134089  0.4134089         nan 0.41220416 0.41220416\n",
      " 0.41340177 0.41340177        nan 0.407428   0.407428   0.40862561\n",
      " 0.40981608        nan 0.4038637  0.4038637  0.4038637  0.4038637\n",
      "        nan 0.4038637  0.4038637  0.4038637  0.4038637         nan\n",
      " 0.40625178 0.40625178 0.40625178 0.40625178        nan 0.40147562\n",
      " 0.40147562 0.40147562 0.40147562        nan 0.39312803 0.39312803\n",
      " 0.39312803 0.39312803        nan 0.41459224 0.41220416 0.4134089\n",
      " 0.4134089         nan 0.41220416 0.41220416 0.41340177 0.41340177\n",
      "        nan 0.407428   0.407428   0.40862561 0.40981608        nan\n",
      " 0.4038637  0.4038637  0.4038637  0.4038637         nan 0.4038637\n",
      " 0.4038637  0.4038637  0.4038637         nan 0.40625178 0.40625178\n",
      " 0.40625178 0.40625178        nan 0.40147562 0.40147562 0.40147562\n",
      " 0.40147562        nan 0.39312803 0.39312803 0.39312803 0.39312803\n",
      "        nan 0.41459224 0.41220416 0.4134089  0.4134089         nan\n",
      " 0.41220416 0.41220416 0.41340177 0.41340177        nan 0.407428\n",
      " 0.407428   0.40862561 0.40981608        nan 0.4038637  0.4038637\n",
      " 0.4038637  0.4038637         nan 0.4038637  0.4038637  0.4038637\n",
      " 0.4038637         nan 0.40625178 0.40625178 0.40625178 0.40625178\n",
      "        nan 0.40147562 0.40147562 0.40147562 0.40147562        nan\n",
      " 0.39312803 0.39312803 0.39312803 0.39312803]\n",
      "  warnings.warn(\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training:  0.4731182795698925\n",
      "6\n",
      "Fitting 5 folds for each of 640 candidates, totalling 3200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "640 fits failed out of a total of 3200.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "640 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan 0.28994279 0.28994279 0.28994279 0.28994279        nan\n",
      " 0.28994279 0.28994279 0.28994279 0.28994279        nan 0.28994279\n",
      " 0.28994279 0.28994279 0.28994279        nan 0.28994279 0.28994279\n",
      " 0.28994279 0.28994279        nan 0.28994279 0.28994279 0.28994279\n",
      " 0.28994279        nan 0.28994279 0.28994279 0.28994279 0.28994279\n",
      "        nan 0.28994279 0.28994279 0.28994279 0.28994279        nan\n",
      " 0.28994279 0.28994279 0.28994279 0.28994279        nan 0.30719663\n",
      " 0.30719663 0.30719663 0.30719663        nan 0.30719663 0.30719663\n",
      " 0.30719663 0.30719663        nan 0.30719663 0.30719663 0.30719663\n",
      " 0.30719663        nan 0.30225836 0.30225836 0.30225836 0.30225836\n",
      "        nan 0.30469738 0.30469738 0.30469738 0.30469738        nan\n",
      " 0.30963565 0.30963565 0.30963565 0.30963565        nan 0.30963565\n",
      " 0.30963565 0.30963565 0.30963565        nan 0.31207468 0.31207468\n",
      " 0.31207468 0.31207468        nan 0.32186089 0.32186089 0.32926829\n",
      " 0.32926829        nan 0.32679916 0.32679916 0.32926829 0.32926829\n",
      "        nan 0.32926829 0.32926829 0.32926829 0.32926829        nan\n",
      " 0.32183077 0.32183077 0.32183077 0.32183077        nan 0.32429991\n",
      " 0.32429991 0.32429991 0.32429991        nan 0.32923818 0.32923818\n",
      " 0.32923818 0.32923818        nan 0.32676905 0.32676905 0.32676905\n",
      " 0.32676905        nan 0.33408612 0.33408612 0.33408612 0.33408612\n",
      "        nan 0.33167721 0.33414634 0.34152364 0.3390545         nan\n",
      " 0.35386932 0.35386932 0.35386932 0.35140018        nan 0.34155375\n",
      " 0.34155375 0.34402288 0.34402288        nan 0.32676905 0.32676905\n",
      " 0.32676905 0.32676905        nan 0.33167721 0.33167721 0.33167721\n",
      " 0.33167721        nan 0.33661548 0.33661548 0.33661548 0.33661548\n",
      "        nan 0.33414634 0.33414634 0.33414634 0.33414634        nan\n",
      " 0.32429991 0.32429991 0.32429991 0.32429991        nan 0.3390545\n",
      " 0.3390545  0.3464318  0.34890093        nan 0.34890093 0.34890093\n",
      " 0.34890093 0.35383921        nan 0.3390545  0.3390545  0.34152364\n",
      " 0.34152364        nan 0.32183077 0.32183077 0.32183077 0.32183077\n",
      "        nan 0.32923818 0.32923818 0.32923818 0.32923818        nan\n",
      " 0.3390545  0.3390545  0.3390545  0.3390545         nan 0.34149353\n",
      " 0.34149353 0.34149353 0.34149353        nan 0.33652514 0.33652514\n",
      " 0.33652514 0.33652514        nan 0.34890093 0.3464318  0.36856369\n",
      " 0.35627823        nan 0.35377898 0.35377898 0.36115628 0.35624812\n",
      "        nan 0.34884071 0.34884071 0.35130985 0.34640169        nan\n",
      " 0.32420958 0.32420958 0.32420958 0.32420958        nan 0.32917796\n",
      " 0.32917796 0.32917796 0.32917796        nan 0.34399277 0.34399277\n",
      " 0.34399277 0.34399277        nan 0.3464318  0.3464318  0.3464318\n",
      " 0.3464318         nan 0.33405601 0.33405601 0.33405601 0.33405601\n",
      "        nan 0.35140018 0.34893104 0.37597109 0.35874737        nan\n",
      " 0.36118639 0.36118639 0.37103282 0.36118639        nan 0.35377898\n",
      " 0.35377898 0.35624812 0.35133996        nan 0.32420958 0.32420958\n",
      " 0.32420958 0.32420958        nan 0.32917796 0.32917796 0.32917796\n",
      " 0.32917796        nan 0.34399277 0.34399277 0.34399277 0.34399277\n",
      "        nan 0.3464318  0.3464318  0.3464318  0.3464318         nan\n",
      " 0.33405601 0.33405601 0.33405601 0.33405601        nan 0.34646191\n",
      " 0.34399277 0.37103282 0.35874737        nan 0.35624812 0.35624812\n",
      " 0.36856369 0.36365553        nan 0.35377898 0.35377898 0.35624812\n",
      " 0.35133996        nan 0.32420958 0.32420958 0.32420958 0.32420958\n",
      "        nan 0.32917796 0.32917796 0.32917796 0.32917796        nan\n",
      " 0.34399277 0.34399277 0.34399277 0.34399277        nan 0.3464318\n",
      " 0.3464318  0.3464318  0.3464318         nan 0.33405601 0.33405601\n",
      " 0.33405601 0.33405601        nan 0.34893104 0.34646191 0.37103282\n",
      " 0.35874737        nan 0.35871725 0.35871725 0.36856369 0.36365553\n",
      "        nan 0.35377898 0.35377898 0.35624812 0.35133996        nan\n",
      " 0.32420958 0.32420958 0.32420958 0.32420958        nan 0.32917796\n",
      " 0.32917796 0.32917796 0.32917796        nan 0.34399277 0.34399277\n",
      " 0.34399277 0.34399277        nan 0.3464318  0.3464318  0.3464318\n",
      " 0.3464318         nan 0.33405601 0.33405601 0.33405601 0.33405601\n",
      "        nan 0.34893104 0.34646191 0.37103282 0.35874737        nan\n",
      " 0.35871725 0.35871725 0.36856369 0.36365553        nan 0.35377898\n",
      " 0.35377898 0.35624812 0.35133996        nan 0.32420958 0.32420958\n",
      " 0.32420958 0.32420958        nan 0.32917796 0.32917796 0.32917796\n",
      " 0.32917796        nan 0.34399277 0.34399277 0.34399277 0.34399277\n",
      "        nan 0.3464318  0.3464318  0.3464318  0.3464318         nan\n",
      " 0.33405601 0.33405601 0.33405601 0.33405601        nan 0.34893104\n",
      " 0.34646191 0.37103282 0.35874737        nan 0.35871725 0.35871725\n",
      " 0.36856369 0.36365553        nan 0.35377898 0.35377898 0.35624812\n",
      " 0.35133996        nan 0.32420958 0.32420958 0.32420958 0.32420958\n",
      "        nan 0.32917796 0.32917796 0.32917796 0.32917796        nan\n",
      " 0.34399277 0.34399277 0.34399277 0.34399277        nan 0.3464318\n",
      " 0.3464318  0.3464318  0.3464318         nan 0.33405601 0.33405601\n",
      " 0.33405601 0.33405601        nan 0.34893104 0.34646191 0.37103282\n",
      " 0.35874737        nan 0.35871725 0.35871725 0.36856369 0.36365553\n",
      "        nan 0.35377898 0.35377898 0.35624812 0.35133996        nan\n",
      " 0.32420958 0.32420958 0.32420958 0.32420958        nan 0.32917796\n",
      " 0.32917796 0.32917796 0.32917796        nan 0.34399277 0.34399277\n",
      " 0.34399277 0.34399277        nan 0.3464318  0.3464318  0.3464318\n",
      " 0.3464318         nan 0.33405601 0.33405601 0.33405601 0.33405601\n",
      "        nan 0.34893104 0.34646191 0.37103282 0.35874737        nan\n",
      " 0.35871725 0.35871725 0.36856369 0.36365553        nan 0.35377898\n",
      " 0.35377898 0.35624812 0.35133996        nan 0.32420958 0.32420958\n",
      " 0.32420958 0.32420958        nan 0.32917796 0.32917796 0.32917796\n",
      " 0.32917796        nan 0.34399277 0.34399277 0.34399277 0.34399277\n",
      "        nan 0.3464318  0.3464318  0.3464318  0.3464318         nan\n",
      " 0.33405601 0.33405601 0.33405601 0.33405601        nan 0.34893104\n",
      " 0.34646191 0.37103282 0.35874737        nan 0.35871725 0.35871725\n",
      " 0.36856369 0.36365553        nan 0.35377898 0.35377898 0.35624812\n",
      " 0.35133996        nan 0.32420958 0.32420958 0.32420958 0.32420958\n",
      "        nan 0.32917796 0.32917796 0.32917796 0.32917796        nan\n",
      " 0.34399277 0.34399277 0.34399277 0.34399277        nan 0.3464318\n",
      " 0.3464318  0.3464318  0.3464318         nan 0.33405601 0.33405601\n",
      " 0.33405601 0.33405601        nan 0.34893104 0.34646191 0.37103282\n",
      " 0.35874737        nan 0.35871725 0.35871725 0.36856369 0.36365553\n",
      "        nan 0.35377898 0.35377898 0.35624812 0.35133996        nan\n",
      " 0.32420958 0.32420958 0.32420958 0.32420958        nan 0.32917796\n",
      " 0.32917796 0.32917796 0.32917796        nan 0.34399277 0.34399277\n",
      " 0.34399277 0.34399277        nan 0.3464318  0.3464318  0.3464318\n",
      " 0.3464318         nan 0.33405601 0.33405601 0.33405601 0.33405601\n",
      "        nan 0.34893104 0.34646191 0.37103282 0.35874737        nan\n",
      " 0.35871725 0.35871725 0.36856369 0.36365553        nan 0.35377898\n",
      " 0.35377898 0.35624812 0.35133996        nan 0.32420958 0.32420958\n",
      " 0.32420958 0.32420958        nan 0.32917796 0.32917796 0.32917796\n",
      " 0.32917796        nan 0.34399277 0.34399277 0.34399277 0.34399277\n",
      "        nan 0.3464318  0.3464318  0.3464318  0.3464318         nan\n",
      " 0.33405601 0.33405601 0.33405601 0.33405601]\n",
      "  warnings.warn(\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training:  0.44226044226044225\n",
      "7\n",
      "Fitting 5 folds for each of 640 candidates, totalling 3200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "640 fits failed out of a total of 3200.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "640 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan 0.37517386 0.37517386 0.37517386 0.37517386        nan\n",
      " 0.37517386 0.37517386 0.37517386 0.37517386        nan 0.37517386\n",
      " 0.37517386 0.37517386 0.37517386        nan 0.37517386 0.37517386\n",
      " 0.37517386 0.37517386        nan 0.37517386 0.37517386 0.37517386\n",
      " 0.37517386        nan 0.37517386 0.37517386 0.37517386 0.37517386\n",
      "        nan 0.37517386 0.37517386 0.37517386 0.37517386        nan\n",
      " 0.37517386 0.37517386 0.37517386 0.37517386        nan 0.39453708\n",
      " 0.39453708 0.39453708 0.39453708        nan 0.39453708 0.39453708\n",
      " 0.39453708 0.39453708        nan 0.39453708 0.39453708 0.39453708\n",
      " 0.39453708        nan 0.3971261  0.3971261  0.3971261  0.3971261\n",
      "        nan 0.3971261  0.3971261  0.3971261  0.3971261         nan\n",
      " 0.3971261  0.3971261  0.3971261  0.3971261         nan 0.3971261\n",
      " 0.3971261  0.3971261  0.3971261         nan 0.3971261  0.3971261\n",
      " 0.3971261  0.3971261         nan 0.39064097 0.39064097 0.39064097\n",
      " 0.39064097        nan 0.39064097 0.39064097 0.39064097 0.39064097\n",
      "        nan 0.39064097 0.39064097 0.39064097 0.39064097        nan\n",
      " 0.38935065 0.38935065 0.38935065 0.38935065        nan 0.38805195\n",
      " 0.38805195 0.38805195 0.38805195        nan 0.38676163 0.38676163\n",
      " 0.38676163 0.38676163        nan 0.38285714 0.38285714 0.38285714\n",
      " 0.38285714        nan 0.38285714 0.38285714 0.38285714 0.38285714\n",
      "        nan 0.37642229 0.37642229 0.37642229 0.37512359        nan\n",
      " 0.37512359 0.37512359 0.37512359 0.37512359        nan 0.37642229\n",
      " 0.37642229 0.37642229 0.37642229        nan 0.36864684 0.36864684\n",
      " 0.36864684 0.36864684        nan 0.36604943 0.36604943 0.36604943\n",
      " 0.36604943        nan 0.36863008 0.36863008 0.36863008 0.36863008\n",
      "        nan 0.36992878 0.36992878 0.36992878 0.36992878        nan\n",
      " 0.36992878 0.36992878 0.36992878 0.36992878        nan 0.39844156\n",
      " 0.39844156 0.39715124 0.39585253        nan 0.39195643 0.39195643\n",
      " 0.39195643 0.39195643        nan 0.39455383 0.39455383 0.39455383\n",
      " 0.39455383        nan 0.38937579 0.38937579 0.38937579 0.38937579\n",
      "        nan 0.38548806 0.38548806 0.38548806 0.38548806        nan\n",
      " 0.38677838 0.38677838 0.38677838 0.38677838        nan 0.39067449\n",
      " 0.39067449 0.39067449 0.39067449        nan 0.39067449 0.39067449\n",
      " 0.39067449 0.39067449        nan 0.37907834 0.37907834 0.38037704\n",
      " 0.38166736        nan 0.37778802 0.37778802 0.38037704 0.38296607\n",
      "        nan 0.39329703 0.39329703 0.39458735 0.39587767        nan\n",
      " 0.39196481 0.39196481 0.39196481 0.39196481        nan 0.38937579\n",
      " 0.38937579 0.38937579 0.38937579        nan 0.38677838 0.38677838\n",
      " 0.38677838 0.38677838        nan 0.39327189 0.39327189 0.39327189\n",
      " 0.39327189        nan 0.39197319 0.39197319 0.39197319 0.39197319\n",
      "        nan 0.38165061 0.38165061 0.38424801 0.38813574        nan\n",
      " 0.38168412 0.38168412 0.38037704 0.38556347        nan 0.39329703\n",
      " 0.39329703 0.39458735 0.39587767        nan 0.39196481 0.39196481\n",
      " 0.39196481 0.39196481        nan 0.38937579 0.38937579 0.38937579\n",
      " 0.38937579        nan 0.38677838 0.38677838 0.38677838 0.38677838\n",
      "        nan 0.39327189 0.39327189 0.39327189 0.39327189        nan\n",
      " 0.39197319 0.39197319 0.39197319 0.39197319        nan 0.38424801\n",
      " 0.38424801 0.38684541 0.38813574        nan 0.38168412 0.38168412\n",
      " 0.38297444 0.38556347        nan 0.39329703 0.39329703 0.39458735\n",
      " 0.39587767        nan 0.39196481 0.39196481 0.39196481 0.39196481\n",
      "        nan 0.38937579 0.38937579 0.38937579 0.38937579        nan\n",
      " 0.38677838 0.38677838 0.38677838 0.38677838        nan 0.39327189\n",
      " 0.39327189 0.39327189 0.39327189        nan 0.39197319 0.39197319\n",
      " 0.39197319 0.39197319        nan 0.38424801 0.38424801 0.38684541\n",
      " 0.38813574        nan 0.38168412 0.38168412 0.38297444 0.38556347\n",
      "        nan 0.39329703 0.39329703 0.39458735 0.39587767        nan\n",
      " 0.39196481 0.39196481 0.39196481 0.39196481        nan 0.38937579\n",
      " 0.38937579 0.38937579 0.38937579        nan 0.38677838 0.38677838\n",
      " 0.38677838 0.38677838        nan 0.39327189 0.39327189 0.39327189\n",
      " 0.39327189        nan 0.39197319 0.39197319 0.39197319 0.39197319\n",
      "        nan 0.38424801 0.38424801 0.38684541 0.38813574        nan\n",
      " 0.38168412 0.38168412 0.38297444 0.38556347        nan 0.39329703\n",
      " 0.39329703 0.39458735 0.39587767        nan 0.39196481 0.39196481\n",
      " 0.39196481 0.39196481        nan 0.38937579 0.38937579 0.38937579\n",
      " 0.38937579        nan 0.38677838 0.38677838 0.38677838 0.38677838\n",
      "        nan 0.39327189 0.39327189 0.39327189 0.39327189        nan\n",
      " 0.39197319 0.39197319 0.39197319 0.39197319        nan 0.38424801\n",
      " 0.38424801 0.38684541 0.38813574        nan 0.38168412 0.38168412\n",
      " 0.38297444 0.38556347        nan 0.39329703 0.39329703 0.39458735\n",
      " 0.39587767        nan 0.39196481 0.39196481 0.39196481 0.39196481\n",
      "        nan 0.38937579 0.38937579 0.38937579 0.38937579        nan\n",
      " 0.38677838 0.38677838 0.38677838 0.38677838        nan 0.39327189\n",
      " 0.39327189 0.39327189 0.39327189        nan 0.39197319 0.39197319\n",
      " 0.39197319 0.39197319        nan 0.38424801 0.38424801 0.38684541\n",
      " 0.38813574        nan 0.38168412 0.38168412 0.38297444 0.38556347\n",
      "        nan 0.39329703 0.39329703 0.39458735 0.39587767        nan\n",
      " 0.39196481 0.39196481 0.39196481 0.39196481        nan 0.38937579\n",
      " 0.38937579 0.38937579 0.38937579        nan 0.38677838 0.38677838\n",
      " 0.38677838 0.38677838        nan 0.39327189 0.39327189 0.39327189\n",
      " 0.39327189        nan 0.39197319 0.39197319 0.39197319 0.39197319\n",
      "        nan 0.38424801 0.38424801 0.38684541 0.38813574        nan\n",
      " 0.38168412 0.38168412 0.38297444 0.38556347        nan 0.39329703\n",
      " 0.39329703 0.39458735 0.39587767        nan 0.39196481 0.39196481\n",
      " 0.39196481 0.39196481        nan 0.38937579 0.38937579 0.38937579\n",
      " 0.38937579        nan 0.38677838 0.38677838 0.38677838 0.38677838\n",
      "        nan 0.39327189 0.39327189 0.39327189 0.39327189        nan\n",
      " 0.39197319 0.39197319 0.39197319 0.39197319        nan 0.38424801\n",
      " 0.38424801 0.38684541 0.38813574        nan 0.38168412 0.38168412\n",
      " 0.38297444 0.38556347        nan 0.39329703 0.39329703 0.39458735\n",
      " 0.39587767        nan 0.39196481 0.39196481 0.39196481 0.39196481\n",
      "        nan 0.38937579 0.38937579 0.38937579 0.38937579        nan\n",
      " 0.38677838 0.38677838 0.38677838 0.38677838        nan 0.39327189\n",
      " 0.39327189 0.39327189 0.39327189        nan 0.39197319 0.39197319\n",
      " 0.39197319 0.39197319        nan 0.38424801 0.38424801 0.38684541\n",
      " 0.38813574        nan 0.38168412 0.38168412 0.38297444 0.38556347\n",
      "        nan 0.39329703 0.39329703 0.39458735 0.39587767        nan\n",
      " 0.39196481 0.39196481 0.39196481 0.39196481        nan 0.38937579\n",
      " 0.38937579 0.38937579 0.38937579        nan 0.38677838 0.38677838\n",
      " 0.38677838 0.38677838        nan 0.39327189 0.39327189 0.39327189\n",
      " 0.39327189        nan 0.39197319 0.39197319 0.39197319 0.39197319\n",
      "        nan 0.38424801 0.38424801 0.38684541 0.38813574        nan\n",
      " 0.38168412 0.38168412 0.38297444 0.38556347        nan 0.39329703\n",
      " 0.39329703 0.39458735 0.39587767        nan 0.39196481 0.39196481\n",
      " 0.39196481 0.39196481        nan 0.38937579 0.38937579 0.38937579\n",
      " 0.38937579        nan 0.38677838 0.38677838 0.38677838 0.38677838\n",
      "        nan 0.39327189 0.39327189 0.39327189 0.39327189        nan\n",
      " 0.39197319 0.39197319 0.39197319 0.39197319]\n",
      "  warnings.warn(\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training:  0.4320827943078913\n",
      "8\n",
      "Fitting 5 folds for each of 640 candidates, totalling 3200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "640 fits failed out of a total of 3200.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "640 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan 0.34046847 0.34046847 0.34046847 0.34046847        nan\n",
      " 0.34046847 0.34046847 0.34046847 0.34046847        nan 0.34046847\n",
      " 0.34046847 0.34046847 0.34046847        nan 0.34046847 0.34046847\n",
      " 0.34046847 0.34046847        nan 0.34046847 0.34046847 0.34046847\n",
      " 0.34046847        nan 0.34046847 0.34046847 0.34046847 0.34046847\n",
      "        nan 0.34046847 0.34046847 0.34046847 0.34046847        nan\n",
      " 0.34046847 0.34046847 0.34046847 0.34046847        nan 0.3110991\n",
      " 0.3110991  0.3110991  0.3110991         nan 0.3110991  0.3110991\n",
      " 0.3110991  0.3110991         nan 0.3110991  0.3110991  0.3110991\n",
      " 0.3110991         nan 0.3110991  0.3110991  0.3110991  0.3110991\n",
      "        nan 0.3110991  0.3110991  0.3110991  0.3110991         nan\n",
      " 0.3110991  0.3110991  0.3110991  0.3110991         nan 0.3110991\n",
      " 0.3110991  0.3110991  0.3110991         nan 0.3110991  0.3110991\n",
      " 0.3110991  0.3110991         nan 0.31675676 0.31675676 0.31675676\n",
      " 0.31675676        nan 0.31138739 0.31138739 0.31138739 0.31405405\n",
      "        nan 0.31405405 0.31405405 0.31405405 0.31672072        nan\n",
      " 0.32479279 0.32479279 0.32479279 0.32479279        nan 0.32479279\n",
      " 0.32479279 0.32479279 0.32479279        nan 0.32479279 0.32479279\n",
      " 0.32479279 0.32479279        nan 0.32479279 0.32479279 0.32479279\n",
      " 0.32479279        nan 0.32745946 0.32745946 0.32745946 0.32745946\n",
      "        nan 0.33545946 0.33545946 0.33275676 0.32738739        nan\n",
      " 0.32742342 0.32742342 0.32472072 0.32201802        nan 0.32738739\n",
      " 0.32738739 0.32738739 0.32468468        nan 0.34082883 0.34082883\n",
      " 0.34082883 0.34082883        nan 0.32742342 0.32742342 0.32742342\n",
      " 0.32742342        nan 0.32742342 0.32742342 0.32742342 0.32742342\n",
      "        nan 0.32742342 0.32742342 0.32742342 0.32742342        nan\n",
      " 0.33275676 0.33275676 0.33275676 0.33275676        nan 0.32745946\n",
      " 0.32745946 0.33279279 0.32475676        nan 0.33016216 0.33016216\n",
      " 0.32472072 0.31935135        nan 0.33012613 0.33012613 0.32472072\n",
      " 0.32201802        nan 0.3461982  0.3461982  0.3461982  0.3461982\n",
      "        nan 0.34886486 0.34886486 0.34886486 0.34886486        nan\n",
      " 0.34886486 0.34886486 0.34886486 0.34886486        nan 0.3489009\n",
      " 0.3489009  0.3489009  0.3489009         nan 0.3461982  0.3461982\n",
      " 0.3461982  0.3461982         nan 0.34630631 0.34904505 0.34363964\n",
      " 0.33556757        nan 0.35178378 0.35178378 0.34100901 0.33023423\n",
      "        nan 0.35441441 0.35441441 0.34900901 0.34356757        nan\n",
      " 0.35697297 0.35697297 0.35697297 0.35697297        nan 0.35427027\n",
      " 0.35427027 0.35427027 0.35427027        nan 0.3489009  0.3489009\n",
      " 0.3489009  0.3489009         nan 0.34893694 0.34893694 0.34893694\n",
      " 0.34893694        nan 0.3409009  0.3409009  0.3409009  0.3409009\n",
      "        nan 0.34897297 0.35171171 0.34630631 0.33823423        nan\n",
      " 0.35978378 0.35978378 0.35167568 0.3409009         nan 0.35174775\n",
      " 0.35174775 0.34634234 0.3409009         nan 0.35697297 0.35697297\n",
      " 0.35697297 0.35697297        nan 0.35427027 0.35427027 0.35427027\n",
      " 0.35427027        nan 0.3489009  0.3489009  0.3489009  0.3489009\n",
      "        nan 0.34893694 0.34893694 0.34893694 0.34893694        nan\n",
      " 0.3409009  0.3409009  0.3409009  0.3409009         nan 0.34363964\n",
      " 0.35171171 0.34097297 0.33556757        nan 0.35445045 0.35445045\n",
      " 0.34634234 0.33556757        nan 0.35174775 0.35174775 0.34634234\n",
      " 0.3409009         nan 0.35697297 0.35697297 0.35697297 0.35697297\n",
      "        nan 0.35427027 0.35427027 0.35427027 0.35427027        nan\n",
      " 0.3489009  0.3489009  0.3489009  0.3489009         nan 0.34893694\n",
      " 0.34893694 0.34893694 0.34893694        nan 0.3409009  0.3409009\n",
      " 0.3409009  0.3409009         nan 0.34630631 0.35437838 0.34097297\n",
      " 0.33556757        nan 0.35711712 0.35711712 0.34634234 0.33556757\n",
      "        nan 0.35441441 0.35441441 0.34634234 0.3409009         nan\n",
      " 0.35697297 0.35697297 0.35697297 0.35697297        nan 0.35427027\n",
      " 0.35427027 0.35427027 0.35427027        nan 0.3489009  0.3489009\n",
      " 0.3489009  0.3489009         nan 0.34893694 0.34893694 0.34893694\n",
      " 0.34893694        nan 0.3409009  0.3409009  0.3409009  0.3409009\n",
      "        nan 0.34630631 0.35437838 0.34097297 0.33556757        nan\n",
      " 0.35711712 0.35711712 0.34634234 0.33556757        nan 0.35441441\n",
      " 0.35441441 0.34634234 0.3409009         nan 0.35697297 0.35697297\n",
      " 0.35697297 0.35697297        nan 0.35427027 0.35427027 0.35427027\n",
      " 0.35427027        nan 0.3489009  0.3489009  0.3489009  0.3489009\n",
      "        nan 0.34893694 0.34893694 0.34893694 0.34893694        nan\n",
      " 0.3409009  0.3409009  0.3409009  0.3409009         nan 0.34630631\n",
      " 0.35437838 0.34097297 0.33556757        nan 0.35711712 0.35711712\n",
      " 0.34634234 0.33556757        nan 0.35441441 0.35441441 0.34634234\n",
      " 0.3409009         nan 0.35697297 0.35697297 0.35697297 0.35697297\n",
      "        nan 0.35427027 0.35427027 0.35427027 0.35427027        nan\n",
      " 0.3489009  0.3489009  0.3489009  0.3489009         nan 0.34893694\n",
      " 0.34893694 0.34893694 0.34893694        nan 0.3409009  0.3409009\n",
      " 0.3409009  0.3409009         nan 0.34630631 0.35437838 0.34097297\n",
      " 0.33556757        nan 0.35711712 0.35711712 0.34634234 0.33556757\n",
      "        nan 0.35441441 0.35441441 0.34634234 0.3409009         nan\n",
      " 0.35697297 0.35697297 0.35697297 0.35697297        nan 0.35427027\n",
      " 0.35427027 0.35427027 0.35427027        nan 0.3489009  0.3489009\n",
      " 0.3489009  0.3489009         nan 0.34893694 0.34893694 0.34893694\n",
      " 0.34893694        nan 0.3409009  0.3409009  0.3409009  0.3409009\n",
      "        nan 0.34630631 0.35437838 0.34097297 0.33556757        nan\n",
      " 0.35711712 0.35711712 0.34634234 0.33556757        nan 0.35441441\n",
      " 0.35441441 0.34634234 0.3409009         nan 0.35697297 0.35697297\n",
      " 0.35697297 0.35697297        nan 0.35427027 0.35427027 0.35427027\n",
      " 0.35427027        nan 0.3489009  0.3489009  0.3489009  0.3489009\n",
      "        nan 0.34893694 0.34893694 0.34893694 0.34893694        nan\n",
      " 0.3409009  0.3409009  0.3409009  0.3409009         nan 0.34630631\n",
      " 0.35437838 0.34097297 0.33556757        nan 0.35711712 0.35711712\n",
      " 0.34634234 0.33556757        nan 0.35441441 0.35441441 0.34634234\n",
      " 0.3409009         nan 0.35697297 0.35697297 0.35697297 0.35697297\n",
      "        nan 0.35427027 0.35427027 0.35427027 0.35427027        nan\n",
      " 0.3489009  0.3489009  0.3489009  0.3489009         nan 0.34893694\n",
      " 0.34893694 0.34893694 0.34893694        nan 0.3409009  0.3409009\n",
      " 0.3409009  0.3409009         nan 0.34630631 0.35437838 0.34097297\n",
      " 0.33556757        nan 0.35711712 0.35711712 0.34634234 0.33556757\n",
      "        nan 0.35441441 0.35441441 0.34634234 0.3409009         nan\n",
      " 0.35697297 0.35697297 0.35697297 0.35697297        nan 0.35427027\n",
      " 0.35427027 0.35427027 0.35427027        nan 0.3489009  0.3489009\n",
      " 0.3489009  0.3489009         nan 0.34893694 0.34893694 0.34893694\n",
      " 0.34893694        nan 0.3409009  0.3409009  0.3409009  0.3409009\n",
      "        nan 0.34630631 0.35437838 0.34097297 0.33556757        nan\n",
      " 0.35711712 0.35711712 0.34634234 0.33556757        nan 0.35441441\n",
      " 0.35441441 0.34634234 0.3409009         nan 0.35697297 0.35697297\n",
      " 0.35697297 0.35697297        nan 0.35427027 0.35427027 0.35427027\n",
      " 0.35427027        nan 0.3489009  0.3489009  0.3489009  0.3489009\n",
      "        nan 0.34893694 0.34893694 0.34893694 0.34893694        nan\n",
      " 0.3409009  0.3409009  0.3409009  0.3409009 ]\n",
      "  warnings.warn(\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training:  0.450402144772118\n",
      "9\n",
      "Fitting 5 folds for each of 640 candidates, totalling 3200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "640 fits failed out of a total of 3200.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "640 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan 0.43382664 0.43382664 0.43382664 0.43382664        nan\n",
      " 0.43382664 0.43382664 0.43382664 0.43382664        nan 0.43382664\n",
      " 0.43382664 0.43382664 0.43382664        nan 0.43382664 0.43382664\n",
      " 0.43382664 0.43382664        nan 0.43382664 0.43382664 0.43382664\n",
      " 0.43382664        nan 0.43382664 0.43382664 0.43382664 0.43382664\n",
      "        nan 0.43382664 0.43382664 0.43382664 0.43382664        nan\n",
      " 0.43382664 0.43382664 0.43382664 0.43382664        nan 0.42938689\n",
      " 0.42938689 0.42938689 0.42938689        nan 0.42938689 0.42938689\n",
      " 0.42938689 0.42938689        nan 0.42938689 0.42938689 0.42938689\n",
      " 0.42938689        nan 0.43868922 0.43868922 0.43868922 0.43868922\n",
      "        nan 0.43868922 0.43868922 0.43868922 0.43868922        nan\n",
      " 0.42505285 0.42505285 0.42505285 0.42505285        nan 0.42505285\n",
      " 0.42505285 0.42505285 0.42505285        nan 0.42505285 0.42505285\n",
      " 0.42505285 0.42505285        nan 0.45211416 0.44756871 0.44756871\n",
      " 0.44756871        nan 0.44756871 0.44756871 0.44756871 0.44756871\n",
      "        nan 0.44756871 0.44756871 0.44756871 0.44756871        nan\n",
      " 0.42938689 0.42938689 0.42938689 0.42938689        nan 0.42938689\n",
      " 0.42938689 0.42938689 0.42938689        nan 0.41575053 0.41575053\n",
      " 0.41575053 0.41575053        nan 0.41575053 0.41575053 0.41575053\n",
      " 0.41575053        nan 0.42029598 0.42029598 0.42029598 0.42029598\n",
      "        nan 0.45211416 0.44756871 0.44756871 0.44756871        nan\n",
      " 0.43372093 0.43372093 0.43372093 0.43837209        nan 0.43837209\n",
      " 0.43837209 0.43837209 0.43837209        nan 0.42473573 0.42473573\n",
      " 0.42473573 0.42473573        nan 0.41564482 0.41564482 0.41564482\n",
      " 0.41564482        nan 0.40200846 0.40200846 0.40200846 0.40200846\n",
      "        nan 0.40655391 0.40655391 0.40655391 0.40655391        nan\n",
      " 0.41575053 0.41575053 0.41575053 0.41575053        nan 0.44735729\n",
      " 0.44281184 0.43826638 0.44291755        nan 0.43372093 0.43372093\n",
      " 0.43372093 0.43837209        nan 0.43837209 0.43837209 0.43837209\n",
      " 0.43837209        nan 0.42473573 0.42473573 0.42473573 0.42473573\n",
      "        nan 0.41564482 0.41564482 0.41564482 0.41564482        nan\n",
      " 0.40200846 0.40200846 0.40200846 0.40200846        nan 0.40655391\n",
      " 0.40655391 0.40655391 0.40655391        nan 0.41575053 0.41575053\n",
      " 0.41575053 0.41575053        nan 0.43372093 0.43372093 0.43372093\n",
      " 0.43837209        nan 0.42917548 0.42917548 0.42917548 0.43382664\n",
      "        nan 0.43382664 0.43382664 0.43382664 0.43382664        nan\n",
      " 0.42019027 0.42019027 0.42019027 0.42019027        nan 0.41564482\n",
      " 0.41564482 0.41564482 0.41564482        nan 0.40200846 0.40200846\n",
      " 0.40200846 0.40200846        nan 0.40655391 0.40655391 0.40655391\n",
      " 0.40655391        nan 0.41575053 0.41575053 0.41575053 0.41575053\n",
      "        nan 0.43372093 0.43372093 0.43372093 0.43837209        nan\n",
      " 0.42917548 0.42917548 0.42917548 0.43382664        nan 0.43382664\n",
      " 0.43382664 0.43382664 0.43382664        nan 0.42019027 0.42019027\n",
      " 0.42019027 0.42019027        nan 0.41564482 0.41564482 0.41564482\n",
      " 0.41564482        nan 0.40200846 0.40200846 0.40200846 0.40200846\n",
      "        nan 0.40655391 0.40655391 0.40655391 0.40655391        nan\n",
      " 0.41575053 0.41575053 0.41575053 0.41575053        nan 0.43372093\n",
      " 0.43372093 0.43372093 0.43837209        nan 0.42917548 0.42917548\n",
      " 0.42917548 0.43382664        nan 0.43382664 0.43382664 0.43382664\n",
      " 0.43382664        nan 0.42019027 0.42019027 0.42019027 0.42019027\n",
      "        nan 0.41564482 0.41564482 0.41564482 0.41564482        nan\n",
      " 0.40200846 0.40200846 0.40200846 0.40200846        nan 0.40655391\n",
      " 0.40655391 0.40655391 0.40655391        nan 0.41575053 0.41575053\n",
      " 0.41575053 0.41575053        nan 0.43372093 0.43372093 0.43372093\n",
      " 0.43837209        nan 0.42917548 0.42917548 0.42917548 0.43382664\n",
      "        nan 0.43382664 0.43382664 0.43382664 0.43382664        nan\n",
      " 0.42019027 0.42019027 0.42019027 0.42019027        nan 0.41564482\n",
      " 0.41564482 0.41564482 0.41564482        nan 0.40200846 0.40200846\n",
      " 0.40200846 0.40200846        nan 0.40655391 0.40655391 0.40655391\n",
      " 0.40655391        nan 0.41575053 0.41575053 0.41575053 0.41575053\n",
      "        nan 0.43372093 0.43372093 0.43372093 0.43837209        nan\n",
      " 0.42917548 0.42917548 0.42917548 0.43382664        nan 0.43382664\n",
      " 0.43382664 0.43382664 0.43382664        nan 0.42019027 0.42019027\n",
      " 0.42019027 0.42019027        nan 0.41564482 0.41564482 0.41564482\n",
      " 0.41564482        nan 0.40200846 0.40200846 0.40200846 0.40200846\n",
      "        nan 0.40655391 0.40655391 0.40655391 0.40655391        nan\n",
      " 0.41575053 0.41575053 0.41575053 0.41575053        nan 0.43372093\n",
      " 0.43372093 0.43372093 0.43837209        nan 0.42917548 0.42917548\n",
      " 0.42917548 0.43382664        nan 0.43382664 0.43382664 0.43382664\n",
      " 0.43382664        nan 0.42019027 0.42019027 0.42019027 0.42019027\n",
      "        nan 0.41564482 0.41564482 0.41564482 0.41564482        nan\n",
      " 0.40200846 0.40200846 0.40200846 0.40200846        nan 0.40655391\n",
      " 0.40655391 0.40655391 0.40655391        nan 0.41575053 0.41575053\n",
      " 0.41575053 0.41575053        nan 0.43372093 0.43372093 0.43372093\n",
      " 0.43837209        nan 0.42917548 0.42917548 0.42917548 0.43382664\n",
      "        nan 0.43382664 0.43382664 0.43382664 0.43382664        nan\n",
      " 0.42019027 0.42019027 0.42019027 0.42019027        nan 0.41564482\n",
      " 0.41564482 0.41564482 0.41564482        nan 0.40200846 0.40200846\n",
      " 0.40200846 0.40200846        nan 0.40655391 0.40655391 0.40655391\n",
      " 0.40655391        nan 0.41575053 0.41575053 0.41575053 0.41575053\n",
      "        nan 0.43372093 0.43372093 0.43372093 0.43837209        nan\n",
      " 0.42917548 0.42917548 0.42917548 0.43382664        nan 0.43382664\n",
      " 0.43382664 0.43382664 0.43382664        nan 0.42019027 0.42019027\n",
      " 0.42019027 0.42019027        nan 0.41564482 0.41564482 0.41564482\n",
      " 0.41564482        nan 0.40200846 0.40200846 0.40200846 0.40200846\n",
      "        nan 0.40655391 0.40655391 0.40655391 0.40655391        nan\n",
      " 0.41575053 0.41575053 0.41575053 0.41575053        nan 0.43372093\n",
      " 0.43372093 0.43372093 0.43837209        nan 0.42917548 0.42917548\n",
      " 0.42917548 0.43382664        nan 0.43382664 0.43382664 0.43382664\n",
      " 0.43382664        nan 0.42019027 0.42019027 0.42019027 0.42019027\n",
      "        nan 0.41564482 0.41564482 0.41564482 0.41564482        nan\n",
      " 0.40200846 0.40200846 0.40200846 0.40200846        nan 0.40655391\n",
      " 0.40655391 0.40655391 0.40655391        nan 0.41575053 0.41575053\n",
      " 0.41575053 0.41575053        nan 0.43372093 0.43372093 0.43372093\n",
      " 0.43837209        nan 0.42917548 0.42917548 0.42917548 0.43382664\n",
      "        nan 0.43382664 0.43382664 0.43382664 0.43382664        nan\n",
      " 0.42019027 0.42019027 0.42019027 0.42019027        nan 0.41564482\n",
      " 0.41564482 0.41564482 0.41564482        nan 0.40200846 0.40200846\n",
      " 0.40200846 0.40200846        nan 0.40655391 0.40655391 0.40655391\n",
      " 0.40655391        nan 0.41575053 0.41575053 0.41575053 0.41575053\n",
      "        nan 0.43372093 0.43372093 0.43372093 0.43837209        nan\n",
      " 0.42917548 0.42917548 0.42917548 0.43382664        nan 0.43382664\n",
      " 0.43382664 0.43382664 0.43382664        nan 0.42019027 0.42019027\n",
      " 0.42019027 0.42019027        nan 0.41564482 0.41564482 0.41564482\n",
      " 0.41564482        nan 0.40200846 0.40200846 0.40200846 0.40200846\n",
      "        nan 0.40655391 0.40655391 0.40655391 0.40655391        nan\n",
      " 0.41575053 0.41575053 0.41575053 0.41575053]\n",
      "  warnings.warn(\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training:  0.4977168949771689\n",
      "10\n",
      "Fitting 5 folds for each of 640 candidates, totalling 3200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "640 fits failed out of a total of 3200.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "640 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan 0.42117647 0.42117647 0.42117647 0.42117647        nan\n",
      " 0.42117647 0.42117647 0.42117647 0.42117647        nan 0.42705882\n",
      " 0.42705882 0.42705882 0.42705882        nan 0.40941176 0.40941176\n",
      " 0.40941176 0.40941176        nan 0.39176471 0.39176471 0.39176471\n",
      " 0.39176471        nan 0.39176471 0.39176471 0.39176471 0.39176471\n",
      "        nan 0.39176471 0.39176471 0.39176471 0.39176471        nan\n",
      " 0.39176471 0.39176471 0.39176471 0.39176471        nan 0.42117647\n",
      " 0.42117647 0.42117647 0.42117647        nan 0.42117647 0.42117647\n",
      " 0.42117647 0.42117647        nan 0.41529412 0.41529412 0.41529412\n",
      " 0.41529412        nan 0.40352941 0.40352941 0.40352941 0.40352941\n",
      "        nan 0.39747899 0.39747899 0.39747899 0.39747899        nan\n",
      " 0.39747899 0.39747899 0.39747899 0.39747899        nan 0.39176471\n",
      " 0.39176471 0.39176471 0.39176471        nan 0.39176471 0.39176471\n",
      " 0.39176471 0.39176471        nan 0.39176471 0.39176471 0.39176471\n",
      " 0.39176471        nan 0.39176471 0.39176471 0.39176471 0.39176471\n",
      "        nan 0.40352941 0.40352941 0.40352941 0.40352941        nan\n",
      " 0.40941176 0.40941176 0.40941176 0.40941176        nan 0.40941176\n",
      " 0.40941176 0.40941176 0.40941176        nan 0.42705882 0.42705882\n",
      " 0.42705882 0.42705882        nan 0.42705882 0.42705882 0.42705882\n",
      " 0.42705882        nan 0.42705882 0.42705882 0.42705882 0.42705882\n",
      "        nan 0.39764706 0.39764706 0.39764706 0.39764706        nan\n",
      " 0.39764706 0.39764706 0.39764706 0.39764706        nan 0.40352941\n",
      " 0.40352941 0.40352941 0.40352941        nan 0.41529412 0.41529412\n",
      " 0.41529412 0.41529412        nan 0.39764706 0.39764706 0.39764706\n",
      " 0.39764706        nan 0.39176471 0.39176471 0.39176471 0.39176471\n",
      "        nan 0.39764706 0.39764706 0.39764706 0.39764706        nan\n",
      " 0.40941176 0.40941176 0.40941176 0.40941176        nan 0.38016807\n",
      " 0.38016807 0.38016807 0.38016807        nan 0.38588235 0.38588235\n",
      " 0.38588235 0.38588235        nan 0.40941176 0.40941176 0.40941176\n",
      " 0.40941176        nan 0.39764706 0.39764706 0.39764706 0.39764706\n",
      "        nan 0.39764706 0.39764706 0.39764706 0.39764706        nan\n",
      " 0.39176471 0.39176471 0.39176471 0.39176471        nan 0.39764706\n",
      " 0.39764706 0.39764706 0.39764706        nan 0.40941176 0.40941176\n",
      " 0.40941176 0.40941176        nan 0.39193277 0.39193277 0.38016807\n",
      " 0.38016807        nan 0.39781513 0.39781513 0.38605042 0.38605042\n",
      "        nan 0.39764706 0.39764706 0.39764706 0.39764706        nan\n",
      " 0.39764706 0.39764706 0.39764706 0.39764706        nan 0.39764706\n",
      " 0.39764706 0.39764706 0.39764706        nan 0.39176471 0.39176471\n",
      " 0.39176471 0.39176471        nan 0.39764706 0.39764706 0.39764706\n",
      " 0.39764706        nan 0.40941176 0.40941176 0.40941176 0.40941176\n",
      "        nan 0.39210084 0.39210084 0.38605042 0.38605042        nan\n",
      " 0.39781513 0.39781513 0.38605042 0.38605042        nan 0.39764706\n",
      " 0.39764706 0.39764706 0.39764706        nan 0.39764706 0.39764706\n",
      " 0.39764706 0.39764706        nan 0.39764706 0.39764706 0.39764706\n",
      " 0.39764706        nan 0.39176471 0.39176471 0.39176471 0.39176471\n",
      "        nan 0.39764706 0.39764706 0.39764706 0.39764706        nan\n",
      " 0.40941176 0.40941176 0.40941176 0.40941176        nan 0.39210084\n",
      " 0.39210084 0.38605042 0.38605042        nan 0.39781513 0.39781513\n",
      " 0.38605042 0.38605042        nan 0.39764706 0.39764706 0.39764706\n",
      " 0.39764706        nan 0.39764706 0.39764706 0.39764706 0.39764706\n",
      "        nan 0.39764706 0.39764706 0.39764706 0.39764706        nan\n",
      " 0.39176471 0.39176471 0.39176471 0.39176471        nan 0.39764706\n",
      " 0.39764706 0.39764706 0.39764706        nan 0.40941176 0.40941176\n",
      " 0.40941176 0.40941176        nan 0.39210084 0.39210084 0.38605042\n",
      " 0.38605042        nan 0.39781513 0.39781513 0.38605042 0.38605042\n",
      "        nan 0.39764706 0.39764706 0.39764706 0.39764706        nan\n",
      " 0.39764706 0.39764706 0.39764706 0.39764706        nan 0.39764706\n",
      " 0.39764706 0.39764706 0.39764706        nan 0.39176471 0.39176471\n",
      " 0.39176471 0.39176471        nan 0.39764706 0.39764706 0.39764706\n",
      " 0.39764706        nan 0.40941176 0.40941176 0.40941176 0.40941176\n",
      "        nan 0.39210084 0.39210084 0.38605042 0.38605042        nan\n",
      " 0.39781513 0.39781513 0.38605042 0.38605042        nan 0.39764706\n",
      " 0.39764706 0.39764706 0.39764706        nan 0.39764706 0.39764706\n",
      " 0.39764706 0.39764706        nan 0.39764706 0.39764706 0.39764706\n",
      " 0.39764706        nan 0.39176471 0.39176471 0.39176471 0.39176471\n",
      "        nan 0.39764706 0.39764706 0.39764706 0.39764706        nan\n",
      " 0.40941176 0.40941176 0.40941176 0.40941176        nan 0.39210084\n",
      " 0.39210084 0.38605042 0.38605042        nan 0.39781513 0.39781513\n",
      " 0.38605042 0.38605042        nan 0.39764706 0.39764706 0.39764706\n",
      " 0.39764706        nan 0.39764706 0.39764706 0.39764706 0.39764706\n",
      "        nan 0.39764706 0.39764706 0.39764706 0.39764706        nan\n",
      " 0.39176471 0.39176471 0.39176471 0.39176471        nan 0.39764706\n",
      " 0.39764706 0.39764706 0.39764706        nan 0.40941176 0.40941176\n",
      " 0.40941176 0.40941176        nan 0.39210084 0.39210084 0.38605042\n",
      " 0.38605042        nan 0.39781513 0.39781513 0.38605042 0.38605042\n",
      "        nan 0.39764706 0.39764706 0.39764706 0.39764706        nan\n",
      " 0.39764706 0.39764706 0.39764706 0.39764706        nan 0.39764706\n",
      " 0.39764706 0.39764706 0.39764706        nan 0.39176471 0.39176471\n",
      " 0.39176471 0.39176471        nan 0.39764706 0.39764706 0.39764706\n",
      " 0.39764706        nan 0.40941176 0.40941176 0.40941176 0.40941176\n",
      "        nan 0.39210084 0.39210084 0.38605042 0.38605042        nan\n",
      " 0.39781513 0.39781513 0.38605042 0.38605042        nan 0.39764706\n",
      " 0.39764706 0.39764706 0.39764706        nan 0.39764706 0.39764706\n",
      " 0.39764706 0.39764706        nan 0.39764706 0.39764706 0.39764706\n",
      " 0.39764706        nan 0.39176471 0.39176471 0.39176471 0.39176471\n",
      "        nan 0.39764706 0.39764706 0.39764706 0.39764706        nan\n",
      " 0.40941176 0.40941176 0.40941176 0.40941176        nan 0.39210084\n",
      " 0.39210084 0.38605042 0.38605042        nan 0.39781513 0.39781513\n",
      " 0.38605042 0.38605042        nan 0.39764706 0.39764706 0.39764706\n",
      " 0.39764706        nan 0.39764706 0.39764706 0.39764706 0.39764706\n",
      "        nan 0.39764706 0.39764706 0.39764706 0.39764706        nan\n",
      " 0.39176471 0.39176471 0.39176471 0.39176471        nan 0.39764706\n",
      " 0.39764706 0.39764706 0.39764706        nan 0.40941176 0.40941176\n",
      " 0.40941176 0.40941176        nan 0.39210084 0.39210084 0.38605042\n",
      " 0.38605042        nan 0.39781513 0.39781513 0.38605042 0.38605042\n",
      "        nan 0.39764706 0.39764706 0.39764706 0.39764706        nan\n",
      " 0.39764706 0.39764706 0.39764706 0.39764706        nan 0.39764706\n",
      " 0.39764706 0.39764706 0.39764706        nan 0.39176471 0.39176471\n",
      " 0.39176471 0.39176471        nan 0.39764706 0.39764706 0.39764706\n",
      " 0.39764706        nan 0.40941176 0.40941176 0.40941176 0.40941176\n",
      "        nan 0.39210084 0.39210084 0.38605042 0.38605042        nan\n",
      " 0.39781513 0.39781513 0.38605042 0.38605042        nan 0.39764706\n",
      " 0.39764706 0.39764706 0.39764706        nan 0.39764706 0.39764706\n",
      " 0.39764706 0.39764706        nan 0.39764706 0.39764706 0.39764706\n",
      " 0.39764706        nan 0.39176471 0.39176471 0.39176471 0.39176471\n",
      "        nan 0.39764706 0.39764706 0.39764706 0.39764706        nan\n",
      " 0.40941176 0.40941176 0.40941176 0.40941176]\n",
      "  warnings.warn(\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training:  0.43859649122807015\n",
      "11\n",
      "Fitting 5 folds for each of 640 candidates, totalling 3200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "640 fits failed out of a total of 3200.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "640 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan 0.44021801 0.44021801 0.44021801 0.44021801        nan\n",
      " 0.44021801 0.44021801 0.44021801 0.44021801        nan 0.44021801\n",
      " 0.44021801 0.44021801 0.44021801        nan 0.44021801 0.44021801\n",
      " 0.44021801 0.44021801        nan 0.44021801 0.44021801 0.44021801\n",
      " 0.44021801        nan 0.44021801 0.44021801 0.44021801 0.44021801\n",
      "        nan 0.44021801 0.44021801 0.44021801 0.44021801        nan\n",
      " 0.44021801 0.44021801 0.44021801 0.44021801        nan 0.44254159\n",
      " 0.44254159 0.44254159 0.44254159        nan 0.44254159 0.44254159\n",
      " 0.44254159 0.44254159        nan 0.44254159 0.44254159 0.44254159\n",
      " 0.44254159        nan 0.44254159 0.44254159 0.44254159 0.44254159\n",
      "        nan 0.44254159 0.44254159 0.44254159 0.44254159        nan\n",
      " 0.44254159 0.44254159 0.44254159 0.44254159        nan 0.44254159\n",
      " 0.44254159 0.44254159 0.44254159        nan 0.44254159 0.44254159\n",
      " 0.44254159 0.44254159        nan 0.44018933 0.44018933 0.44018933\n",
      " 0.44018933        nan 0.44018933 0.44018933 0.44018933 0.44018933\n",
      "        nan 0.44018933 0.44018933 0.44018933 0.44018933        nan\n",
      " 0.44018933 0.44018933 0.44018933 0.44018933        nan 0.44018933\n",
      " 0.44018933 0.44018933 0.44018933        nan 0.44018933 0.44018933\n",
      " 0.44018933 0.44018933        nan 0.44018933 0.44018933 0.44018933\n",
      " 0.44018933        nan 0.44018933 0.44018933 0.44018933 0.44018933\n",
      "        nan 0.43542742 0.43542742 0.43542742 0.44016064        nan\n",
      " 0.44733219 0.44733219 0.44733219 0.44254159        nan 0.44254159\n",
      " 0.44254159 0.44254159 0.437751          nan 0.43772232 0.43772232\n",
      " 0.43772232 0.43772232        nan 0.43772232 0.43772232 0.43772232\n",
      " 0.43772232        nan 0.44013196 0.44013196 0.44013196 0.44013196\n",
      "        nan 0.43293173 0.43293173 0.43293173 0.43293173        nan\n",
      " 0.43293173 0.43293173 0.43293173 0.43293173        nan 0.43055077\n",
      " 0.43055077 0.43534137 0.43055077        nan 0.43055077 0.43055077\n",
      " 0.43534137 0.43055077        nan 0.43055077 0.43055077 0.43055077\n",
      " 0.42576018        nan 0.41858864 0.41858864 0.41858864 0.41858864\n",
      "        nan 0.41858864 0.41858864 0.41858864 0.41858864        nan\n",
      " 0.42099828 0.42099828 0.42099828 0.42099828        nan 0.42329317\n",
      " 0.42329317 0.42329317 0.42329317        nan 0.42570281 0.42570281\n",
      " 0.42570281 0.42570281        nan 0.42576018 0.42576018 0.42816982\n",
      " 0.42096959        nan 0.42816982 0.42816982 0.4329891  0.42578887\n",
      "        nan 0.42578887 0.42578887 0.42578887 0.42099828        nan\n",
      " 0.42340792 0.42340792 0.42340792 0.42340792        nan 0.42340792\n",
      " 0.42340792 0.42340792 0.42340792        nan 0.42819851 0.42819851\n",
      " 0.42819851 0.42819851        nan 0.42576018 0.42576018 0.42576018\n",
      " 0.42576018        nan 0.42816982 0.42816982 0.42816982 0.42816982\n",
      "        nan 0.42819851 0.42819851 0.43060815 0.42099828        nan\n",
      " 0.42340792 0.42340792 0.42822719 0.42102697        nan 0.42102697\n",
      " 0.42102697 0.42102697 0.41623637        nan 0.42340792 0.42340792\n",
      " 0.42340792 0.42340792        nan 0.42340792 0.42340792 0.42340792\n",
      " 0.42340792        nan 0.42819851 0.42819851 0.42819851 0.42819851\n",
      "        nan 0.42576018 0.42576018 0.42576018 0.42576018        nan\n",
      " 0.42816982 0.42816982 0.42816982 0.42816982        nan 0.42102697\n",
      " 0.42102697 0.42346529 0.41385542        nan 0.42102697 0.42102697\n",
      " 0.42584624 0.41864601        nan 0.41626506 0.41626506 0.41864601\n",
      " 0.41385542        nan 0.42340792 0.42340792 0.42340792 0.42340792\n",
      "        nan 0.42340792 0.42340792 0.42340792 0.42340792        nan\n",
      " 0.42819851 0.42819851 0.42819851 0.42819851        nan 0.42576018\n",
      " 0.42576018 0.42576018 0.42576018        nan 0.42816982 0.42816982\n",
      " 0.42816982 0.42816982        nan 0.41620769 0.41620769 0.41864601\n",
      " 0.40903614        nan 0.41864601 0.41864601 0.42346529 0.41864601\n",
      "        nan 0.41626506 0.41626506 0.41864601 0.41385542        nan\n",
      " 0.42340792 0.42340792 0.42340792 0.42340792        nan 0.42340792\n",
      " 0.42340792 0.42340792 0.42340792        nan 0.42819851 0.42819851\n",
      " 0.42819851 0.42819851        nan 0.42576018 0.42576018 0.42576018\n",
      " 0.42576018        nan 0.42816982 0.42816982 0.42816982 0.42816982\n",
      "        nan 0.41620769 0.41620769 0.41864601 0.40903614        nan\n",
      " 0.41864601 0.41864601 0.42346529 0.41864601        nan 0.41626506\n",
      " 0.41626506 0.41864601 0.41385542        nan 0.42340792 0.42340792\n",
      " 0.42340792 0.42340792        nan 0.42340792 0.42340792 0.42340792\n",
      " 0.42340792        nan 0.42819851 0.42819851 0.42819851 0.42819851\n",
      "        nan 0.42576018 0.42576018 0.42576018 0.42576018        nan\n",
      " 0.42816982 0.42816982 0.42816982 0.42816982        nan 0.41620769\n",
      " 0.41620769 0.41864601 0.40903614        nan 0.41864601 0.41864601\n",
      " 0.42346529 0.41864601        nan 0.41626506 0.41626506 0.41864601\n",
      " 0.41385542        nan 0.42340792 0.42340792 0.42340792 0.42340792\n",
      "        nan 0.42340792 0.42340792 0.42340792 0.42340792        nan\n",
      " 0.42819851 0.42819851 0.42819851 0.42819851        nan 0.42576018\n",
      " 0.42576018 0.42576018 0.42576018        nan 0.42816982 0.42816982\n",
      " 0.42816982 0.42816982        nan 0.41620769 0.41620769 0.41864601\n",
      " 0.40903614        nan 0.41864601 0.41864601 0.42346529 0.41864601\n",
      "        nan 0.41626506 0.41626506 0.41864601 0.41385542        nan\n",
      " 0.42340792 0.42340792 0.42340792 0.42340792        nan 0.42340792\n",
      " 0.42340792 0.42340792 0.42340792        nan 0.42819851 0.42819851\n",
      " 0.42819851 0.42819851        nan 0.42576018 0.42576018 0.42576018\n",
      " 0.42576018        nan 0.42816982 0.42816982 0.42816982 0.42816982\n",
      "        nan 0.41620769 0.41620769 0.41864601 0.40903614        nan\n",
      " 0.41864601 0.41864601 0.42346529 0.41864601        nan 0.41626506\n",
      " 0.41626506 0.41864601 0.41385542        nan 0.42340792 0.42340792\n",
      " 0.42340792 0.42340792        nan 0.42340792 0.42340792 0.42340792\n",
      " 0.42340792        nan 0.42819851 0.42819851 0.42819851 0.42819851\n",
      "        nan 0.42576018 0.42576018 0.42576018 0.42576018        nan\n",
      " 0.42816982 0.42816982 0.42816982 0.42816982        nan 0.41620769\n",
      " 0.41620769 0.41864601 0.40903614        nan 0.41864601 0.41864601\n",
      " 0.42346529 0.41864601        nan 0.41626506 0.41626506 0.41864601\n",
      " 0.41385542        nan 0.42340792 0.42340792 0.42340792 0.42340792\n",
      "        nan 0.42340792 0.42340792 0.42340792 0.42340792        nan\n",
      " 0.42819851 0.42819851 0.42819851 0.42819851        nan 0.42576018\n",
      " 0.42576018 0.42576018 0.42576018        nan 0.42816982 0.42816982\n",
      " 0.42816982 0.42816982        nan 0.41620769 0.41620769 0.41864601\n",
      " 0.40903614        nan 0.41864601 0.41864601 0.42346529 0.41864601\n",
      "        nan 0.41626506 0.41626506 0.41864601 0.41385542        nan\n",
      " 0.42340792 0.42340792 0.42340792 0.42340792        nan 0.42340792\n",
      " 0.42340792 0.42340792 0.42340792        nan 0.42819851 0.42819851\n",
      " 0.42819851 0.42819851        nan 0.42576018 0.42576018 0.42576018\n",
      " 0.42576018        nan 0.42816982 0.42816982 0.42816982 0.42816982\n",
      "        nan 0.41620769 0.41620769 0.41864601 0.40903614        nan\n",
      " 0.41864601 0.41864601 0.42346529 0.41864601        nan 0.41626506\n",
      " 0.41626506 0.41864601 0.41385542        nan 0.42340792 0.42340792\n",
      " 0.42340792 0.42340792        nan 0.42340792 0.42340792 0.42340792\n",
      " 0.42340792        nan 0.42819851 0.42819851 0.42819851 0.42819851\n",
      "        nan 0.42576018 0.42576018 0.42576018 0.42576018        nan\n",
      " 0.42816982 0.42816982 0.42816982 0.42816982]\n",
      "  warnings.warn(\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training:  0.4880382775119617\n",
      "12\n",
      "Fitting 5 folds for each of 640 candidates, totalling 3200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "640 fits failed out of a total of 3200.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "640 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan 0.35555556 0.35555556 0.35555556 0.35555556        nan\n",
      " 0.35555556 0.35555556 0.35555556 0.35555556        nan 0.35555556\n",
      " 0.35555556 0.35555556 0.35555556        nan 0.35555556 0.35555556\n",
      " 0.35555556 0.35555556        nan 0.35555556 0.35555556 0.35555556\n",
      " 0.35555556        nan 0.35555556 0.35555556 0.35555556 0.35555556\n",
      "        nan 0.35555556 0.35555556 0.35555556 0.35555556        nan\n",
      " 0.35555556 0.35555556 0.35555556 0.35555556        nan 0.32777778\n",
      " 0.32777778 0.32777778 0.32777778        nan 0.32777778 0.32777778\n",
      " 0.32777778 0.32777778        nan 0.32777778 0.32777778 0.32777778\n",
      " 0.32777778        nan 0.32777778 0.32777778 0.32777778 0.32777778\n",
      "        nan 0.32777778 0.32777778 0.32777778 0.32777778        nan\n",
      " 0.32777778 0.32777778 0.32777778 0.32777778        nan 0.32777778\n",
      " 0.32777778 0.32777778 0.32777778        nan 0.32777778 0.32777778\n",
      " 0.32777778 0.32777778        nan 0.32777778 0.32777778 0.32777778\n",
      " 0.32777778        nan 0.34444444 0.34444444 0.34444444 0.34444444\n",
      "        nan 0.32777778 0.32777778 0.32777778 0.32777778        nan\n",
      " 0.31666667 0.31666667 0.31666667 0.31666667        nan 0.33888889\n",
      " 0.33888889 0.33888889 0.33888889        nan 0.33888889 0.33888889\n",
      " 0.33888889 0.33888889        nan 0.34444444 0.34444444 0.34444444\n",
      " 0.34444444        nan 0.35       0.35       0.35       0.35\n",
      "        nan 0.32222222 0.32222222 0.32222222 0.32222222        nan\n",
      " 0.33333333 0.33333333 0.33333333 0.34444444        nan 0.32222222\n",
      " 0.32222222 0.32222222 0.32222222        nan 0.33888889 0.33888889\n",
      " 0.33888889 0.33888889        nan 0.33888889 0.33888889 0.33888889\n",
      " 0.33888889        nan 0.35       0.35       0.35       0.35\n",
      "        nan 0.35       0.35       0.35       0.35              nan\n",
      " 0.35555556 0.35555556 0.35555556 0.35555556        nan 0.32222222\n",
      " 0.33333333 0.33888889 0.32777778        nan 0.32222222 0.32222222\n",
      " 0.32222222 0.33333333        nan 0.31666667 0.31666667 0.31666667\n",
      " 0.31666667        nan 0.33333333 0.33333333 0.33333333 0.33333333\n",
      "        nan 0.35       0.35       0.35       0.35              nan\n",
      " 0.35       0.35       0.35       0.35              nan 0.35\n",
      " 0.35       0.35       0.35              nan 0.35555556 0.35555556\n",
      " 0.35555556 0.35555556        nan 0.33333333 0.33333333 0.33333333\n",
      " 0.33888889        nan 0.34444444 0.34444444 0.34444444 0.35555556\n",
      "        nan 0.31666667 0.31666667 0.31666667 0.31666667        nan\n",
      " 0.34444444 0.34444444 0.34444444 0.34444444        nan 0.35\n",
      " 0.35       0.35       0.35              nan 0.35       0.35\n",
      " 0.35       0.35              nan 0.35       0.35       0.35\n",
      " 0.35              nan 0.35555556 0.35555556 0.35555556 0.35555556\n",
      "        nan 0.33333333 0.33333333 0.33333333 0.33888889        nan\n",
      " 0.34444444 0.34444444 0.34444444 0.35555556        nan 0.31666667\n",
      " 0.31666667 0.31666667 0.31666667        nan 0.34444444 0.34444444\n",
      " 0.34444444 0.34444444        nan 0.35       0.35       0.35\n",
      " 0.35              nan 0.35       0.35       0.35       0.35\n",
      "        nan 0.35       0.35       0.35       0.35              nan\n",
      " 0.35555556 0.35555556 0.35555556 0.35555556        nan 0.33333333\n",
      " 0.33333333 0.33333333 0.33888889        nan 0.34444444 0.34444444\n",
      " 0.34444444 0.35555556        nan 0.31666667 0.31666667 0.31666667\n",
      " 0.31666667        nan 0.34444444 0.34444444 0.34444444 0.34444444\n",
      "        nan 0.35       0.35       0.35       0.35              nan\n",
      " 0.35       0.35       0.35       0.35              nan 0.35\n",
      " 0.35       0.35       0.35              nan 0.35555556 0.35555556\n",
      " 0.35555556 0.35555556        nan 0.33333333 0.33333333 0.33333333\n",
      " 0.33888889        nan 0.34444444 0.34444444 0.34444444 0.35555556\n",
      "        nan 0.31666667 0.31666667 0.31666667 0.31666667        nan\n",
      " 0.34444444 0.34444444 0.34444444 0.34444444        nan 0.35\n",
      " 0.35       0.35       0.35              nan 0.35       0.35\n",
      " 0.35       0.35              nan 0.35       0.35       0.35\n",
      " 0.35              nan 0.35555556 0.35555556 0.35555556 0.35555556\n",
      "        nan 0.33333333 0.33333333 0.33333333 0.33888889        nan\n",
      " 0.34444444 0.34444444 0.34444444 0.35555556        nan 0.31666667\n",
      " 0.31666667 0.31666667 0.31666667        nan 0.34444444 0.34444444\n",
      " 0.34444444 0.34444444        nan 0.35       0.35       0.35\n",
      " 0.35              nan 0.35       0.35       0.35       0.35\n",
      "        nan 0.35       0.35       0.35       0.35              nan\n",
      " 0.35555556 0.35555556 0.35555556 0.35555556        nan 0.33333333\n",
      " 0.33333333 0.33333333 0.33888889        nan 0.34444444 0.34444444\n",
      " 0.34444444 0.35555556        nan 0.31666667 0.31666667 0.31666667\n",
      " 0.31666667        nan 0.34444444 0.34444444 0.34444444 0.34444444\n",
      "        nan 0.35       0.35       0.35       0.35              nan\n",
      " 0.35       0.35       0.35       0.35              nan 0.35\n",
      " 0.35       0.35       0.35              nan 0.35555556 0.35555556\n",
      " 0.35555556 0.35555556        nan 0.33333333 0.33333333 0.33333333\n",
      " 0.33888889        nan 0.34444444 0.34444444 0.34444444 0.35555556\n",
      "        nan 0.31666667 0.31666667 0.31666667 0.31666667        nan\n",
      " 0.34444444 0.34444444 0.34444444 0.34444444        nan 0.35\n",
      " 0.35       0.35       0.35              nan 0.35       0.35\n",
      " 0.35       0.35              nan 0.35       0.35       0.35\n",
      " 0.35              nan 0.35555556 0.35555556 0.35555556 0.35555556\n",
      "        nan 0.33333333 0.33333333 0.33333333 0.33888889        nan\n",
      " 0.34444444 0.34444444 0.34444444 0.35555556        nan 0.31666667\n",
      " 0.31666667 0.31666667 0.31666667        nan 0.34444444 0.34444444\n",
      " 0.34444444 0.34444444        nan 0.35       0.35       0.35\n",
      " 0.35              nan 0.35       0.35       0.35       0.35\n",
      "        nan 0.35       0.35       0.35       0.35              nan\n",
      " 0.35555556 0.35555556 0.35555556 0.35555556        nan 0.33333333\n",
      " 0.33333333 0.33333333 0.33888889        nan 0.34444444 0.34444444\n",
      " 0.34444444 0.35555556        nan 0.31666667 0.31666667 0.31666667\n",
      " 0.31666667        nan 0.34444444 0.34444444 0.34444444 0.34444444\n",
      "        nan 0.35       0.35       0.35       0.35              nan\n",
      " 0.35       0.35       0.35       0.35              nan 0.35\n",
      " 0.35       0.35       0.35              nan 0.35555556 0.35555556\n",
      " 0.35555556 0.35555556        nan 0.33333333 0.33333333 0.33333333\n",
      " 0.33888889        nan 0.34444444 0.34444444 0.34444444 0.35555556\n",
      "        nan 0.31666667 0.31666667 0.31666667 0.31666667        nan\n",
      " 0.34444444 0.34444444 0.34444444 0.34444444        nan 0.35\n",
      " 0.35       0.35       0.35              nan 0.35       0.35\n",
      " 0.35       0.35              nan 0.35       0.35       0.35\n",
      " 0.35              nan 0.35555556 0.35555556 0.35555556 0.35555556\n",
      "        nan 0.33333333 0.33333333 0.33333333 0.33888889        nan\n",
      " 0.34444444 0.34444444 0.34444444 0.35555556        nan 0.31666667\n",
      " 0.31666667 0.31666667 0.31666667        nan 0.34444444 0.34444444\n",
      " 0.34444444 0.34444444        nan 0.35       0.35       0.35\n",
      " 0.35              nan 0.35       0.35       0.35       0.35\n",
      "        nan 0.35       0.35       0.35       0.35              nan\n",
      " 0.35555556 0.35555556 0.35555556 0.35555556]\n",
      "  warnings.warn(\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training:  0.36666666666666664\n",
      "13\n",
      "Fitting 5 folds for each of 640 candidates, totalling 3200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "640 fits failed out of a total of 3200.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "640 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan 0.40646465 0.40646465 0.40646465 0.40646465        nan\n",
      " 0.40646465 0.40646465 0.40646465 0.40646465        nan 0.40646465\n",
      " 0.40646465 0.40646465 0.40646465        nan 0.40646465 0.40646465\n",
      " 0.40646465 0.40646465        nan 0.40646465 0.40646465 0.40646465\n",
      " 0.40646465        nan 0.40646465 0.40646465 0.40646465 0.40646465\n",
      "        nan 0.40646465 0.40646465 0.40646465 0.40646465        nan\n",
      " 0.40646465 0.40646465 0.40646465 0.40646465        nan 0.42858586\n",
      " 0.42858586 0.42858586 0.42858586        nan 0.42858586 0.42858586\n",
      " 0.42858586 0.42858586        nan 0.42858586 0.42858586 0.42858586\n",
      " 0.42858586        nan 0.42858586 0.42858586 0.42858586 0.42858586\n",
      "        nan 0.42858586 0.42858586 0.42858586 0.42858586        nan\n",
      " 0.42858586 0.42858586 0.42858586 0.42858586        nan 0.42858586\n",
      " 0.42858586 0.42858586 0.42858586        nan 0.44191919 0.44191919\n",
      " 0.44191919 0.44191919        nan 0.43313131 0.43313131 0.43313131\n",
      " 0.43757576        nan 0.43757576 0.43757576 0.43757576 0.4420202\n",
      "        nan 0.43757576 0.43757576 0.43757576 0.4420202         nan\n",
      " 0.4420202  0.4420202  0.4420202  0.4420202         nan 0.41535354\n",
      " 0.41535354 0.41535354 0.41535354        nan 0.41535354 0.41535354\n",
      " 0.41535354 0.41535354        nan 0.41535354 0.41535354 0.41535354\n",
      " 0.41535354        nan 0.42424242 0.42424242 0.42424242 0.42424242\n",
      "        nan 0.41979798 0.41979798 0.41979798 0.41979798        nan\n",
      " 0.41979798 0.41979798 0.41979798 0.42424242        nan 0.41979798\n",
      " 0.41979798 0.41979798 0.42424242        nan 0.42424242 0.42424242\n",
      " 0.42424242 0.42424242        nan 0.41979798 0.41979798 0.41979798\n",
      " 0.41979798        nan 0.41979798 0.41979798 0.41979798 0.41979798\n",
      "        nan 0.41979798 0.41979798 0.41979798 0.41979798        nan\n",
      " 0.42424242 0.42424242 0.42424242 0.42424242        nan 0.41080808\n",
      " 0.41525253 0.41080808 0.41080808        nan 0.41979798 0.41979798\n",
      " 0.41979798 0.42424242        nan 0.41979798 0.41979798 0.41979798\n",
      " 0.42424242        nan 0.42424242 0.42424242 0.42424242 0.42424242\n",
      "        nan 0.41535354 0.41535354 0.41535354 0.41535354        nan\n",
      " 0.41979798 0.41979798 0.41979798 0.41979798        nan 0.41979798\n",
      " 0.41979798 0.41979798 0.41979798        nan 0.42424242 0.42424242\n",
      " 0.42424242 0.42424242        nan 0.41080808 0.41525253 0.41080808\n",
      " 0.41525253        nan 0.41080808 0.41080808 0.41080808 0.41979798\n",
      "        nan 0.41080808 0.41080808 0.41080808 0.41979798        nan\n",
      " 0.42424242 0.42424242 0.42424242 0.42424242        nan 0.41535354\n",
      " 0.41535354 0.41535354 0.41535354        nan 0.41979798 0.41979798\n",
      " 0.41979798 0.41979798        nan 0.41979798 0.41979798 0.41979798\n",
      " 0.41979798        nan 0.42424242 0.42424242 0.42424242 0.42424242\n",
      "        nan 0.41080808 0.41525253 0.41080808 0.41525253        nan\n",
      " 0.41080808 0.41080808 0.41080808 0.41979798        nan 0.41080808\n",
      " 0.41080808 0.41080808 0.41979798        nan 0.42424242 0.42424242\n",
      " 0.42424242 0.42424242        nan 0.41535354 0.41535354 0.41535354\n",
      " 0.41535354        nan 0.41979798 0.41979798 0.41979798 0.41979798\n",
      "        nan 0.41979798 0.41979798 0.41979798 0.41979798        nan\n",
      " 0.42424242 0.42424242 0.42424242 0.42424242        nan 0.41080808\n",
      " 0.41525253 0.41080808 0.41525253        nan 0.41080808 0.41080808\n",
      " 0.41080808 0.41979798        nan 0.41080808 0.41080808 0.41080808\n",
      " 0.41979798        nan 0.42424242 0.42424242 0.42424242 0.42424242\n",
      "        nan 0.41535354 0.41535354 0.41535354 0.41535354        nan\n",
      " 0.41979798 0.41979798 0.41979798 0.41979798        nan 0.41979798\n",
      " 0.41979798 0.41979798 0.41979798        nan 0.42424242 0.42424242\n",
      " 0.42424242 0.42424242        nan 0.41080808 0.41525253 0.41080808\n",
      " 0.41525253        nan 0.41080808 0.41080808 0.41080808 0.41979798\n",
      "        nan 0.41080808 0.41080808 0.41080808 0.41979798        nan\n",
      " 0.42424242 0.42424242 0.42424242 0.42424242        nan 0.41535354\n",
      " 0.41535354 0.41535354 0.41535354        nan 0.41979798 0.41979798\n",
      " 0.41979798 0.41979798        nan 0.41979798 0.41979798 0.41979798\n",
      " 0.41979798        nan 0.42424242 0.42424242 0.42424242 0.42424242\n",
      "        nan 0.41080808 0.41525253 0.41080808 0.41525253        nan\n",
      " 0.41080808 0.41080808 0.41080808 0.41979798        nan 0.41080808\n",
      " 0.41080808 0.41080808 0.41979798        nan 0.42424242 0.42424242\n",
      " 0.42424242 0.42424242        nan 0.41535354 0.41535354 0.41535354\n",
      " 0.41535354        nan 0.41979798 0.41979798 0.41979798 0.41979798\n",
      "        nan 0.41979798 0.41979798 0.41979798 0.41979798        nan\n",
      " 0.42424242 0.42424242 0.42424242 0.42424242        nan 0.41080808\n",
      " 0.41525253 0.41080808 0.41525253        nan 0.41080808 0.41080808\n",
      " 0.41080808 0.41979798        nan 0.41080808 0.41080808 0.41080808\n",
      " 0.41979798        nan 0.42424242 0.42424242 0.42424242 0.42424242\n",
      "        nan 0.41535354 0.41535354 0.41535354 0.41535354        nan\n",
      " 0.41979798 0.41979798 0.41979798 0.41979798        nan 0.41979798\n",
      " 0.41979798 0.41979798 0.41979798        nan 0.42424242 0.42424242\n",
      " 0.42424242 0.42424242        nan 0.41080808 0.41525253 0.41080808\n",
      " 0.41525253        nan 0.41080808 0.41080808 0.41080808 0.41979798\n",
      "        nan 0.41080808 0.41080808 0.41080808 0.41979798        nan\n",
      " 0.42424242 0.42424242 0.42424242 0.42424242        nan 0.41535354\n",
      " 0.41535354 0.41535354 0.41535354        nan 0.41979798 0.41979798\n",
      " 0.41979798 0.41979798        nan 0.41979798 0.41979798 0.41979798\n",
      " 0.41979798        nan 0.42424242 0.42424242 0.42424242 0.42424242\n",
      "        nan 0.41080808 0.41525253 0.41080808 0.41525253        nan\n",
      " 0.41080808 0.41080808 0.41080808 0.41979798        nan 0.41080808\n",
      " 0.41080808 0.41080808 0.41979798        nan 0.42424242 0.42424242\n",
      " 0.42424242 0.42424242        nan 0.41535354 0.41535354 0.41535354\n",
      " 0.41535354        nan 0.41979798 0.41979798 0.41979798 0.41979798\n",
      "        nan 0.41979798 0.41979798 0.41979798 0.41979798        nan\n",
      " 0.42424242 0.42424242 0.42424242 0.42424242        nan 0.41080808\n",
      " 0.41525253 0.41080808 0.41525253        nan 0.41080808 0.41080808\n",
      " 0.41080808 0.41979798        nan 0.41080808 0.41080808 0.41080808\n",
      " 0.41979798        nan 0.42424242 0.42424242 0.42424242 0.42424242\n",
      "        nan 0.41535354 0.41535354 0.41535354 0.41535354        nan\n",
      " 0.41979798 0.41979798 0.41979798 0.41979798        nan 0.41979798\n",
      " 0.41979798 0.41979798 0.41979798        nan 0.42424242 0.42424242\n",
      " 0.42424242 0.42424242        nan 0.41080808 0.41525253 0.41080808\n",
      " 0.41525253        nan 0.41080808 0.41080808 0.41080808 0.41979798\n",
      "        nan 0.41080808 0.41080808 0.41080808 0.41979798        nan\n",
      " 0.42424242 0.42424242 0.42424242 0.42424242        nan 0.41535354\n",
      " 0.41535354 0.41535354 0.41535354        nan 0.41979798 0.41979798\n",
      " 0.41979798 0.41979798        nan 0.41979798 0.41979798 0.41979798\n",
      " 0.41979798        nan 0.42424242 0.42424242 0.42424242 0.42424242\n",
      "        nan 0.41080808 0.41525253 0.41080808 0.41525253        nan\n",
      " 0.41080808 0.41080808 0.41080808 0.41979798        nan 0.41080808\n",
      " 0.41080808 0.41080808 0.41979798        nan 0.42424242 0.42424242\n",
      " 0.42424242 0.42424242        nan 0.41535354 0.41535354 0.41535354\n",
      " 0.41535354        nan 0.41979798 0.41979798 0.41979798 0.41979798\n",
      "        nan 0.41979798 0.41979798 0.41979798 0.41979798        nan\n",
      " 0.42424242 0.42424242 0.42424242 0.42424242]\n",
      "  warnings.warn(\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training:  0.48214285714285715\n",
      "14\n",
      "Fitting 5 folds for each of 640 candidates, totalling 3200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "640 fits failed out of a total of 3200.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "640 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan 0.28118812 0.28118812 0.28118812 0.28118812        nan\n",
      " 0.28118812 0.28118812 0.28118812 0.28118812        nan 0.28118812\n",
      " 0.28118812 0.28118812 0.28118812        nan 0.28118812 0.28118812\n",
      " 0.28118812 0.28118812        nan 0.28118812 0.28118812 0.28118812\n",
      " 0.28118812        nan 0.28118812 0.28118812 0.28118812 0.28118812\n",
      "        nan 0.28118812 0.28118812 0.28118812 0.28118812        nan\n",
      " 0.28118812 0.28118812 0.28118812 0.28118812        nan 0.31287129\n",
      " 0.31287129 0.31287129 0.31287129        nan 0.31287129 0.31287129\n",
      " 0.31287129 0.31287129        nan 0.31287129 0.31287129 0.31287129\n",
      " 0.31287129        nan 0.31287129 0.31287129 0.31287129 0.31287129\n",
      "        nan 0.31287129 0.31287129 0.31287129 0.31287129        nan\n",
      " 0.31287129 0.31287129 0.31287129 0.31287129        nan 0.31287129\n",
      " 0.31287129 0.31287129 0.31287129        nan 0.31287129 0.31287129\n",
      " 0.31287129 0.31287129        nan 0.32079208 0.32079208 0.32079208\n",
      " 0.32079208        nan 0.32079208 0.32079208 0.32079208 0.32079208\n",
      "        nan 0.32079208 0.32079208 0.32079208 0.32079208        nan\n",
      " 0.32079208 0.32079208 0.32079208 0.32079208        nan 0.32079208\n",
      " 0.32079208 0.32079208 0.32079208        nan 0.32079208 0.32079208\n",
      " 0.32079208 0.32079208        nan 0.32079208 0.32079208 0.32079208\n",
      " 0.32079208        nan 0.32079208 0.32079208 0.32079208 0.32079208\n",
      "        nan 0.30891089 0.30891089 0.30891089 0.30891089        nan\n",
      " 0.30891089 0.30891089 0.30891089 0.30891089        nan 0.30693069\n",
      " 0.30693069 0.30693069 0.30693069        nan 0.30891089 0.30891089\n",
      " 0.30891089 0.30891089        nan 0.30891089 0.30891089 0.30891089\n",
      " 0.30891089        nan 0.31089109 0.31089109 0.31089109 0.31089109\n",
      "        nan 0.31089109 0.31089109 0.31089109 0.31089109        nan\n",
      " 0.31089109 0.31089109 0.31089109 0.31089109        nan 0.29306931\n",
      " 0.29306931 0.29306931 0.29306931        nan 0.29108911 0.29108911\n",
      " 0.29108911 0.29108911        nan 0.29108911 0.29108911 0.29108911\n",
      " 0.29108911        nan 0.2950495  0.2950495  0.2950495  0.2950495\n",
      "        nan 0.2950495  0.2950495  0.2950495  0.2950495         nan\n",
      " 0.29306931 0.29306931 0.29306931 0.29306931        nan 0.29306931\n",
      " 0.29306931 0.29306931 0.29306931        nan 0.29306931 0.29306931\n",
      " 0.29306931 0.29306931        nan 0.27920792 0.27920792 0.27920792\n",
      " 0.27920792        nan 0.27524752 0.27524752 0.27524752 0.27524752\n",
      "        nan 0.28712871 0.28712871 0.28712871 0.28712871        nan\n",
      " 0.3029703  0.3029703  0.3029703  0.3029703         nan 0.28712871\n",
      " 0.28712871 0.28712871 0.28712871        nan 0.27524752 0.27524752\n",
      " 0.27524752 0.27524752        nan 0.28712871 0.28712871 0.28712871\n",
      " 0.28712871        nan 0.28910891 0.28910891 0.28910891 0.28910891\n",
      "        nan 0.26930693 0.26930693 0.26930693 0.26930693        nan\n",
      " 0.27722772 0.27722772 0.27722772 0.27524752        nan 0.28316832\n",
      " 0.28316832 0.28316832 0.28316832        nan 0.3009901  0.3009901\n",
      " 0.3009901  0.3009901         nan 0.2990099  0.2990099  0.2990099\n",
      " 0.2990099         nan 0.28910891 0.28910891 0.28910891 0.28910891\n",
      "        nan 0.27722772 0.27722772 0.27722772 0.27722772        nan\n",
      " 0.27920792 0.27920792 0.27920792 0.27920792        nan 0.27524752\n",
      " 0.27524752 0.27524752 0.27326733        nan 0.27326733 0.27326733\n",
      " 0.27524752 0.27326733        nan 0.28712871 0.28712871 0.28712871\n",
      " 0.28514851        nan 0.29108911 0.29108911 0.29108911 0.29108911\n",
      "        nan 0.28910891 0.28910891 0.28910891 0.28910891        nan\n",
      " 0.27722772 0.27722772 0.27722772 0.27722772        nan 0.27722772\n",
      " 0.27722772 0.27722772 0.27722772        nan 0.27920792 0.27920792\n",
      " 0.27920792 0.27920792        nan 0.27326733 0.27326733 0.27722772\n",
      " 0.27524752        nan 0.27524752 0.27524752 0.27722772 0.27524752\n",
      "        nan 0.28712871 0.28712871 0.28712871 0.28514851        nan\n",
      " 0.29108911 0.29108911 0.29108911 0.29108911        nan 0.28910891\n",
      " 0.28910891 0.28910891 0.28910891        nan 0.27722772 0.27722772\n",
      " 0.27722772 0.27722772        nan 0.27722772 0.27722772 0.27722772\n",
      " 0.27722772        nan 0.27920792 0.27920792 0.27920792 0.27920792\n",
      "        nan 0.27326733 0.27326733 0.27722772 0.27524752        nan\n",
      " 0.27524752 0.27524752 0.27722772 0.27524752        nan 0.28712871\n",
      " 0.28712871 0.28712871 0.28514851        nan 0.29108911 0.29108911\n",
      " 0.29108911 0.29108911        nan 0.28910891 0.28910891 0.28910891\n",
      " 0.28910891        nan 0.27722772 0.27722772 0.27722772 0.27722772\n",
      "        nan 0.27722772 0.27722772 0.27722772 0.27722772        nan\n",
      " 0.27920792 0.27920792 0.27920792 0.27920792        nan 0.27326733\n",
      " 0.27326733 0.27722772 0.27524752        nan 0.27524752 0.27524752\n",
      " 0.27722772 0.27524752        nan 0.28712871 0.28712871 0.28712871\n",
      " 0.28514851        nan 0.29108911 0.29108911 0.29108911 0.29108911\n",
      "        nan 0.28910891 0.28910891 0.28910891 0.28910891        nan\n",
      " 0.27722772 0.27722772 0.27722772 0.27722772        nan 0.27722772\n",
      " 0.27722772 0.27722772 0.27722772        nan 0.27920792 0.27920792\n",
      " 0.27920792 0.27920792        nan 0.27326733 0.27326733 0.27722772\n",
      " 0.27524752        nan 0.27524752 0.27524752 0.27722772 0.27524752\n",
      "        nan 0.28712871 0.28712871 0.28712871 0.28514851        nan\n",
      " 0.29108911 0.29108911 0.29108911 0.29108911        nan 0.28910891\n",
      " 0.28910891 0.28910891 0.28910891        nan 0.27722772 0.27722772\n",
      " 0.27722772 0.27722772        nan 0.27722772 0.27722772 0.27722772\n",
      " 0.27722772        nan 0.27920792 0.27920792 0.27920792 0.27920792\n",
      "        nan 0.27326733 0.27326733 0.27722772 0.27524752        nan\n",
      " 0.27524752 0.27524752 0.27722772 0.27524752        nan 0.28712871\n",
      " 0.28712871 0.28712871 0.28514851        nan 0.29108911 0.29108911\n",
      " 0.29108911 0.29108911        nan 0.28910891 0.28910891 0.28910891\n",
      " 0.28910891        nan 0.27722772 0.27722772 0.27722772 0.27722772\n",
      "        nan 0.27722772 0.27722772 0.27722772 0.27722772        nan\n",
      " 0.27920792 0.27920792 0.27920792 0.27920792        nan 0.27326733\n",
      " 0.27326733 0.27722772 0.27524752        nan 0.27524752 0.27524752\n",
      " 0.27722772 0.27524752        nan 0.28712871 0.28712871 0.28712871\n",
      " 0.28514851        nan 0.29108911 0.29108911 0.29108911 0.29108911\n",
      "        nan 0.28910891 0.28910891 0.28910891 0.28910891        nan\n",
      " 0.27722772 0.27722772 0.27722772 0.27722772        nan 0.27722772\n",
      " 0.27722772 0.27722772 0.27722772        nan 0.27920792 0.27920792\n",
      " 0.27920792 0.27920792        nan 0.27326733 0.27326733 0.27722772\n",
      " 0.27524752        nan 0.27524752 0.27524752 0.27722772 0.27524752\n",
      "        nan 0.28712871 0.28712871 0.28712871 0.28514851        nan\n",
      " 0.29108911 0.29108911 0.29108911 0.29108911        nan 0.28910891\n",
      " 0.28910891 0.28910891 0.28910891        nan 0.27722772 0.27722772\n",
      " 0.27722772 0.27722772        nan 0.27722772 0.27722772 0.27722772\n",
      " 0.27722772        nan 0.27920792 0.27920792 0.27920792 0.27920792\n",
      "        nan 0.27326733 0.27326733 0.27722772 0.27524752        nan\n",
      " 0.27524752 0.27524752 0.27722772 0.27524752        nan 0.28712871\n",
      " 0.28712871 0.28712871 0.28514851        nan 0.29108911 0.29108911\n",
      " 0.29108911 0.29108911        nan 0.28910891 0.28910891 0.28910891\n",
      " 0.28910891        nan 0.27722772 0.27722772 0.27722772 0.27722772\n",
      "        nan 0.27722772 0.27722772 0.27722772 0.27722772        nan\n",
      " 0.27920792 0.27920792 0.27920792 0.27920792]\n",
      "  warnings.warn(\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training:  0.32475247524752476\n",
      "15\n",
      "Fitting 5 folds for each of 640 candidates, totalling 3200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "640 fits failed out of a total of 3200.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "640 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan 0.40513834 0.40513834 0.40513834 0.40513834        nan\n",
      " 0.40513834 0.40513834 0.40513834 0.40513834        nan 0.40513834\n",
      " 0.40513834 0.40513834 0.40513834        nan 0.40513834 0.40513834\n",
      " 0.40513834 0.40513834        nan 0.40513834 0.40513834 0.40513834\n",
      " 0.40513834        nan 0.40513834 0.40513834 0.40513834 0.40513834\n",
      "        nan 0.39604743 0.39604743 0.39604743 0.39604743        nan\n",
      " 0.39604743 0.39604743 0.39604743 0.39604743        nan 0.40513834\n",
      " 0.40513834 0.40513834 0.40513834        nan 0.40513834 0.40513834\n",
      " 0.40513834 0.40513834        nan 0.41383399 0.41383399 0.41383399\n",
      " 0.41383399        nan 0.44110672 0.44110672 0.44110672 0.44110672\n",
      "        nan 0.44110672 0.44110672 0.44110672 0.44110672        nan\n",
      " 0.44110672 0.44110672 0.44110672 0.44110672        nan 0.45889328\n",
      " 0.45889328 0.45889328 0.45889328        nan 0.44071146 0.44071146\n",
      " 0.44071146 0.44071146        nan 0.4229249  0.4229249  0.4229249\n",
      " 0.4229249         nan 0.41383399 0.41383399 0.41383399 0.41383399\n",
      "        nan 0.42252964 0.42252964 0.42252964 0.42252964        nan\n",
      " 0.45889328 0.45889328 0.45889328 0.45889328        nan 0.45889328\n",
      " 0.45889328 0.45889328 0.45889328        nan 0.45889328 0.45889328\n",
      " 0.45889328 0.45889328        nan 0.45889328 0.45889328 0.45889328\n",
      " 0.45889328        nan 0.45889328 0.45889328 0.45889328 0.45889328\n",
      "        nan 0.45019763 0.45019763 0.45889328 0.45889328        nan\n",
      " 0.44110672 0.44110672 0.44980237 0.44980237        nan 0.44071146\n",
      " 0.44071146 0.44071146 0.44071146        nan 0.45889328 0.45889328\n",
      " 0.45889328 0.45889328        nan 0.45889328 0.45889328 0.45889328\n",
      " 0.45889328        nan 0.45889328 0.45889328 0.45889328 0.45889328\n",
      "        nan 0.45889328 0.45889328 0.45889328 0.45889328        nan\n",
      " 0.45889328 0.45889328 0.45889328 0.45889328        nan 0.45889328\n",
      " 0.45889328 0.46758893 0.46758893        nan 0.45889328 0.45889328\n",
      " 0.46758893 0.46758893        nan 0.44071146 0.44071146 0.44071146\n",
      " 0.44071146        nan 0.45889328 0.45889328 0.45889328 0.45889328\n",
      "        nan 0.45889328 0.45889328 0.45889328 0.45889328        nan\n",
      " 0.45889328 0.45889328 0.45889328 0.45889328        nan 0.45889328\n",
      " 0.45889328 0.45889328 0.45889328        nan 0.45889328 0.45889328\n",
      " 0.45889328 0.45889328        nan 0.45889328 0.45889328 0.47667984\n",
      " 0.47667984        nan 0.46798419 0.46798419 0.47667984 0.47667984\n",
      "        nan 0.44980237 0.44980237 0.44980237 0.44980237        nan\n",
      " 0.45889328 0.45889328 0.45889328 0.45889328        nan 0.45889328\n",
      " 0.45889328 0.45889328 0.45889328        nan 0.45889328 0.45889328\n",
      " 0.45889328 0.45889328        nan 0.45889328 0.45889328 0.45889328\n",
      " 0.45889328        nan 0.45889328 0.45889328 0.45889328 0.45889328\n",
      "        nan 0.45889328 0.45889328 0.47667984 0.47667984        nan\n",
      " 0.46798419 0.46798419 0.47667984 0.47667984        nan 0.44980237\n",
      " 0.44980237 0.44980237 0.44980237        nan 0.45889328 0.45889328\n",
      " 0.45889328 0.45889328        nan 0.45889328 0.45889328 0.45889328\n",
      " 0.45889328        nan 0.45889328 0.45889328 0.45889328 0.45889328\n",
      "        nan 0.45889328 0.45889328 0.45889328 0.45889328        nan\n",
      " 0.45889328 0.45889328 0.45889328 0.45889328        nan 0.45889328\n",
      " 0.45889328 0.47667984 0.47667984        nan 0.46798419 0.46798419\n",
      " 0.47667984 0.47667984        nan 0.44980237 0.44980237 0.44980237\n",
      " 0.44980237        nan 0.45889328 0.45889328 0.45889328 0.45889328\n",
      "        nan 0.45889328 0.45889328 0.45889328 0.45889328        nan\n",
      " 0.45889328 0.45889328 0.45889328 0.45889328        nan 0.45889328\n",
      " 0.45889328 0.45889328 0.45889328        nan 0.45889328 0.45889328\n",
      " 0.45889328 0.45889328        nan 0.45889328 0.45889328 0.47667984\n",
      " 0.47667984        nan 0.46798419 0.46798419 0.47667984 0.47667984\n",
      "        nan 0.44980237 0.44980237 0.44980237 0.44980237        nan\n",
      " 0.45889328 0.45889328 0.45889328 0.45889328        nan 0.45889328\n",
      " 0.45889328 0.45889328 0.45889328        nan 0.45889328 0.45889328\n",
      " 0.45889328 0.45889328        nan 0.45889328 0.45889328 0.45889328\n",
      " 0.45889328        nan 0.45889328 0.45889328 0.45889328 0.45889328\n",
      "        nan 0.45889328 0.45889328 0.47667984 0.47667984        nan\n",
      " 0.46798419 0.46798419 0.47667984 0.47667984        nan 0.44980237\n",
      " 0.44980237 0.44980237 0.44980237        nan 0.45889328 0.45889328\n",
      " 0.45889328 0.45889328        nan 0.45889328 0.45889328 0.45889328\n",
      " 0.45889328        nan 0.45889328 0.45889328 0.45889328 0.45889328\n",
      "        nan 0.45889328 0.45889328 0.45889328 0.45889328        nan\n",
      " 0.45889328 0.45889328 0.45889328 0.45889328        nan 0.45889328\n",
      " 0.45889328 0.47667984 0.47667984        nan 0.46798419 0.46798419\n",
      " 0.47667984 0.47667984        nan 0.44980237 0.44980237 0.44980237\n",
      " 0.44980237        nan 0.45889328 0.45889328 0.45889328 0.45889328\n",
      "        nan 0.45889328 0.45889328 0.45889328 0.45889328        nan\n",
      " 0.45889328 0.45889328 0.45889328 0.45889328        nan 0.45889328\n",
      " 0.45889328 0.45889328 0.45889328        nan 0.45889328 0.45889328\n",
      " 0.45889328 0.45889328        nan 0.45889328 0.45889328 0.47667984\n",
      " 0.47667984        nan 0.46798419 0.46798419 0.47667984 0.47667984\n",
      "        nan 0.44980237 0.44980237 0.44980237 0.44980237        nan\n",
      " 0.45889328 0.45889328 0.45889328 0.45889328        nan 0.45889328\n",
      " 0.45889328 0.45889328 0.45889328        nan 0.45889328 0.45889328\n",
      " 0.45889328 0.45889328        nan 0.45889328 0.45889328 0.45889328\n",
      " 0.45889328        nan 0.45889328 0.45889328 0.45889328 0.45889328\n",
      "        nan 0.45889328 0.45889328 0.47667984 0.47667984        nan\n",
      " 0.46798419 0.46798419 0.47667984 0.47667984        nan 0.44980237\n",
      " 0.44980237 0.44980237 0.44980237        nan 0.45889328 0.45889328\n",
      " 0.45889328 0.45889328        nan 0.45889328 0.45889328 0.45889328\n",
      " 0.45889328        nan 0.45889328 0.45889328 0.45889328 0.45889328\n",
      "        nan 0.45889328 0.45889328 0.45889328 0.45889328        nan\n",
      " 0.45889328 0.45889328 0.45889328 0.45889328        nan 0.45889328\n",
      " 0.45889328 0.47667984 0.47667984        nan 0.46798419 0.46798419\n",
      " 0.47667984 0.47667984        nan 0.44980237 0.44980237 0.44980237\n",
      " 0.44980237        nan 0.45889328 0.45889328 0.45889328 0.45889328\n",
      "        nan 0.45889328 0.45889328 0.45889328 0.45889328        nan\n",
      " 0.45889328 0.45889328 0.45889328 0.45889328        nan 0.45889328\n",
      " 0.45889328 0.45889328 0.45889328        nan 0.45889328 0.45889328\n",
      " 0.45889328 0.45889328        nan 0.45889328 0.45889328 0.47667984\n",
      " 0.47667984        nan 0.46798419 0.46798419 0.47667984 0.47667984\n",
      "        nan 0.44980237 0.44980237 0.44980237 0.44980237        nan\n",
      " 0.45889328 0.45889328 0.45889328 0.45889328        nan 0.45889328\n",
      " 0.45889328 0.45889328 0.45889328        nan 0.45889328 0.45889328\n",
      " 0.45889328 0.45889328        nan 0.45889328 0.45889328 0.45889328\n",
      " 0.45889328        nan 0.45889328 0.45889328 0.45889328 0.45889328\n",
      "        nan 0.45889328 0.45889328 0.47667984 0.47667984        nan\n",
      " 0.46798419 0.46798419 0.47667984 0.47667984        nan 0.44980237\n",
      " 0.44980237 0.44980237 0.44980237        nan 0.45889328 0.45889328\n",
      " 0.45889328 0.45889328        nan 0.45889328 0.45889328 0.45889328\n",
      " 0.45889328        nan 0.45889328 0.45889328 0.45889328 0.45889328\n",
      "        nan 0.45889328 0.45889328 0.45889328 0.45889328        nan\n",
      " 0.45889328 0.45889328 0.45889328 0.45889328]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training:  0.5135135135135135\n",
      "16\n",
      "Fitting 5 folds for each of 640 candidates, totalling 3200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "640 fits failed out of a total of 3200.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "640 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan 0.28952381 0.28952381 0.28952381 0.28952381        nan\n",
      " 0.28952381 0.28952381 0.28952381 0.28952381        nan 0.28952381\n",
      " 0.28952381 0.28952381 0.28952381        nan 0.28952381 0.28952381\n",
      " 0.28952381 0.28952381        nan 0.28952381 0.28952381 0.28952381\n",
      " 0.28952381        nan 0.28952381 0.28952381 0.28952381 0.28952381\n",
      "        nan 0.28952381 0.28952381 0.28952381 0.28952381        nan\n",
      " 0.28952381 0.28952381 0.28952381 0.28952381        nan 0.28952381\n",
      " 0.28952381 0.28952381 0.28952381        nan 0.28952381 0.28952381\n",
      " 0.28952381 0.28952381        nan 0.28952381 0.28952381 0.28952381\n",
      " 0.28952381        nan 0.28952381 0.28952381 0.28952381 0.28952381\n",
      "        nan 0.28952381 0.28952381 0.28952381 0.28952381        nan\n",
      " 0.28952381 0.28952381 0.28952381 0.28952381        nan 0.28952381\n",
      " 0.28952381 0.28952381 0.28952381        nan 0.28761905 0.28761905\n",
      " 0.28761905 0.28761905        nan 0.2952381  0.2952381  0.2952381\n",
      " 0.2952381         nan 0.2952381  0.2952381  0.2952381  0.2952381\n",
      "        nan 0.2952381  0.2952381  0.2952381  0.2952381         nan\n",
      " 0.2952381  0.2952381  0.2952381  0.2952381         nan 0.29333333\n",
      " 0.29333333 0.29333333 0.29333333        nan 0.28380952 0.28380952\n",
      " 0.28380952 0.28380952        nan 0.28380952 0.28380952 0.28380952\n",
      " 0.28380952        nan 0.28       0.28       0.28       0.28\n",
      "        nan 0.27619048 0.27619048 0.27619048 0.27619048        nan\n",
      " 0.27428571 0.27428571 0.27809524 0.27809524        nan 0.27809524\n",
      " 0.27809524 0.27809524 0.27809524        nan 0.28761905 0.28761905\n",
      " 0.28761905 0.28761905        nan 0.28571429 0.28571429 0.28571429\n",
      " 0.28571429        nan 0.29333333 0.29333333 0.29333333 0.29333333\n",
      "        nan 0.28380952 0.28380952 0.28380952 0.28380952        nan\n",
      " 0.28       0.28       0.28       0.28              nan 0.27238095\n",
      " 0.27238095 0.27238095 0.27238095        nan 0.27428571 0.27428571\n",
      " 0.28       0.28              nan 0.27809524 0.27809524 0.28\n",
      " 0.28              nan 0.28380952 0.28380952 0.28380952 0.28380952\n",
      "        nan 0.28380952 0.28380952 0.28380952 0.28380952        nan\n",
      " 0.28761905 0.28761905 0.28761905 0.28761905        nan 0.27809524\n",
      " 0.27809524 0.27809524 0.27809524        nan 0.27238095 0.27238095\n",
      " 0.27238095 0.27238095        nan 0.25904762 0.25904762 0.25904762\n",
      " 0.25904762        nan 0.25714286 0.25714286 0.26285714 0.2647619\n",
      "        nan 0.26095238 0.26095238 0.26285714 0.2647619         nan\n",
      " 0.27428571 0.27428571 0.27428571 0.27428571        nan 0.28190476\n",
      " 0.28190476 0.28190476 0.28190476        nan 0.28571429 0.28571429\n",
      " 0.28571429 0.28571429        nan 0.27428571 0.27428571 0.27428571\n",
      " 0.27428571        nan 0.27238095 0.27238095 0.27238095 0.27238095\n",
      "        nan 0.25904762 0.25904762 0.25904762 0.25904762        nan\n",
      " 0.25714286 0.25714286 0.26285714 0.2647619         nan 0.26095238\n",
      " 0.26095238 0.26285714 0.2647619         nan 0.27428571 0.27428571\n",
      " 0.27428571 0.27428571        nan 0.28190476 0.28190476 0.28190476\n",
      " 0.28190476        nan 0.28571429 0.28571429 0.28571429 0.28571429\n",
      "        nan 0.27428571 0.27428571 0.27428571 0.27428571        nan\n",
      " 0.27238095 0.27238095 0.27238095 0.27238095        nan 0.25904762\n",
      " 0.25904762 0.25904762 0.25904762        nan 0.25714286 0.25714286\n",
      " 0.26285714 0.2647619         nan 0.26095238 0.26095238 0.26285714\n",
      " 0.2647619         nan 0.27428571 0.27428571 0.27428571 0.27428571\n",
      "        nan 0.28190476 0.28190476 0.28190476 0.28190476        nan\n",
      " 0.28571429 0.28571429 0.28571429 0.28571429        nan 0.27428571\n",
      " 0.27428571 0.27428571 0.27428571        nan 0.27238095 0.27238095\n",
      " 0.27238095 0.27238095        nan 0.25904762 0.25904762 0.25904762\n",
      " 0.25904762        nan 0.25714286 0.25714286 0.26285714 0.2647619\n",
      "        nan 0.26095238 0.26095238 0.26285714 0.2647619         nan\n",
      " 0.27428571 0.27428571 0.27428571 0.27428571        nan 0.28190476\n",
      " 0.28190476 0.28190476 0.28190476        nan 0.28571429 0.28571429\n",
      " 0.28571429 0.28571429        nan 0.27428571 0.27428571 0.27428571\n",
      " 0.27428571        nan 0.27238095 0.27238095 0.27238095 0.27238095\n",
      "        nan 0.25904762 0.25904762 0.25904762 0.25904762        nan\n",
      " 0.25714286 0.25714286 0.26285714 0.2647619         nan 0.26095238\n",
      " 0.26095238 0.26285714 0.2647619         nan 0.27428571 0.27428571\n",
      " 0.27428571 0.27428571        nan 0.28190476 0.28190476 0.28190476\n",
      " 0.28190476        nan 0.28571429 0.28571429 0.28571429 0.28571429\n",
      "        nan 0.27428571 0.27428571 0.27428571 0.27428571        nan\n",
      " 0.27238095 0.27238095 0.27238095 0.27238095        nan 0.25904762\n",
      " 0.25904762 0.25904762 0.25904762        nan 0.25714286 0.25714286\n",
      " 0.26285714 0.2647619         nan 0.26095238 0.26095238 0.26285714\n",
      " 0.2647619         nan 0.27428571 0.27428571 0.27428571 0.27428571\n",
      "        nan 0.28190476 0.28190476 0.28190476 0.28190476        nan\n",
      " 0.28571429 0.28571429 0.28571429 0.28571429        nan 0.27428571\n",
      " 0.27428571 0.27428571 0.27428571        nan 0.27238095 0.27238095\n",
      " 0.27238095 0.27238095        nan 0.25904762 0.25904762 0.25904762\n",
      " 0.25904762        nan 0.25714286 0.25714286 0.26285714 0.2647619\n",
      "        nan 0.26095238 0.26095238 0.26285714 0.2647619         nan\n",
      " 0.27428571 0.27428571 0.27428571 0.27428571        nan 0.28190476\n",
      " 0.28190476 0.28190476 0.28190476        nan 0.28571429 0.28571429\n",
      " 0.28571429 0.28571429        nan 0.27428571 0.27428571 0.27428571\n",
      " 0.27428571        nan 0.27238095 0.27238095 0.27238095 0.27238095\n",
      "        nan 0.25904762 0.25904762 0.25904762 0.25904762        nan\n",
      " 0.25714286 0.25714286 0.26285714 0.2647619         nan 0.26095238\n",
      " 0.26095238 0.26285714 0.2647619         nan 0.27428571 0.27428571\n",
      " 0.27428571 0.27428571        nan 0.28190476 0.28190476 0.28190476\n",
      " 0.28190476        nan 0.28571429 0.28571429 0.28571429 0.28571429\n",
      "        nan 0.27428571 0.27428571 0.27428571 0.27428571        nan\n",
      " 0.27238095 0.27238095 0.27238095 0.27238095        nan 0.25904762\n",
      " 0.25904762 0.25904762 0.25904762        nan 0.25714286 0.25714286\n",
      " 0.26285714 0.2647619         nan 0.26095238 0.26095238 0.26285714\n",
      " 0.2647619         nan 0.27428571 0.27428571 0.27428571 0.27428571\n",
      "        nan 0.28190476 0.28190476 0.28190476 0.28190476        nan\n",
      " 0.28571429 0.28571429 0.28571429 0.28571429        nan 0.27428571\n",
      " 0.27428571 0.27428571 0.27428571        nan 0.27238095 0.27238095\n",
      " 0.27238095 0.27238095        nan 0.25904762 0.25904762 0.25904762\n",
      " 0.25904762        nan 0.25714286 0.25714286 0.26285714 0.2647619\n",
      "        nan 0.26095238 0.26095238 0.26285714 0.2647619         nan\n",
      " 0.27428571 0.27428571 0.27428571 0.27428571        nan 0.28190476\n",
      " 0.28190476 0.28190476 0.28190476        nan 0.28571429 0.28571429\n",
      " 0.28571429 0.28571429        nan 0.27428571 0.27428571 0.27428571\n",
      " 0.27428571        nan 0.27238095 0.27238095 0.27238095 0.27238095\n",
      "        nan 0.25904762 0.25904762 0.25904762 0.25904762        nan\n",
      " 0.25714286 0.25714286 0.26285714 0.2647619         nan 0.26095238\n",
      " 0.26095238 0.26285714 0.2647619         nan 0.27428571 0.27428571\n",
      " 0.27428571 0.27428571        nan 0.28190476 0.28190476 0.28190476\n",
      " 0.28190476        nan 0.28571429 0.28571429 0.28571429 0.28571429\n",
      "        nan 0.27428571 0.27428571 0.27428571 0.27428571        nan\n",
      " 0.27238095 0.27238095 0.27238095 0.27238095]\n",
      "  warnings.warn(\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training:  0.31047619047619046\n",
      "17\n",
      "Fitting 5 folds for each of 640 candidates, totalling 3200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "640 fits failed out of a total of 3200.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "640 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan 0.36780488 0.36780488 0.36780488 0.36780488        nan\n",
      " 0.36780488 0.36780488 0.36780488 0.36780488        nan 0.36780488\n",
      " 0.36780488 0.36780488 0.36780488        nan 0.35804878 0.35804878\n",
      " 0.35804878 0.35804878        nan 0.35804878 0.35804878 0.35804878\n",
      " 0.35804878        nan 0.35804878 0.35804878 0.35804878 0.35804878\n",
      "        nan 0.35804878 0.35804878 0.35804878 0.35804878        nan\n",
      " 0.35804878 0.35804878 0.35804878 0.35804878        nan 0.36780488\n",
      " 0.36780488 0.36780488 0.36780488        nan 0.36780488 0.36780488\n",
      " 0.36780488 0.36780488        nan 0.36780488 0.36780488 0.36780488\n",
      " 0.36780488        nan 0.35304878 0.35304878 0.35304878 0.35304878\n",
      "        nan 0.35317073 0.35317073 0.35317073 0.35317073        nan\n",
      " 0.35317073 0.35317073 0.35317073 0.35317073        nan 0.35317073\n",
      " 0.35317073 0.35317073 0.35317073        nan 0.35804878 0.35804878\n",
      " 0.35804878 0.35804878        nan 0.36280488 0.36280488 0.36280488\n",
      " 0.36280488        nan 0.35304878 0.35304878 0.35304878 0.36280488\n",
      "        nan 0.34817073 0.34817073 0.34817073 0.35792683        nan\n",
      " 0.34817073 0.34817073 0.34817073 0.34817073        nan 0.34829268\n",
      " 0.34829268 0.34829268 0.34829268        nan 0.34829268 0.34829268\n",
      " 0.34829268 0.34829268        nan 0.35317073 0.35317073 0.35317073\n",
      " 0.35317073        nan 0.35804878 0.35804878 0.35804878 0.35804878\n",
      "        nan 0.36780488 0.36780488 0.36280488 0.36280488        nan\n",
      " 0.35304878 0.35304878 0.35292683 0.36268293        nan 0.34804878\n",
      " 0.34804878 0.34804878 0.35292683        nan 0.34817073 0.34817073\n",
      " 0.34817073 0.34817073        nan 0.34829268 0.34829268 0.34829268\n",
      " 0.34829268        nan 0.34829268 0.34829268 0.34829268 0.34829268\n",
      "        nan 0.35317073 0.35317073 0.35317073 0.35317073        nan\n",
      " 0.35804878 0.35804878 0.35804878 0.35804878        nan 0.35780488\n",
      " 0.36280488 0.35780488 0.35780488        nan 0.35304878 0.35304878\n",
      " 0.35292683 0.36268293        nan 0.34317073 0.34317073 0.34317073\n",
      " 0.34804878        nan 0.34817073 0.34817073 0.34817073 0.34817073\n",
      "        nan 0.34829268 0.34829268 0.34829268 0.34829268        nan\n",
      " 0.34829268 0.34829268 0.34829268 0.34829268        nan 0.35317073\n",
      " 0.35317073 0.35317073 0.35317073        nan 0.35804878 0.35804878\n",
      " 0.35804878 0.35804878        nan 0.34804878 0.35304878 0.34804878\n",
      " 0.35292683        nan 0.34817073 0.34817073 0.34804878 0.35780488\n",
      "        nan 0.34317073 0.34317073 0.34317073 0.34804878        nan\n",
      " 0.34817073 0.34817073 0.34817073 0.34817073        nan 0.34829268\n",
      " 0.34829268 0.34829268 0.34829268        nan 0.34829268 0.34829268\n",
      " 0.34829268 0.34829268        nan 0.35317073 0.35317073 0.35317073\n",
      " 0.35317073        nan 0.35804878 0.35804878 0.35804878 0.35804878\n",
      "        nan 0.34317073 0.34817073 0.34804878 0.35292683        nan\n",
      " 0.34817073 0.34817073 0.34804878 0.35780488        nan 0.34317073\n",
      " 0.34317073 0.34317073 0.34804878        nan 0.34817073 0.34817073\n",
      " 0.34817073 0.34817073        nan 0.34829268 0.34829268 0.34829268\n",
      " 0.34829268        nan 0.34829268 0.34829268 0.34829268 0.34829268\n",
      "        nan 0.35317073 0.35317073 0.35317073 0.35317073        nan\n",
      " 0.35804878 0.35804878 0.35804878 0.35804878        nan 0.34317073\n",
      " 0.34817073 0.34804878 0.35292683        nan 0.34817073 0.34817073\n",
      " 0.34804878 0.35780488        nan 0.34317073 0.34317073 0.34317073\n",
      " 0.34804878        nan 0.34817073 0.34817073 0.34817073 0.34817073\n",
      "        nan 0.34829268 0.34829268 0.34829268 0.34829268        nan\n",
      " 0.34829268 0.34829268 0.34829268 0.34829268        nan 0.35317073\n",
      " 0.35317073 0.35317073 0.35317073        nan 0.35804878 0.35804878\n",
      " 0.35804878 0.35804878        nan 0.34317073 0.34817073 0.34804878\n",
      " 0.35292683        nan 0.34817073 0.34817073 0.34804878 0.35780488\n",
      "        nan 0.34317073 0.34317073 0.34317073 0.34804878        nan\n",
      " 0.34817073 0.34817073 0.34817073 0.34817073        nan 0.34829268\n",
      " 0.34829268 0.34829268 0.34829268        nan 0.34829268 0.34829268\n",
      " 0.34829268 0.34829268        nan 0.35317073 0.35317073 0.35317073\n",
      " 0.35317073        nan 0.35804878 0.35804878 0.35804878 0.35804878\n",
      "        nan 0.34317073 0.34817073 0.34804878 0.35292683        nan\n",
      " 0.34817073 0.34817073 0.34804878 0.35780488        nan 0.34317073\n",
      " 0.34317073 0.34317073 0.34804878        nan 0.34817073 0.34817073\n",
      " 0.34817073 0.34817073        nan 0.34829268 0.34829268 0.34829268\n",
      " 0.34829268        nan 0.34829268 0.34829268 0.34829268 0.34829268\n",
      "        nan 0.35317073 0.35317073 0.35317073 0.35317073        nan\n",
      " 0.35804878 0.35804878 0.35804878 0.35804878        nan 0.34317073\n",
      " 0.34817073 0.34804878 0.35292683        nan 0.34817073 0.34817073\n",
      " 0.34804878 0.35780488        nan 0.34317073 0.34317073 0.34317073\n",
      " 0.34804878        nan 0.34817073 0.34817073 0.34817073 0.34817073\n",
      "        nan 0.34829268 0.34829268 0.34829268 0.34829268        nan\n",
      " 0.34829268 0.34829268 0.34829268 0.34829268        nan 0.35317073\n",
      " 0.35317073 0.35317073 0.35317073        nan 0.35804878 0.35804878\n",
      " 0.35804878 0.35804878        nan 0.34317073 0.34817073 0.34804878\n",
      " 0.35292683        nan 0.34817073 0.34817073 0.34804878 0.35780488\n",
      "        nan 0.34317073 0.34317073 0.34317073 0.34804878        nan\n",
      " 0.34817073 0.34817073 0.34817073 0.34817073        nan 0.34829268\n",
      " 0.34829268 0.34829268 0.34829268        nan 0.34829268 0.34829268\n",
      " 0.34829268 0.34829268        nan 0.35317073 0.35317073 0.35317073\n",
      " 0.35317073        nan 0.35804878 0.35804878 0.35804878 0.35804878\n",
      "        nan 0.34317073 0.34817073 0.34804878 0.35292683        nan\n",
      " 0.34817073 0.34817073 0.34804878 0.35780488        nan 0.34317073\n",
      " 0.34317073 0.34317073 0.34804878        nan 0.34817073 0.34817073\n",
      " 0.34817073 0.34817073        nan 0.34829268 0.34829268 0.34829268\n",
      " 0.34829268        nan 0.34829268 0.34829268 0.34829268 0.34829268\n",
      "        nan 0.35317073 0.35317073 0.35317073 0.35317073        nan\n",
      " 0.35804878 0.35804878 0.35804878 0.35804878        nan 0.34317073\n",
      " 0.34817073 0.34804878 0.35292683        nan 0.34817073 0.34817073\n",
      " 0.34804878 0.35780488        nan 0.34317073 0.34317073 0.34317073\n",
      " 0.34804878        nan 0.34817073 0.34817073 0.34817073 0.34817073\n",
      "        nan 0.34829268 0.34829268 0.34829268 0.34829268        nan\n",
      " 0.34829268 0.34829268 0.34829268 0.34829268        nan 0.35317073\n",
      " 0.35317073 0.35317073 0.35317073        nan 0.35804878 0.35804878\n",
      " 0.35804878 0.35804878        nan 0.34317073 0.34817073 0.34804878\n",
      " 0.35292683        nan 0.34817073 0.34817073 0.34804878 0.35780488\n",
      "        nan 0.34317073 0.34317073 0.34317073 0.34804878        nan\n",
      " 0.34817073 0.34817073 0.34817073 0.34817073        nan 0.34829268\n",
      " 0.34829268 0.34829268 0.34829268        nan 0.34829268 0.34829268\n",
      " 0.34829268 0.34829268        nan 0.35317073 0.35317073 0.35317073\n",
      " 0.35317073        nan 0.35804878 0.35804878 0.35804878 0.35804878\n",
      "        nan 0.34317073 0.34817073 0.34804878 0.35292683        nan\n",
      " 0.34817073 0.34817073 0.34804878 0.35780488        nan 0.34317073\n",
      " 0.34317073 0.34317073 0.34804878        nan 0.34817073 0.34817073\n",
      " 0.34817073 0.34817073        nan 0.34829268 0.34829268 0.34829268\n",
      " 0.34829268        nan 0.34829268 0.34829268 0.34829268 0.34829268\n",
      "        nan 0.35317073 0.35317073 0.35317073 0.35317073        nan\n",
      " 0.35804878 0.35804878 0.35804878 0.35804878]\n",
      "  warnings.warn(\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training:  0.37745098039215685\n",
      "18\n",
      "Fitting 5 folds for each of 640 candidates, totalling 3200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "640 fits failed out of a total of 3200.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "640 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan 0.53938462 0.53938462 0.53938462 0.53938462        nan\n",
      " 0.53938462 0.53938462 0.53938462 0.53938462        nan 0.53938462\n",
      " 0.53938462 0.53938462 0.53938462        nan 0.53138462 0.53138462\n",
      " 0.53138462 0.53138462        nan 0.53138462 0.53138462 0.53138462\n",
      " 0.53138462        nan 0.53138462 0.53138462 0.53138462 0.53138462\n",
      "        nan 0.52369231 0.52369231 0.52369231 0.52369231        nan\n",
      " 0.52369231 0.52369231 0.52369231 0.52369231        nan 0.53938462\n",
      " 0.53938462 0.53938462 0.53938462        nan 0.53938462 0.53938462\n",
      " 0.53938462 0.53938462        nan 0.53938462 0.53938462 0.53938462\n",
      " 0.53938462        nan 0.53907692 0.53907692 0.53907692 0.53907692\n",
      "        nan 0.53138462 0.53138462 0.53138462 0.53138462        nan\n",
      " 0.53138462 0.53138462 0.53138462 0.53138462        nan 0.52369231\n",
      " 0.52369231 0.52369231 0.52369231        nan 0.52369231 0.52369231\n",
      " 0.52369231 0.52369231        nan 0.53907692 0.53907692 0.54676923\n",
      " 0.54676923        nan 0.53907692 0.53907692 0.54676923 0.54676923\n",
      "        nan 0.54676923 0.54676923 0.54676923 0.54676923        nan\n",
      " 0.53907692 0.53907692 0.53907692 0.53907692        nan 0.53138462\n",
      " 0.53138462 0.53138462 0.53138462        nan 0.53138462 0.53138462\n",
      " 0.53138462 0.53138462        nan 0.52369231 0.52369231 0.52369231\n",
      " 0.52369231        nan 0.52369231 0.52369231 0.52369231 0.52369231\n",
      "        nan 0.53876923 0.53876923 0.54646154 0.54646154        nan\n",
      " 0.53107692 0.53107692 0.53876923 0.53876923        nan 0.53876923\n",
      " 0.53876923 0.53876923 0.53876923        nan 0.55446154 0.55446154\n",
      " 0.55446154 0.55446154        nan 0.53138462 0.53138462 0.53138462\n",
      " 0.53138462        nan 0.53138462 0.53138462 0.53138462 0.53138462\n",
      "        nan 0.52369231 0.52369231 0.52369231 0.52369231        nan\n",
      " 0.52369231 0.52369231 0.52369231 0.52369231        nan 0.53876923\n",
      " 0.53876923 0.54646154 0.54646154        nan 0.52338462 0.52338462\n",
      " 0.54646154 0.54646154        nan 0.53076923 0.53076923 0.53076923\n",
      " 0.53076923        nan 0.55446154 0.55446154 0.55446154 0.55446154\n",
      "        nan 0.53138462 0.53138462 0.53138462 0.53138462        nan\n",
      " 0.53138462 0.53138462 0.53138462 0.53138462        nan 0.52369231\n",
      " 0.52369231 0.52369231 0.52369231        nan 0.52369231 0.52369231\n",
      " 0.52369231 0.52369231        nan 0.50738462 0.51538462 0.53846154\n",
      " 0.53846154        nan 0.49938462 0.49938462 0.52246154 0.53846154\n",
      "        nan 0.50676923 0.50676923 0.50676923 0.51476923        nan\n",
      " 0.55446154 0.55446154 0.55446154 0.55446154        nan 0.53138462\n",
      " 0.53138462 0.53138462 0.53138462        nan 0.53138462 0.53138462\n",
      " 0.53138462 0.53138462        nan 0.52369231 0.52369231 0.52369231\n",
      " 0.52369231        nan 0.52369231 0.52369231 0.52369231 0.52369231\n",
      "        nan 0.49138462 0.49938462 0.52246154 0.53846154        nan\n",
      " 0.49938462 0.49938462 0.52246154 0.53846154        nan 0.50676923\n",
      " 0.50676923 0.50676923 0.51476923        nan 0.55446154 0.55446154\n",
      " 0.55446154 0.55446154        nan 0.53138462 0.53138462 0.53138462\n",
      " 0.53138462        nan 0.53138462 0.53138462 0.53138462 0.53138462\n",
      "        nan 0.52369231 0.52369231 0.52369231 0.52369231        nan\n",
      " 0.52369231 0.52369231 0.52369231 0.52369231        nan 0.49138462\n",
      " 0.49938462 0.52246154 0.53846154        nan 0.49938462 0.49938462\n",
      " 0.52246154 0.53846154        nan 0.50676923 0.50676923 0.50676923\n",
      " 0.51476923        nan 0.55446154 0.55446154 0.55446154 0.55446154\n",
      "        nan 0.53138462 0.53138462 0.53138462 0.53138462        nan\n",
      " 0.53138462 0.53138462 0.53138462 0.53138462        nan 0.52369231\n",
      " 0.52369231 0.52369231 0.52369231        nan 0.52369231 0.52369231\n",
      " 0.52369231 0.52369231        nan 0.49138462 0.49938462 0.52246154\n",
      " 0.53846154        nan 0.49938462 0.49938462 0.52246154 0.53846154\n",
      "        nan 0.50676923 0.50676923 0.50676923 0.51476923        nan\n",
      " 0.55446154 0.55446154 0.55446154 0.55446154        nan 0.53138462\n",
      " 0.53138462 0.53138462 0.53138462        nan 0.53138462 0.53138462\n",
      " 0.53138462 0.53138462        nan 0.52369231 0.52369231 0.52369231\n",
      " 0.52369231        nan 0.52369231 0.52369231 0.52369231 0.52369231\n",
      "        nan 0.49138462 0.49938462 0.52246154 0.53846154        nan\n",
      " 0.49938462 0.49938462 0.52246154 0.53846154        nan 0.50676923\n",
      " 0.50676923 0.50676923 0.51476923        nan 0.55446154 0.55446154\n",
      " 0.55446154 0.55446154        nan 0.53138462 0.53138462 0.53138462\n",
      " 0.53138462        nan 0.53138462 0.53138462 0.53138462 0.53138462\n",
      "        nan 0.52369231 0.52369231 0.52369231 0.52369231        nan\n",
      " 0.52369231 0.52369231 0.52369231 0.52369231        nan 0.49138462\n",
      " 0.49938462 0.52246154 0.53846154        nan 0.49938462 0.49938462\n",
      " 0.52246154 0.53846154        nan 0.50676923 0.50676923 0.50676923\n",
      " 0.51476923        nan 0.55446154 0.55446154 0.55446154 0.55446154\n",
      "        nan 0.53138462 0.53138462 0.53138462 0.53138462        nan\n",
      " 0.53138462 0.53138462 0.53138462 0.53138462        nan 0.52369231\n",
      " 0.52369231 0.52369231 0.52369231        nan 0.52369231 0.52369231\n",
      " 0.52369231 0.52369231        nan 0.49138462 0.49938462 0.52246154\n",
      " 0.53846154        nan 0.49938462 0.49938462 0.52246154 0.53846154\n",
      "        nan 0.50676923 0.50676923 0.50676923 0.51476923        nan\n",
      " 0.55446154 0.55446154 0.55446154 0.55446154        nan 0.53138462\n",
      " 0.53138462 0.53138462 0.53138462        nan 0.53138462 0.53138462\n",
      " 0.53138462 0.53138462        nan 0.52369231 0.52369231 0.52369231\n",
      " 0.52369231        nan 0.52369231 0.52369231 0.52369231 0.52369231\n",
      "        nan 0.49138462 0.49938462 0.52246154 0.53846154        nan\n",
      " 0.49938462 0.49938462 0.52246154 0.53846154        nan 0.50676923\n",
      " 0.50676923 0.50676923 0.51476923        nan 0.55446154 0.55446154\n",
      " 0.55446154 0.55446154        nan 0.53138462 0.53138462 0.53138462\n",
      " 0.53138462        nan 0.53138462 0.53138462 0.53138462 0.53138462\n",
      "        nan 0.52369231 0.52369231 0.52369231 0.52369231        nan\n",
      " 0.52369231 0.52369231 0.52369231 0.52369231        nan 0.49138462\n",
      " 0.49938462 0.52246154 0.53846154        nan 0.49938462 0.49938462\n",
      " 0.52246154 0.53846154        nan 0.50676923 0.50676923 0.50676923\n",
      " 0.51476923        nan 0.55446154 0.55446154 0.55446154 0.55446154\n",
      "        nan 0.53138462 0.53138462 0.53138462 0.53138462        nan\n",
      " 0.53138462 0.53138462 0.53138462 0.53138462        nan 0.52369231\n",
      " 0.52369231 0.52369231 0.52369231        nan 0.52369231 0.52369231\n",
      " 0.52369231 0.52369231        nan 0.49138462 0.49938462 0.52246154\n",
      " 0.53846154        nan 0.49938462 0.49938462 0.52246154 0.53846154\n",
      "        nan 0.50676923 0.50676923 0.50676923 0.51476923        nan\n",
      " 0.55446154 0.55446154 0.55446154 0.55446154        nan 0.53138462\n",
      " 0.53138462 0.53138462 0.53138462        nan 0.53138462 0.53138462\n",
      " 0.53138462 0.53138462        nan 0.52369231 0.52369231 0.52369231\n",
      " 0.52369231        nan 0.52369231 0.52369231 0.52369231 0.52369231\n",
      "        nan 0.49138462 0.49938462 0.52246154 0.53846154        nan\n",
      " 0.49938462 0.49938462 0.52246154 0.53846154        nan 0.50676923\n",
      " 0.50676923 0.50676923 0.51476923        nan 0.55446154 0.55446154\n",
      " 0.55446154 0.55446154        nan 0.53138462 0.53138462 0.53138462\n",
      " 0.53138462        nan 0.53138462 0.53138462 0.53138462 0.53138462\n",
      "        nan 0.52369231 0.52369231 0.52369231 0.52369231        nan\n",
      " 0.52369231 0.52369231 0.52369231 0.52369231]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training:  0.578125\n",
      "19\n",
      "Fitting 5 folds for each of 640 candidates, totalling 3200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "640 fits failed out of a total of 3200.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "640 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan 0.42682692 0.42682692 0.42682692 0.42682692        nan\n",
      " 0.42682692 0.42682692 0.42682692 0.42682692        nan 0.42682692\n",
      " 0.42682692 0.42682692 0.42682692        nan 0.42682692 0.42682692\n",
      " 0.42682692 0.42682692        nan 0.42682692 0.42682692 0.42682692\n",
      " 0.42682692        nan 0.42682692 0.42682692 0.42682692 0.42682692\n",
      "        nan 0.42682692 0.42682692 0.42682692 0.42682692        nan\n",
      " 0.42682692 0.42682692 0.42682692 0.42682692        nan 0.48620192\n",
      " 0.48620192 0.48620192 0.48620192        nan 0.48932692 0.48932692\n",
      " 0.48932692 0.48932692        nan 0.48932692 0.48932692 0.48932692\n",
      " 0.48932692        nan 0.48932692 0.48932692 0.48932692 0.48932692\n",
      "        nan 0.48932692 0.48932692 0.48932692 0.48932692        nan\n",
      " 0.48932692 0.48932692 0.48932692 0.48932692        nan 0.48932692\n",
      " 0.48932692 0.48932692 0.48932692        nan 0.48932692 0.48932692\n",
      " 0.48932692 0.48932692        nan 0.49245192 0.49245192 0.49245192\n",
      " 0.49245192        nan 0.49245192 0.49245192 0.49245192 0.49245192\n",
      "        nan 0.49245192 0.49245192 0.49245192 0.49245192        nan\n",
      " 0.489375   0.489375   0.489375   0.489375          nan 0.489375\n",
      " 0.489375   0.489375   0.489375          nan 0.48625    0.48625\n",
      " 0.48625    0.48625           nan 0.48625    0.48625    0.48625\n",
      " 0.48625           nan 0.48620192 0.48620192 0.48620192 0.48620192\n",
      "        nan 0.49870192 0.49870192 0.49870192 0.49870192        nan\n",
      " 0.49870192 0.49870192 0.49870192 0.49557692        nan 0.49870192\n",
      " 0.49870192 0.50182692 0.49870192        nan 0.489375   0.489375\n",
      " 0.489375   0.489375          nan 0.489375   0.489375   0.489375\n",
      " 0.489375          nan 0.489375   0.489375   0.489375   0.489375\n",
      "        nan 0.489375   0.489375   0.489375   0.489375          nan\n",
      " 0.48932692 0.48932692 0.48932692 0.48932692        nan 0.48\n",
      " 0.48       0.48625    0.48625           nan 0.48932692 0.48932692\n",
      " 0.48932692 0.48620192        nan 0.48932692 0.48932692 0.49245192\n",
      " 0.48932692        nan 0.48620192 0.48620192 0.48620192 0.48620192\n",
      "        nan 0.48       0.48       0.48       0.48              nan\n",
      " 0.48       0.48       0.48       0.48              nan 0.48\n",
      " 0.48       0.48       0.48              nan 0.47995192 0.47995192\n",
      " 0.47995192 0.47995192        nan 0.45192308 0.45504808 0.46129808\n",
      " 0.47067308        nan 0.46129808 0.46129808 0.46754808 0.47067308\n",
      "        nan 0.46129808 0.46129808 0.47067308 0.47379808        nan\n",
      " 0.47682692 0.47682692 0.47682692 0.47682692        nan 0.470625\n",
      " 0.470625   0.470625   0.470625          nan 0.47375    0.47375\n",
      " 0.47375    0.47375           nan 0.47375    0.47375    0.47375\n",
      " 0.47375           nan 0.47995192 0.47995192 0.47995192 0.47995192\n",
      "        nan 0.44576923 0.43951923 0.46129808 0.47067308        nan\n",
      " 0.45514423 0.45514423 0.46754808 0.47067308        nan 0.46129808\n",
      " 0.46129808 0.47067308 0.47379808        nan 0.47682692 0.47682692\n",
      " 0.47682692 0.47682692        nan 0.470625   0.470625   0.470625\n",
      " 0.470625          nan 0.47375    0.47375    0.47375    0.47375\n",
      "        nan 0.47375    0.47375    0.47375    0.47375           nan\n",
      " 0.47995192 0.47995192 0.47995192 0.47995192        nan 0.44264423\n",
      " 0.43951923 0.46442308 0.47067308        nan 0.45514423 0.45514423\n",
      " 0.46754808 0.47067308        nan 0.46129808 0.46129808 0.47067308\n",
      " 0.47379808        nan 0.47682692 0.47682692 0.47682692 0.47682692\n",
      "        nan 0.470625   0.470625   0.470625   0.470625          nan\n",
      " 0.47375    0.47375    0.47375    0.47375           nan 0.47375\n",
      " 0.47375    0.47375    0.47375           nan 0.47995192 0.47995192\n",
      " 0.47995192 0.47995192        nan 0.44576923 0.44264423 0.46442308\n",
      " 0.47067308        nan 0.45514423 0.45514423 0.46754808 0.47067308\n",
      "        nan 0.46129808 0.46129808 0.47067308 0.47379808        nan\n",
      " 0.47682692 0.47682692 0.47682692 0.47682692        nan 0.470625\n",
      " 0.470625   0.470625   0.470625          nan 0.47375    0.47375\n",
      " 0.47375    0.47375           nan 0.47375    0.47375    0.47375\n",
      " 0.47375           nan 0.47995192 0.47995192 0.47995192 0.47995192\n",
      "        nan 0.44576923 0.44264423 0.46442308 0.47067308        nan\n",
      " 0.45514423 0.45514423 0.46754808 0.47067308        nan 0.46129808\n",
      " 0.46129808 0.47067308 0.47379808        nan 0.47682692 0.47682692\n",
      " 0.47682692 0.47682692        nan 0.470625   0.470625   0.470625\n",
      " 0.470625          nan 0.47375    0.47375    0.47375    0.47375\n",
      "        nan 0.47375    0.47375    0.47375    0.47375           nan\n",
      " 0.47995192 0.47995192 0.47995192 0.47995192        nan 0.44576923\n",
      " 0.44264423 0.46442308 0.47067308        nan 0.45514423 0.45514423\n",
      " 0.46754808 0.47067308        nan 0.46129808 0.46129808 0.47067308\n",
      " 0.47379808        nan 0.47682692 0.47682692 0.47682692 0.47682692\n",
      "        nan 0.470625   0.470625   0.470625   0.470625          nan\n",
      " 0.47375    0.47375    0.47375    0.47375           nan 0.47375\n",
      " 0.47375    0.47375    0.47375           nan 0.47995192 0.47995192\n",
      " 0.47995192 0.47995192        nan 0.44576923 0.44264423 0.46442308\n",
      " 0.47067308        nan 0.45514423 0.45514423 0.46754808 0.47067308\n",
      "        nan 0.46129808 0.46129808 0.47067308 0.47379808        nan\n",
      " 0.47682692 0.47682692 0.47682692 0.47682692        nan 0.470625\n",
      " 0.470625   0.470625   0.470625          nan 0.47375    0.47375\n",
      " 0.47375    0.47375           nan 0.47375    0.47375    0.47375\n",
      " 0.47375           nan 0.47995192 0.47995192 0.47995192 0.47995192\n",
      "        nan 0.44576923 0.44264423 0.46442308 0.47067308        nan\n",
      " 0.45514423 0.45514423 0.46754808 0.47067308        nan 0.46129808\n",
      " 0.46129808 0.47067308 0.47379808        nan 0.47682692 0.47682692\n",
      " 0.47682692 0.47682692        nan 0.470625   0.470625   0.470625\n",
      " 0.470625          nan 0.47375    0.47375    0.47375    0.47375\n",
      "        nan 0.47375    0.47375    0.47375    0.47375           nan\n",
      " 0.47995192 0.47995192 0.47995192 0.47995192        nan 0.44576923\n",
      " 0.44264423 0.46442308 0.47067308        nan 0.45514423 0.45514423\n",
      " 0.46754808 0.47067308        nan 0.46129808 0.46129808 0.47067308\n",
      " 0.47379808        nan 0.47682692 0.47682692 0.47682692 0.47682692\n",
      "        nan 0.470625   0.470625   0.470625   0.470625          nan\n",
      " 0.47375    0.47375    0.47375    0.47375           nan 0.47375\n",
      " 0.47375    0.47375    0.47375           nan 0.47995192 0.47995192\n",
      " 0.47995192 0.47995192        nan 0.44576923 0.44264423 0.46442308\n",
      " 0.47067308        nan 0.45514423 0.45514423 0.46754808 0.47067308\n",
      "        nan 0.46129808 0.46129808 0.47067308 0.47379808        nan\n",
      " 0.47682692 0.47682692 0.47682692 0.47682692        nan 0.470625\n",
      " 0.470625   0.470625   0.470625          nan 0.47375    0.47375\n",
      " 0.47375    0.47375           nan 0.47375    0.47375    0.47375\n",
      " 0.47375           nan 0.47995192 0.47995192 0.47995192 0.47995192\n",
      "        nan 0.44576923 0.44264423 0.46442308 0.47067308        nan\n",
      " 0.45514423 0.45514423 0.46754808 0.47067308        nan 0.46129808\n",
      " 0.46129808 0.47067308 0.47379808        nan 0.47682692 0.47682692\n",
      " 0.47682692 0.47682692        nan 0.470625   0.470625   0.470625\n",
      " 0.470625          nan 0.47375    0.47375    0.47375    0.47375\n",
      "        nan 0.47375    0.47375    0.47375    0.47375           nan\n",
      " 0.47995192 0.47995192 0.47995192 0.47995192]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training:  0.5202492211838006\n",
      "20\n",
      "Fitting 5 folds for each of 640 candidates, totalling 3200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "640 fits failed out of a total of 3200.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "640 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan 0.41626506 0.41626506 0.41626506 0.41626506        nan\n",
      " 0.41626506 0.41626506 0.41626506 0.41626506        nan 0.41626506\n",
      " 0.41626506 0.41626506 0.41626506        nan 0.41626506 0.41626506\n",
      " 0.41626506 0.41626506        nan 0.41626506 0.41626506 0.41626506\n",
      " 0.41626506        nan 0.41626506 0.41626506 0.41626506 0.41626506\n",
      "        nan 0.41626506 0.41626506 0.41626506 0.41626506        nan\n",
      " 0.41626506 0.41626506 0.41626506 0.41626506        nan 0.41147447\n",
      " 0.41147447 0.41147447 0.41147447        nan 0.41147447 0.41147447\n",
      " 0.41147447 0.41147447        nan 0.41147447 0.41147447 0.41147447\n",
      " 0.41147447        nan 0.40671256 0.40671256 0.40671256 0.40671256\n",
      "        nan 0.40671256 0.40671256 0.40671256 0.40671256        nan\n",
      " 0.40671256 0.40671256 0.40671256 0.40671256        nan 0.40671256\n",
      " 0.40671256 0.40671256 0.40671256        nan 0.40671256 0.40671256\n",
      " 0.40671256 0.40671256        nan 0.40433161 0.40433161 0.40433161\n",
      " 0.40433161        nan 0.40433161 0.40433161 0.40433161 0.40433161\n",
      "        nan 0.40433161 0.40433161 0.40433161 0.40433161        nan\n",
      " 0.40433161 0.40433161 0.40433161 0.40433161        nan 0.40433161\n",
      " 0.40433161 0.40433161 0.40433161        nan 0.40674125 0.40674125\n",
      " 0.40674125 0.40674125        nan 0.40433161 0.40433161 0.40433161\n",
      " 0.40433161        nan 0.40671256 0.40671256 0.40671256 0.40671256\n",
      "        nan 0.40427424 0.40427424 0.40668388 0.40192197        nan\n",
      " 0.40427424 0.40427424 0.40668388 0.40192197        nan 0.40668388\n",
      " 0.40668388 0.40668388 0.40430293        nan 0.39951234 0.39951234\n",
      " 0.39951234 0.39951234        nan 0.39951234 0.39951234 0.39951234\n",
      " 0.39951234        nan 0.40192197 0.40192197 0.40192197 0.40192197\n",
      "        nan 0.39951234 0.39951234 0.39951234 0.39951234        nan\n",
      " 0.40189329 0.40189329 0.40189329 0.40189329        nan 0.41388411\n",
      " 0.41388411 0.41147447 0.40433161        nan 0.40668388 0.40668388\n",
      " 0.41147447 0.40195066        nan 0.40668388 0.40668388 0.40668388\n",
      " 0.40430293        nan 0.39951234 0.39951234 0.39951234 0.39951234\n",
      "        nan 0.40189329 0.40189329 0.40189329 0.40189329        nan\n",
      " 0.40192197 0.40192197 0.40192197 0.40192197        nan 0.39713138\n",
      " 0.39713138 0.39713138 0.39713138        nan 0.40189329 0.40189329\n",
      " 0.40189329 0.40189329        nan 0.40668388 0.40906483 0.4091222\n",
      " 0.40433161        nan 0.39707401 0.39707401 0.40427424 0.39954102\n",
      "        nan 0.39948365 0.39948365 0.39948365 0.39707401        nan\n",
      " 0.39469306 0.39469306 0.39469306 0.39469306        nan 0.39948365\n",
      " 0.39948365 0.39948365 0.39948365        nan 0.39954102 0.39954102\n",
      " 0.39954102 0.39954102        nan 0.39713138 0.39713138 0.39713138\n",
      " 0.39713138        nan 0.40189329 0.40189329 0.40189329 0.40189329\n",
      "        nan 0.40668388 0.40665519 0.40671256 0.40192197        nan\n",
      " 0.39707401 0.39707401 0.40427424 0.39954102        nan 0.39948365\n",
      " 0.39948365 0.39948365 0.39707401        nan 0.39469306 0.39469306\n",
      " 0.39469306 0.39469306        nan 0.39948365 0.39948365 0.39948365\n",
      " 0.39948365        nan 0.39954102 0.39954102 0.39954102 0.39954102\n",
      "        nan 0.39713138 0.39713138 0.39713138 0.39713138        nan\n",
      " 0.40189329 0.40189329 0.40189329 0.40189329        nan 0.4018646\n",
      " 0.40183592 0.40189329 0.40192197        nan 0.39707401 0.39707401\n",
      " 0.40427424 0.39954102        nan 0.39948365 0.39948365 0.39948365\n",
      " 0.39707401        nan 0.39469306 0.39469306 0.39469306 0.39469306\n",
      "        nan 0.39948365 0.39948365 0.39948365 0.39948365        nan\n",
      " 0.39954102 0.39954102 0.39954102 0.39954102        nan 0.39713138\n",
      " 0.39713138 0.39713138 0.39713138        nan 0.40189329 0.40189329\n",
      " 0.40189329 0.40189329        nan 0.4018646  0.40183592 0.40189329\n",
      " 0.40192197        nan 0.39707401 0.39707401 0.40427424 0.39954102\n",
      "        nan 0.39948365 0.39948365 0.39948365 0.39707401        nan\n",
      " 0.39469306 0.39469306 0.39469306 0.39469306        nan 0.39948365\n",
      " 0.39948365 0.39948365 0.39948365        nan 0.39954102 0.39954102\n",
      " 0.39954102 0.39954102        nan 0.39713138 0.39713138 0.39713138\n",
      " 0.39713138        nan 0.40189329 0.40189329 0.40189329 0.40189329\n",
      "        nan 0.4018646  0.40183592 0.40189329 0.40192197        nan\n",
      " 0.39707401 0.39707401 0.40427424 0.39954102        nan 0.39948365\n",
      " 0.39948365 0.39948365 0.39707401        nan 0.39469306 0.39469306\n",
      " 0.39469306 0.39469306        nan 0.39948365 0.39948365 0.39948365\n",
      " 0.39948365        nan 0.39954102 0.39954102 0.39954102 0.39954102\n",
      "        nan 0.39713138 0.39713138 0.39713138 0.39713138        nan\n",
      " 0.40189329 0.40189329 0.40189329 0.40189329        nan 0.4018646\n",
      " 0.40183592 0.40189329 0.40192197        nan 0.39707401 0.39707401\n",
      " 0.40427424 0.39954102        nan 0.39948365 0.39948365 0.39948365\n",
      " 0.39707401        nan 0.39469306 0.39469306 0.39469306 0.39469306\n",
      "        nan 0.39948365 0.39948365 0.39948365 0.39948365        nan\n",
      " 0.39954102 0.39954102 0.39954102 0.39954102        nan 0.39713138\n",
      " 0.39713138 0.39713138 0.39713138        nan 0.40189329 0.40189329\n",
      " 0.40189329 0.40189329        nan 0.4018646  0.40183592 0.40189329\n",
      " 0.40192197        nan 0.39707401 0.39707401 0.40427424 0.39954102\n",
      "        nan 0.39948365 0.39948365 0.39948365 0.39707401        nan\n",
      " 0.39469306 0.39469306 0.39469306 0.39469306        nan 0.39948365\n",
      " 0.39948365 0.39948365 0.39948365        nan 0.39954102 0.39954102\n",
      " 0.39954102 0.39954102        nan 0.39713138 0.39713138 0.39713138\n",
      " 0.39713138        nan 0.40189329 0.40189329 0.40189329 0.40189329\n",
      "        nan 0.4018646  0.40183592 0.40189329 0.40192197        nan\n",
      " 0.39707401 0.39707401 0.40427424 0.39954102        nan 0.39948365\n",
      " 0.39948365 0.39948365 0.39707401        nan 0.39469306 0.39469306\n",
      " 0.39469306 0.39469306        nan 0.39948365 0.39948365 0.39948365\n",
      " 0.39948365        nan 0.39954102 0.39954102 0.39954102 0.39954102\n",
      "        nan 0.39713138 0.39713138 0.39713138 0.39713138        nan\n",
      " 0.40189329 0.40189329 0.40189329 0.40189329        nan 0.4018646\n",
      " 0.40183592 0.40189329 0.40192197        nan 0.39707401 0.39707401\n",
      " 0.40427424 0.39954102        nan 0.39948365 0.39948365 0.39948365\n",
      " 0.39707401        nan 0.39469306 0.39469306 0.39469306 0.39469306\n",
      "        nan 0.39948365 0.39948365 0.39948365 0.39948365        nan\n",
      " 0.39954102 0.39954102 0.39954102 0.39954102        nan 0.39713138\n",
      " 0.39713138 0.39713138 0.39713138        nan 0.40189329 0.40189329\n",
      " 0.40189329 0.40189329        nan 0.4018646  0.40183592 0.40189329\n",
      " 0.40192197        nan 0.39707401 0.39707401 0.40427424 0.39954102\n",
      "        nan 0.39948365 0.39948365 0.39948365 0.39707401        nan\n",
      " 0.39469306 0.39469306 0.39469306 0.39469306        nan 0.39948365\n",
      " 0.39948365 0.39948365 0.39948365        nan 0.39954102 0.39954102\n",
      " 0.39954102 0.39954102        nan 0.39713138 0.39713138 0.39713138\n",
      " 0.39713138        nan 0.40189329 0.40189329 0.40189329 0.40189329\n",
      "        nan 0.4018646  0.40183592 0.40189329 0.40192197        nan\n",
      " 0.39707401 0.39707401 0.40427424 0.39954102        nan 0.39948365\n",
      " 0.39948365 0.39948365 0.39707401        nan 0.39469306 0.39469306\n",
      " 0.39469306 0.39469306        nan 0.39948365 0.39948365 0.39948365\n",
      " 0.39948365        nan 0.39954102 0.39954102 0.39954102 0.39954102\n",
      "        nan 0.39713138 0.39713138 0.39713138 0.39713138        nan\n",
      " 0.40189329 0.40189329 0.40189329 0.40189329]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training:  0.41626794258373206\n",
      "21\n",
      "Fitting 5 folds for each of 640 candidates, totalling 3200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "640 fits failed out of a total of 3200.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "640 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan 0.51455026 0.51455026 0.51455026 0.51455026        nan\n",
      " 0.51455026 0.51455026 0.51455026 0.51455026        nan 0.51455026\n",
      " 0.51455026 0.51455026 0.51455026        nan 0.51455026 0.51455026\n",
      " 0.51455026 0.51455026        nan 0.51455026 0.51455026 0.51455026\n",
      " 0.51455026        nan 0.51455026 0.51455026 0.51455026 0.51455026\n",
      "        nan 0.51455026 0.51455026 0.51455026 0.51455026        nan\n",
      " 0.51455026 0.51455026 0.51455026 0.51455026        nan 0.52936508\n",
      " 0.52936508 0.52936508 0.52936508        nan 0.52936508 0.52936508\n",
      " 0.52936508 0.52936508        nan 0.52936508 0.52936508 0.52936508\n",
      " 0.52936508        nan 0.52936508 0.52936508 0.52936508 0.52936508\n",
      "        nan 0.52936508 0.52936508 0.52936508 0.52936508        nan\n",
      " 0.54417989 0.54417989 0.54417989 0.54417989        nan 0.54417989\n",
      " 0.54417989 0.54417989 0.54417989        nan 0.54417989 0.54417989\n",
      " 0.54417989 0.54417989        nan 0.52962963 0.52962963 0.52962963\n",
      " 0.52962963        nan 0.52962963 0.52962963 0.52962963 0.52962963\n",
      "        nan 0.52962963 0.52962963 0.52962963 0.52962963        nan\n",
      " 0.53677249 0.53677249 0.53677249 0.53677249        nan 0.52962963\n",
      " 0.52962963 0.52962963 0.52962963        nan 0.52962963 0.52962963\n",
      " 0.52962963 0.52962963        nan 0.53703704 0.53703704 0.53703704\n",
      " 0.53703704        nan 0.52962963 0.52962963 0.52962963 0.52962963\n",
      "        nan 0.54417989 0.54417989 0.54417989 0.52962963        nan\n",
      " 0.54417989 0.54417989 0.54417989 0.52962963        nan 0.52222222\n",
      " 0.52222222 0.52222222 0.52222222        nan 0.53677249 0.53677249\n",
      " 0.53677249 0.53677249        nan 0.52962963 0.52962963 0.52962963\n",
      " 0.52962963        nan 0.52962963 0.52962963 0.52962963 0.52962963\n",
      "        nan 0.53703704 0.53703704 0.53703704 0.53703704        nan\n",
      " 0.52962963 0.52962963 0.52962963 0.52962963        nan 0.52222222\n",
      " 0.52962963 0.52962963 0.52962963        nan 0.52962963 0.52962963\n",
      " 0.52962963 0.52962963        nan 0.52222222 0.52222222 0.52222222\n",
      " 0.52222222        nan 0.53677249 0.53677249 0.53677249 0.53677249\n",
      "        nan 0.52962963 0.52962963 0.52962963 0.52962963        nan\n",
      " 0.52962963 0.52962963 0.52962963 0.52962963        nan 0.53703704\n",
      " 0.53703704 0.53703704 0.53703704        nan 0.52962963 0.52962963\n",
      " 0.52962963 0.52962963        nan 0.52222222 0.52222222 0.52962963\n",
      " 0.52962963        nan 0.52962963 0.52962963 0.52962963 0.52962963\n",
      "        nan 0.52222222 0.52222222 0.52222222 0.52222222        nan\n",
      " 0.53677249 0.53677249 0.53677249 0.53677249        nan 0.52962963\n",
      " 0.52962963 0.52962963 0.52962963        nan 0.52962963 0.52962963\n",
      " 0.52962963 0.52962963        nan 0.53703704 0.53703704 0.53703704\n",
      " 0.53703704        nan 0.52962963 0.52962963 0.52962963 0.52962963\n",
      "        nan 0.52222222 0.52222222 0.52962963 0.52962963        nan\n",
      " 0.52962963 0.52962963 0.52962963 0.52962963        nan 0.52222222\n",
      " 0.52222222 0.52222222 0.52222222        nan 0.53677249 0.53677249\n",
      " 0.53677249 0.53677249        nan 0.52962963 0.52962963 0.52962963\n",
      " 0.52962963        nan 0.52962963 0.52962963 0.52962963 0.52962963\n",
      "        nan 0.53703704 0.53703704 0.53703704 0.53703704        nan\n",
      " 0.52962963 0.52962963 0.52962963 0.52962963        nan 0.52222222\n",
      " 0.52222222 0.52962963 0.52962963        nan 0.52962963 0.52962963\n",
      " 0.52962963 0.52962963        nan 0.52222222 0.52222222 0.52222222\n",
      " 0.52222222        nan 0.53677249 0.53677249 0.53677249 0.53677249\n",
      "        nan 0.52962963 0.52962963 0.52962963 0.52962963        nan\n",
      " 0.52962963 0.52962963 0.52962963 0.52962963        nan 0.53703704\n",
      " 0.53703704 0.53703704 0.53703704        nan 0.52962963 0.52962963\n",
      " 0.52962963 0.52962963        nan 0.52222222 0.52222222 0.52962963\n",
      " 0.52962963        nan 0.52962963 0.52962963 0.52962963 0.52962963\n",
      "        nan 0.52222222 0.52222222 0.52222222 0.52222222        nan\n",
      " 0.53677249 0.53677249 0.53677249 0.53677249        nan 0.52962963\n",
      " 0.52962963 0.52962963 0.52962963        nan 0.52962963 0.52962963\n",
      " 0.52962963 0.52962963        nan 0.53703704 0.53703704 0.53703704\n",
      " 0.53703704        nan 0.52962963 0.52962963 0.52962963 0.52962963\n",
      "        nan 0.52222222 0.52222222 0.52962963 0.52962963        nan\n",
      " 0.52962963 0.52962963 0.52962963 0.52962963        nan 0.52222222\n",
      " 0.52222222 0.52222222 0.52222222        nan 0.53677249 0.53677249\n",
      " 0.53677249 0.53677249        nan 0.52962963 0.52962963 0.52962963\n",
      " 0.52962963        nan 0.52962963 0.52962963 0.52962963 0.52962963\n",
      "        nan 0.53703704 0.53703704 0.53703704 0.53703704        nan\n",
      " 0.52962963 0.52962963 0.52962963 0.52962963        nan 0.52222222\n",
      " 0.52222222 0.52962963 0.52962963        nan 0.52962963 0.52962963\n",
      " 0.52962963 0.52962963        nan 0.52222222 0.52222222 0.52222222\n",
      " 0.52222222        nan 0.53677249 0.53677249 0.53677249 0.53677249\n",
      "        nan 0.52962963 0.52962963 0.52962963 0.52962963        nan\n",
      " 0.52962963 0.52962963 0.52962963 0.52962963        nan 0.53703704\n",
      " 0.53703704 0.53703704 0.53703704        nan 0.52962963 0.52962963\n",
      " 0.52962963 0.52962963        nan 0.52222222 0.52222222 0.52962963\n",
      " 0.52962963        nan 0.52962963 0.52962963 0.52962963 0.52962963\n",
      "        nan 0.52222222 0.52222222 0.52222222 0.52222222        nan\n",
      " 0.53677249 0.53677249 0.53677249 0.53677249        nan 0.52962963\n",
      " 0.52962963 0.52962963 0.52962963        nan 0.52962963 0.52962963\n",
      " 0.52962963 0.52962963        nan 0.53703704 0.53703704 0.53703704\n",
      " 0.53703704        nan 0.52962963 0.52962963 0.52962963 0.52962963\n",
      "        nan 0.52222222 0.52222222 0.52962963 0.52962963        nan\n",
      " 0.52962963 0.52962963 0.52962963 0.52962963        nan 0.52222222\n",
      " 0.52222222 0.52222222 0.52222222        nan 0.53677249 0.53677249\n",
      " 0.53677249 0.53677249        nan 0.52962963 0.52962963 0.52962963\n",
      " 0.52962963        nan 0.52962963 0.52962963 0.52962963 0.52962963\n",
      "        nan 0.53703704 0.53703704 0.53703704 0.53703704        nan\n",
      " 0.52962963 0.52962963 0.52962963 0.52962963        nan 0.52222222\n",
      " 0.52222222 0.52962963 0.52962963        nan 0.52962963 0.52962963\n",
      " 0.52962963 0.52962963        nan 0.52222222 0.52222222 0.52222222\n",
      " 0.52222222        nan 0.53677249 0.53677249 0.53677249 0.53677249\n",
      "        nan 0.52962963 0.52962963 0.52962963 0.52962963        nan\n",
      " 0.52962963 0.52962963 0.52962963 0.52962963        nan 0.53703704\n",
      " 0.53703704 0.53703704 0.53703704        nan 0.52962963 0.52962963\n",
      " 0.52962963 0.52962963        nan 0.52222222 0.52222222 0.52962963\n",
      " 0.52962963        nan 0.52962963 0.52962963 0.52962963 0.52962963\n",
      "        nan 0.52222222 0.52222222 0.52222222 0.52222222        nan\n",
      " 0.53677249 0.53677249 0.53677249 0.53677249        nan 0.52962963\n",
      " 0.52962963 0.52962963 0.52962963        nan 0.52962963 0.52962963\n",
      " 0.52962963 0.52962963        nan 0.53703704 0.53703704 0.53703704\n",
      " 0.53703704        nan 0.52962963 0.52962963 0.52962963 0.52962963\n",
      "        nan 0.52222222 0.52222222 0.52962963 0.52962963        nan\n",
      " 0.52962963 0.52962963 0.52962963 0.52962963        nan 0.52222222\n",
      " 0.52222222 0.52222222 0.52222222        nan 0.53677249 0.53677249\n",
      " 0.53677249 0.53677249        nan 0.52962963 0.52962963 0.52962963\n",
      " 0.52962963        nan 0.52962963 0.52962963 0.52962963 0.52962963\n",
      "        nan 0.53703704 0.53703704 0.53703704 0.53703704        nan\n",
      " 0.52962963 0.52962963 0.52962963 0.52962963]\n",
      "  warnings.warn(\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training:  0.5955882352941176\n",
      "22\n",
      "Fitting 5 folds for each of 640 candidates, totalling 3200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "640 fits failed out of a total of 3200.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "640 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan 0.38580392 0.38580392 0.38580392 0.38580392        nan\n",
      " 0.38580392 0.38580392 0.38580392 0.38580392        nan 0.38580392\n",
      " 0.38580392 0.38580392 0.38580392        nan 0.38580392 0.38580392\n",
      " 0.38580392 0.38580392        nan 0.38972549 0.38972549 0.38972549\n",
      " 0.38972549        nan 0.38972549 0.38972549 0.38972549 0.38972549\n",
      "        nan 0.38972549 0.38972549 0.38972549 0.38972549        nan\n",
      " 0.38972549 0.38972549 0.38972549 0.38972549        nan 0.37003922\n",
      " 0.37003922 0.37003922 0.37003922        nan 0.37003922 0.37003922\n",
      " 0.37003922 0.37003922        nan 0.37003922 0.37003922 0.37003922\n",
      " 0.37003922        nan 0.37796078 0.37796078 0.37796078 0.37796078\n",
      "        nan 0.38972549 0.38972549 0.38972549 0.38972549        nan\n",
      " 0.38972549 0.38972549 0.38972549 0.38972549        nan 0.38972549\n",
      " 0.38972549 0.38972549 0.38972549        nan 0.38972549 0.38972549\n",
      " 0.38972549 0.38972549        nan 0.37003922 0.37003922 0.37003922\n",
      " 0.37003922        nan 0.37003922 0.37003922 0.37003922 0.37003922\n",
      "        nan 0.37396078 0.37396078 0.37396078 0.37396078        nan\n",
      " 0.38188235 0.38188235 0.38188235 0.38188235        nan 0.38972549\n",
      " 0.38972549 0.38972549 0.38972549        nan 0.38172549 0.38172549\n",
      " 0.38172549 0.38172549        nan 0.38972549 0.38972549 0.38972549\n",
      " 0.38972549        nan 0.38972549 0.38972549 0.38972549 0.38972549\n",
      "        nan 0.36611765 0.36611765 0.36611765 0.36611765        nan\n",
      " 0.36611765 0.36611765 0.36611765 0.36611765        nan 0.37396078\n",
      " 0.37396078 0.37396078 0.37396078        nan 0.37388235 0.37388235\n",
      " 0.37388235 0.37388235        nan 0.38172549 0.38172549 0.38172549\n",
      " 0.38172549        nan 0.38172549 0.38172549 0.38172549 0.38172549\n",
      "        nan 0.38972549 0.38972549 0.38972549 0.38972549        nan\n",
      " 0.38972549 0.38972549 0.38972549 0.38972549        nan 0.36611765\n",
      " 0.36611765 0.36611765 0.36611765        nan 0.36611765 0.36611765\n",
      " 0.36611765 0.36611765        nan 0.37396078 0.37396078 0.37396078\n",
      " 0.37396078        nan 0.37388235 0.37388235 0.37388235 0.37388235\n",
      "        nan 0.38172549 0.38172549 0.38172549 0.38172549        nan\n",
      " 0.38172549 0.38172549 0.38172549 0.38172549        nan 0.38972549\n",
      " 0.38972549 0.38972549 0.38972549        nan 0.38972549 0.38972549\n",
      " 0.38972549 0.38972549        nan 0.35811765 0.35811765 0.35811765\n",
      " 0.35811765        nan 0.36211765 0.36211765 0.36211765 0.36211765\n",
      "        nan 0.36996078 0.36996078 0.36996078 0.36996078        nan\n",
      " 0.37388235 0.37388235 0.37388235 0.37388235        nan 0.38172549\n",
      " 0.38172549 0.38172549 0.38172549        nan 0.38172549 0.38172549\n",
      " 0.38172549 0.38172549        nan 0.38972549 0.38972549 0.38972549\n",
      " 0.38972549        nan 0.38972549 0.38972549 0.38972549 0.38972549\n",
      "        nan 0.35811765 0.35811765 0.35811765 0.35811765        nan\n",
      " 0.36211765 0.36211765 0.36211765 0.36211765        nan 0.36996078\n",
      " 0.36996078 0.36996078 0.36996078        nan 0.37388235 0.37388235\n",
      " 0.37388235 0.37388235        nan 0.38172549 0.38172549 0.38172549\n",
      " 0.38172549        nan 0.38172549 0.38172549 0.38172549 0.38172549\n",
      "        nan 0.38972549 0.38972549 0.38972549 0.38972549        nan\n",
      " 0.38972549 0.38972549 0.38972549 0.38972549        nan 0.35811765\n",
      " 0.35811765 0.35811765 0.35811765        nan 0.36211765 0.36211765\n",
      " 0.36211765 0.36211765        nan 0.36996078 0.36996078 0.36996078\n",
      " 0.36996078        nan 0.37388235 0.37388235 0.37388235 0.37388235\n",
      "        nan 0.38172549 0.38172549 0.38172549 0.38172549        nan\n",
      " 0.38172549 0.38172549 0.38172549 0.38172549        nan 0.38972549\n",
      " 0.38972549 0.38972549 0.38972549        nan 0.38972549 0.38972549\n",
      " 0.38972549 0.38972549        nan 0.35811765 0.35811765 0.35811765\n",
      " 0.35811765        nan 0.36211765 0.36211765 0.36211765 0.36211765\n",
      "        nan 0.36996078 0.36996078 0.36996078 0.36996078        nan\n",
      " 0.37388235 0.37388235 0.37388235 0.37388235        nan 0.38172549\n",
      " 0.38172549 0.38172549 0.38172549        nan 0.38172549 0.38172549\n",
      " 0.38172549 0.38172549        nan 0.38972549 0.38972549 0.38972549\n",
      " 0.38972549        nan 0.38972549 0.38972549 0.38972549 0.38972549\n",
      "        nan 0.35811765 0.35811765 0.35811765 0.35811765        nan\n",
      " 0.36211765 0.36211765 0.36211765 0.36211765        nan 0.36996078\n",
      " 0.36996078 0.36996078 0.36996078        nan 0.37388235 0.37388235\n",
      " 0.37388235 0.37388235        nan 0.38172549 0.38172549 0.38172549\n",
      " 0.38172549        nan 0.38172549 0.38172549 0.38172549 0.38172549\n",
      "        nan 0.38972549 0.38972549 0.38972549 0.38972549        nan\n",
      " 0.38972549 0.38972549 0.38972549 0.38972549        nan 0.35811765\n",
      " 0.35811765 0.35811765 0.35811765        nan 0.36211765 0.36211765\n",
      " 0.36211765 0.36211765        nan 0.36996078 0.36996078 0.36996078\n",
      " 0.36996078        nan 0.37388235 0.37388235 0.37388235 0.37388235\n",
      "        nan 0.38172549 0.38172549 0.38172549 0.38172549        nan\n",
      " 0.38172549 0.38172549 0.38172549 0.38172549        nan 0.38972549\n",
      " 0.38972549 0.38972549 0.38972549        nan 0.38972549 0.38972549\n",
      " 0.38972549 0.38972549        nan 0.35811765 0.35811765 0.35811765\n",
      " 0.35811765        nan 0.36211765 0.36211765 0.36211765 0.36211765\n",
      "        nan 0.36996078 0.36996078 0.36996078 0.36996078        nan\n",
      " 0.37388235 0.37388235 0.37388235 0.37388235        nan 0.38172549\n",
      " 0.38172549 0.38172549 0.38172549        nan 0.38172549 0.38172549\n",
      " 0.38172549 0.38172549        nan 0.38972549 0.38972549 0.38972549\n",
      " 0.38972549        nan 0.38972549 0.38972549 0.38972549 0.38972549\n",
      "        nan 0.35811765 0.35811765 0.35811765 0.35811765        nan\n",
      " 0.36211765 0.36211765 0.36211765 0.36211765        nan 0.36996078\n",
      " 0.36996078 0.36996078 0.36996078        nan 0.37388235 0.37388235\n",
      " 0.37388235 0.37388235        nan 0.38172549 0.38172549 0.38172549\n",
      " 0.38172549        nan 0.38172549 0.38172549 0.38172549 0.38172549\n",
      "        nan 0.38972549 0.38972549 0.38972549 0.38972549        nan\n",
      " 0.38972549 0.38972549 0.38972549 0.38972549        nan 0.35811765\n",
      " 0.35811765 0.35811765 0.35811765        nan 0.36211765 0.36211765\n",
      " 0.36211765 0.36211765        nan 0.36996078 0.36996078 0.36996078\n",
      " 0.36996078        nan 0.37388235 0.37388235 0.37388235 0.37388235\n",
      "        nan 0.38172549 0.38172549 0.38172549 0.38172549        nan\n",
      " 0.38172549 0.38172549 0.38172549 0.38172549        nan 0.38972549\n",
      " 0.38972549 0.38972549 0.38972549        nan 0.38972549 0.38972549\n",
      " 0.38972549 0.38972549        nan 0.35811765 0.35811765 0.35811765\n",
      " 0.35811765        nan 0.36211765 0.36211765 0.36211765 0.36211765\n",
      "        nan 0.36996078 0.36996078 0.36996078 0.36996078        nan\n",
      " 0.37388235 0.37388235 0.37388235 0.37388235        nan 0.38172549\n",
      " 0.38172549 0.38172549 0.38172549        nan 0.38172549 0.38172549\n",
      " 0.38172549 0.38172549        nan 0.38972549 0.38972549 0.38972549\n",
      " 0.38972549        nan 0.38972549 0.38972549 0.38972549 0.38972549\n",
      "        nan 0.35811765 0.35811765 0.35811765 0.35811765        nan\n",
      " 0.36211765 0.36211765 0.36211765 0.36211765        nan 0.36996078\n",
      " 0.36996078 0.36996078 0.36996078        nan 0.37388235 0.37388235\n",
      " 0.37388235 0.37388235        nan 0.38172549 0.38172549 0.38172549\n",
      " 0.38172549        nan 0.38172549 0.38172549 0.38172549 0.38172549\n",
      "        nan 0.38972549 0.38972549 0.38972549 0.38972549        nan\n",
      " 0.38972549 0.38972549 0.38972549 0.38972549]\n",
      "  warnings.warn(\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training:  0.39763779527559057\n",
      "23\n",
      "Fitting 5 folds for each of 640 candidates, totalling 3200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "640 fits failed out of a total of 3200.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "640 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan 0.38572939 0.38572939 0.38572939 0.38572939        nan\n",
      " 0.38572939 0.38572939 0.38572939 0.38572939        nan 0.38572939\n",
      " 0.38572939 0.38572939 0.38572939        nan 0.38572939 0.38572939\n",
      " 0.38572939 0.38572939        nan 0.38572939 0.38572939 0.38572939\n",
      " 0.38572939        nan 0.38572939 0.38572939 0.38572939 0.38572939\n",
      "        nan 0.38572939 0.38572939 0.38572939 0.38572939        nan\n",
      " 0.38572939 0.38572939 0.38572939 0.38572939        nan 0.39006342\n",
      " 0.39006342 0.39006342 0.39006342        nan 0.39006342 0.39006342\n",
      " 0.39006342 0.39006342        nan 0.39006342 0.39006342 0.39006342\n",
      " 0.39006342        nan 0.37642706 0.37642706 0.37642706 0.37642706\n",
      "        nan 0.37188161 0.37188161 0.37188161 0.37188161        nan\n",
      " 0.3627907  0.3627907  0.3627907  0.3627907         nan 0.3627907\n",
      " 0.3627907  0.3627907  0.3627907         nan 0.3627907  0.3627907\n",
      " 0.3627907  0.3627907         nan 0.38086681 0.38086681 0.38086681\n",
      " 0.38086681        nan 0.37621564 0.37621564 0.37621564 0.37621564\n",
      "        nan 0.3807611  0.3807611  0.3807611  0.3807611         nan\n",
      " 0.36712474 0.36712474 0.36712474 0.36712474        nan 0.36257928\n",
      " 0.36257928 0.36257928 0.36257928        nan 0.35348837 0.35348837\n",
      " 0.35348837 0.35348837        nan 0.35348837 0.35348837 0.35348837\n",
      " 0.35348837        nan 0.35348837 0.35348837 0.35348837 0.35348837\n",
      "        nan 0.38551797 0.38551797 0.38551797 0.38086681        nan\n",
      " 0.38086681 0.38086681 0.38086681 0.37621564        nan 0.3807611\n",
      " 0.3807611  0.3807611  0.3807611         nan 0.35782241 0.35782241\n",
      " 0.35782241 0.35782241        nan 0.35327696 0.35327696 0.35327696\n",
      " 0.35327696        nan 0.3487315  0.3487315  0.3487315  0.3487315\n",
      "        nan 0.3487315  0.3487315  0.3487315  0.3487315         nan\n",
      " 0.3487315  0.3487315  0.3487315  0.3487315         nan 0.39016913\n",
      " 0.39016913 0.39016913 0.38086681        nan 0.36723044 0.36723044\n",
      " 0.3717759  0.35782241        nan 0.35327696 0.35327696 0.35782241\n",
      " 0.35782241        nan 0.35327696 0.35327696 0.35327696 0.35327696\n",
      "        nan 0.35327696 0.35327696 0.35327696 0.35327696        nan\n",
      " 0.3487315  0.3487315  0.3487315  0.3487315         nan 0.34408034\n",
      " 0.34408034 0.34408034 0.34408034        nan 0.3487315  0.3487315\n",
      " 0.3487315  0.3487315         nan 0.36268499 0.36268499 0.36723044\n",
      " 0.36701903        nan 0.36268499 0.36268499 0.36723044 0.35327696\n",
      "        nan 0.3487315  0.3487315  0.35327696 0.35327696        nan\n",
      " 0.35327696 0.35327696 0.35327696 0.35327696        nan 0.35327696\n",
      " 0.35327696 0.35327696 0.35327696        nan 0.3487315  0.3487315\n",
      " 0.3487315  0.3487315         nan 0.34408034 0.34408034 0.34408034\n",
      " 0.34408034        nan 0.3487315  0.3487315  0.3487315  0.3487315\n",
      "        nan 0.36268499 0.36268499 0.36723044 0.36701903        nan\n",
      " 0.36268499 0.36268499 0.36723044 0.35327696        nan 0.3487315\n",
      " 0.3487315  0.35327696 0.35327696        nan 0.35327696 0.35327696\n",
      " 0.35327696 0.35327696        nan 0.35327696 0.35327696 0.35327696\n",
      " 0.35327696        nan 0.3487315  0.3487315  0.3487315  0.3487315\n",
      "        nan 0.34408034 0.34408034 0.34408034 0.34408034        nan\n",
      " 0.3487315  0.3487315  0.3487315  0.3487315         nan 0.36268499\n",
      " 0.36268499 0.36723044 0.36701903        nan 0.36268499 0.36268499\n",
      " 0.36723044 0.35327696        nan 0.3487315  0.3487315  0.35327696\n",
      " 0.35327696        nan 0.35327696 0.35327696 0.35327696 0.35327696\n",
      "        nan 0.35327696 0.35327696 0.35327696 0.35327696        nan\n",
      " 0.3487315  0.3487315  0.3487315  0.3487315         nan 0.34408034\n",
      " 0.34408034 0.34408034 0.34408034        nan 0.3487315  0.3487315\n",
      " 0.3487315  0.3487315         nan 0.36268499 0.36268499 0.36723044\n",
      " 0.36701903        nan 0.36268499 0.36268499 0.36723044 0.35327696\n",
      "        nan 0.3487315  0.3487315  0.35327696 0.35327696        nan\n",
      " 0.35327696 0.35327696 0.35327696 0.35327696        nan 0.35327696\n",
      " 0.35327696 0.35327696 0.35327696        nan 0.3487315  0.3487315\n",
      " 0.3487315  0.3487315         nan 0.34408034 0.34408034 0.34408034\n",
      " 0.34408034        nan 0.3487315  0.3487315  0.3487315  0.3487315\n",
      "        nan 0.36268499 0.36268499 0.36723044 0.36701903        nan\n",
      " 0.36268499 0.36268499 0.36723044 0.35327696        nan 0.3487315\n",
      " 0.3487315  0.35327696 0.35327696        nan 0.35327696 0.35327696\n",
      " 0.35327696 0.35327696        nan 0.35327696 0.35327696 0.35327696\n",
      " 0.35327696        nan 0.3487315  0.3487315  0.3487315  0.3487315\n",
      "        nan 0.34408034 0.34408034 0.34408034 0.34408034        nan\n",
      " 0.3487315  0.3487315  0.3487315  0.3487315         nan 0.36268499\n",
      " 0.36268499 0.36723044 0.36701903        nan 0.36268499 0.36268499\n",
      " 0.36723044 0.35327696        nan 0.3487315  0.3487315  0.35327696\n",
      " 0.35327696        nan 0.35327696 0.35327696 0.35327696 0.35327696\n",
      "        nan 0.35327696 0.35327696 0.35327696 0.35327696        nan\n",
      " 0.3487315  0.3487315  0.3487315  0.3487315         nan 0.34408034\n",
      " 0.34408034 0.34408034 0.34408034        nan 0.3487315  0.3487315\n",
      " 0.3487315  0.3487315         nan 0.36268499 0.36268499 0.36723044\n",
      " 0.36701903        nan 0.36268499 0.36268499 0.36723044 0.35327696\n",
      "        nan 0.3487315  0.3487315  0.35327696 0.35327696        nan\n",
      " 0.35327696 0.35327696 0.35327696 0.35327696        nan 0.35327696\n",
      " 0.35327696 0.35327696 0.35327696        nan 0.3487315  0.3487315\n",
      " 0.3487315  0.3487315         nan 0.34408034 0.34408034 0.34408034\n",
      " 0.34408034        nan 0.3487315  0.3487315  0.3487315  0.3487315\n",
      "        nan 0.36268499 0.36268499 0.36723044 0.36701903        nan\n",
      " 0.36268499 0.36268499 0.36723044 0.35327696        nan 0.3487315\n",
      " 0.3487315  0.35327696 0.35327696        nan 0.35327696 0.35327696\n",
      " 0.35327696 0.35327696        nan 0.35327696 0.35327696 0.35327696\n",
      " 0.35327696        nan 0.3487315  0.3487315  0.3487315  0.3487315\n",
      "        nan 0.34408034 0.34408034 0.34408034 0.34408034        nan\n",
      " 0.3487315  0.3487315  0.3487315  0.3487315         nan 0.36268499\n",
      " 0.36268499 0.36723044 0.36701903        nan 0.36268499 0.36268499\n",
      " 0.36723044 0.35327696        nan 0.3487315  0.3487315  0.35327696\n",
      " 0.35327696        nan 0.35327696 0.35327696 0.35327696 0.35327696\n",
      "        nan 0.35327696 0.35327696 0.35327696 0.35327696        nan\n",
      " 0.3487315  0.3487315  0.3487315  0.3487315         nan 0.34408034\n",
      " 0.34408034 0.34408034 0.34408034        nan 0.3487315  0.3487315\n",
      " 0.3487315  0.3487315         nan 0.36268499 0.36268499 0.36723044\n",
      " 0.36701903        nan 0.36268499 0.36268499 0.36723044 0.35327696\n",
      "        nan 0.3487315  0.3487315  0.35327696 0.35327696        nan\n",
      " 0.35327696 0.35327696 0.35327696 0.35327696        nan 0.35327696\n",
      " 0.35327696 0.35327696 0.35327696        nan 0.3487315  0.3487315\n",
      " 0.3487315  0.3487315         nan 0.34408034 0.34408034 0.34408034\n",
      " 0.34408034        nan 0.3487315  0.3487315  0.3487315  0.3487315\n",
      "        nan 0.36268499 0.36268499 0.36723044 0.36701903        nan\n",
      " 0.36268499 0.36268499 0.36723044 0.35327696        nan 0.3487315\n",
      " 0.3487315  0.35327696 0.35327696        nan 0.35327696 0.35327696\n",
      " 0.35327696 0.35327696        nan 0.35327696 0.35327696 0.35327696\n",
      " 0.35327696        nan 0.3487315  0.3487315  0.3487315  0.3487315\n",
      "        nan 0.34408034 0.34408034 0.34408034 0.34408034        nan\n",
      " 0.3487315  0.3487315  0.3487315  0.3487315 ]\n",
      "  warnings.warn(\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training:  0.463302752293578\n",
      "24\n",
      "Fitting 5 folds for each of 640 candidates, totalling 3200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "640 fits failed out of a total of 3200.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "640 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan 0.50320197 0.50320197 0.50320197 0.50320197        nan\n",
      " 0.50320197 0.50320197 0.50320197 0.50320197        nan 0.50320197\n",
      " 0.50320197 0.50320197 0.50320197        nan 0.50320197 0.50320197\n",
      " 0.50320197 0.50320197        nan 0.50320197 0.50320197 0.50320197\n",
      " 0.50320197        nan 0.50320197 0.50320197 0.50320197 0.50320197\n",
      "        nan 0.50320197 0.50320197 0.50320197 0.50320197        nan\n",
      " 0.50320197 0.50320197 0.50320197 0.50320197        nan 0.51034483\n",
      " 0.51034483 0.51034483 0.51034483        nan 0.51034483 0.51034483\n",
      " 0.51034483 0.51034483        nan 0.51034483 0.51034483 0.51034483\n",
      " 0.51034483        nan 0.51748768 0.51748768 0.51748768 0.51748768\n",
      "        nan 0.52463054 0.52463054 0.52463054 0.52463054        nan\n",
      " 0.55320197 0.55320197 0.55320197 0.55320197        nan 0.55320197\n",
      " 0.55320197 0.55320197 0.55320197        nan 0.55320197 0.55320197\n",
      " 0.55320197 0.55320197        nan 0.5317734  0.5317734  0.53891626\n",
      " 0.53891626        nan 0.5317734  0.5317734  0.53891626 0.53891626\n",
      "        nan 0.53891626 0.53891626 0.53891626 0.53891626        nan\n",
      " 0.54605911 0.54605911 0.54605911 0.54605911        nan 0.54605911\n",
      " 0.54605911 0.54605911 0.54605911        nan 0.5317734  0.5317734\n",
      " 0.5317734  0.5317734         nan 0.55320197 0.55320197 0.55320197\n",
      " 0.55320197        nan 0.55320197 0.55320197 0.55320197 0.55320197\n",
      "        nan 0.51748768 0.51748768 0.52463054 0.52463054        nan\n",
      " 0.51034483 0.51034483 0.51748768 0.51748768        nan 0.51748768\n",
      " 0.51748768 0.51748768 0.51748768        nan 0.5317734  0.5317734\n",
      " 0.5317734  0.5317734         nan 0.52463054 0.52463054 0.52463054\n",
      " 0.52463054        nan 0.53891626 0.53891626 0.53891626 0.53891626\n",
      "        nan 0.55320197 0.55320197 0.55320197 0.55320197        nan\n",
      " 0.55320197 0.55320197 0.55320197 0.55320197        nan 0.51773399\n",
      " 0.51773399 0.5317734  0.5317734         nan 0.51059113 0.51059113\n",
      " 0.52463054 0.52463054        nan 0.51773399 0.51773399 0.52463054\n",
      " 0.52463054        nan 0.53891626 0.53891626 0.53891626 0.53891626\n",
      "        nan 0.5317734  0.5317734  0.5317734  0.5317734         nan\n",
      " 0.53891626 0.53891626 0.53891626 0.53891626        nan 0.55320197\n",
      " 0.55320197 0.55320197 0.55320197        nan 0.55320197 0.55320197\n",
      " 0.55320197 0.55320197        nan 0.49679803 0.49679803 0.52463054\n",
      " 0.53891626        nan 0.50344828 0.50344828 0.51748768 0.52463054\n",
      "        nan 0.51059113 0.51059113 0.51748768 0.52463054        nan\n",
      " 0.53891626 0.53891626 0.53891626 0.53891626        nan 0.5317734\n",
      " 0.5317734  0.5317734  0.5317734         nan 0.53891626 0.53891626\n",
      " 0.53891626 0.53891626        nan 0.55320197 0.55320197 0.55320197\n",
      " 0.55320197        nan 0.55320197 0.55320197 0.55320197 0.55320197\n",
      "        nan 0.49679803 0.49679803 0.52463054 0.53891626        nan\n",
      " 0.50344828 0.50344828 0.51748768 0.52463054        nan 0.51059113\n",
      " 0.51059113 0.51748768 0.52463054        nan 0.53891626 0.53891626\n",
      " 0.53891626 0.53891626        nan 0.5317734  0.5317734  0.5317734\n",
      " 0.5317734         nan 0.53891626 0.53891626 0.53891626 0.53891626\n",
      "        nan 0.55320197 0.55320197 0.55320197 0.55320197        nan\n",
      " 0.55320197 0.55320197 0.55320197 0.55320197        nan 0.49679803\n",
      " 0.49679803 0.52463054 0.53891626        nan 0.50344828 0.50344828\n",
      " 0.51748768 0.52463054        nan 0.51059113 0.51059113 0.51748768\n",
      " 0.52463054        nan 0.53891626 0.53891626 0.53891626 0.53891626\n",
      "        nan 0.5317734  0.5317734  0.5317734  0.5317734         nan\n",
      " 0.53891626 0.53891626 0.53891626 0.53891626        nan 0.55320197\n",
      " 0.55320197 0.55320197 0.55320197        nan 0.55320197 0.55320197\n",
      " 0.55320197 0.55320197        nan 0.49679803 0.49679803 0.52463054\n",
      " 0.53891626        nan 0.50344828 0.50344828 0.51748768 0.52463054\n",
      "        nan 0.51059113 0.51059113 0.51748768 0.52463054        nan\n",
      " 0.53891626 0.53891626 0.53891626 0.53891626        nan 0.5317734\n",
      " 0.5317734  0.5317734  0.5317734         nan 0.53891626 0.53891626\n",
      " 0.53891626 0.53891626        nan 0.55320197 0.55320197 0.55320197\n",
      " 0.55320197        nan 0.55320197 0.55320197 0.55320197 0.55320197\n",
      "        nan 0.49679803 0.49679803 0.52463054 0.53891626        nan\n",
      " 0.50344828 0.50344828 0.51748768 0.52463054        nan 0.51059113\n",
      " 0.51059113 0.51748768 0.52463054        nan 0.53891626 0.53891626\n",
      " 0.53891626 0.53891626        nan 0.5317734  0.5317734  0.5317734\n",
      " 0.5317734         nan 0.53891626 0.53891626 0.53891626 0.53891626\n",
      "        nan 0.55320197 0.55320197 0.55320197 0.55320197        nan\n",
      " 0.55320197 0.55320197 0.55320197 0.55320197        nan 0.49679803\n",
      " 0.49679803 0.52463054 0.53891626        nan 0.50344828 0.50344828\n",
      " 0.51748768 0.52463054        nan 0.51059113 0.51059113 0.51748768\n",
      " 0.52463054        nan 0.53891626 0.53891626 0.53891626 0.53891626\n",
      "        nan 0.5317734  0.5317734  0.5317734  0.5317734         nan\n",
      " 0.53891626 0.53891626 0.53891626 0.53891626        nan 0.55320197\n",
      " 0.55320197 0.55320197 0.55320197        nan 0.55320197 0.55320197\n",
      " 0.55320197 0.55320197        nan 0.49679803 0.49679803 0.52463054\n",
      " 0.53891626        nan 0.50344828 0.50344828 0.51748768 0.52463054\n",
      "        nan 0.51059113 0.51059113 0.51748768 0.52463054        nan\n",
      " 0.53891626 0.53891626 0.53891626 0.53891626        nan 0.5317734\n",
      " 0.5317734  0.5317734  0.5317734         nan 0.53891626 0.53891626\n",
      " 0.53891626 0.53891626        nan 0.55320197 0.55320197 0.55320197\n",
      " 0.55320197        nan 0.55320197 0.55320197 0.55320197 0.55320197\n",
      "        nan 0.49679803 0.49679803 0.52463054 0.53891626        nan\n",
      " 0.50344828 0.50344828 0.51748768 0.52463054        nan 0.51059113\n",
      " 0.51059113 0.51748768 0.52463054        nan 0.53891626 0.53891626\n",
      " 0.53891626 0.53891626        nan 0.5317734  0.5317734  0.5317734\n",
      " 0.5317734         nan 0.53891626 0.53891626 0.53891626 0.53891626\n",
      "        nan 0.55320197 0.55320197 0.55320197 0.55320197        nan\n",
      " 0.55320197 0.55320197 0.55320197 0.55320197        nan 0.49679803\n",
      " 0.49679803 0.52463054 0.53891626        nan 0.50344828 0.50344828\n",
      " 0.51748768 0.52463054        nan 0.51059113 0.51059113 0.51748768\n",
      " 0.52463054        nan 0.53891626 0.53891626 0.53891626 0.53891626\n",
      "        nan 0.5317734  0.5317734  0.5317734  0.5317734         nan\n",
      " 0.53891626 0.53891626 0.53891626 0.53891626        nan 0.55320197\n",
      " 0.55320197 0.55320197 0.55320197        nan 0.55320197 0.55320197\n",
      " 0.55320197 0.55320197        nan 0.49679803 0.49679803 0.52463054\n",
      " 0.53891626        nan 0.50344828 0.50344828 0.51748768 0.52463054\n",
      "        nan 0.51059113 0.51059113 0.51748768 0.52463054        nan\n",
      " 0.53891626 0.53891626 0.53891626 0.53891626        nan 0.5317734\n",
      " 0.5317734  0.5317734  0.5317734         nan 0.53891626 0.53891626\n",
      " 0.53891626 0.53891626        nan 0.55320197 0.55320197 0.55320197\n",
      " 0.55320197        nan 0.55320197 0.55320197 0.55320197 0.55320197\n",
      "        nan 0.49679803 0.49679803 0.52463054 0.53891626        nan\n",
      " 0.50344828 0.50344828 0.51748768 0.52463054        nan 0.51059113\n",
      " 0.51059113 0.51748768 0.52463054        nan 0.53891626 0.53891626\n",
      " 0.53891626 0.53891626        nan 0.5317734  0.5317734  0.5317734\n",
      " 0.5317734         nan 0.53891626 0.53891626 0.53891626 0.53891626\n",
      "        nan 0.55320197 0.55320197 0.55320197 0.55320197        nan\n",
      " 0.55320197 0.55320197 0.55320197 0.55320197]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training:  0.5531914893617021\n",
      "25\n",
      "Fitting 5 folds for each of 640 candidates, totalling 3200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "640 fits failed out of a total of 3200.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "640 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [nan  1.  1.  1.  1. nan  1.  1.  1.  1. nan  1.  1.  1.  1. nan  1.  1.\n",
      "  1.  1. nan  1.  1.  1.  1. nan  1.  1.  1.  1. nan  1.  1.  1.  1. nan\n",
      "  1.  1.  1.  1. nan  1.  1.  1.  1. nan  1.  1.  1.  1. nan  1.  1.  1.\n",
      "  1. nan  1.  1.  1.  1. nan  1.  1.  1.  1. nan  1.  1.  1.  1. nan  1.\n",
      "  1.  1.  1. nan  1.  1.  1.  1. nan  1.  1.  1.  1. nan  1.  1.  1.  1.\n",
      " nan  1.  1.  1.  1. nan  1.  1.  1.  1. nan  1.  1.  1.  1. nan  1.  1.\n",
      "  1.  1. nan  1.  1.  1.  1. nan  1.  1.  1.  1. nan  1.  1.  1.  1. nan\n",
      "  1.  1.  1.  1. nan  1.  1.  1.  1. nan  1.  1.  1.  1. nan  1.  1.  1.\n",
      "  1. nan  1.  1.  1.  1. nan  1.  1.  1.  1. nan  1.  1.  1.  1. nan  1.\n",
      "  1.  1.  1. nan  1.  1.  1.  1. nan  1.  1.  1.  1. nan  1.  1.  1.  1.\n",
      " nan  1.  1.  1.  1. nan  1.  1.  1.  1. nan  1.  1.  1.  1. nan  1.  1.\n",
      "  1.  1. nan  1.  1.  1.  1. nan  1.  1.  1.  1. nan  1.  1.  1.  1. nan\n",
      "  1.  1.  1.  1. nan  1.  1.  1.  1. nan  1.  1.  1.  1. nan  1.  1.  1.\n",
      "  1. nan  1.  1.  1.  1. nan  1.  1.  1.  1. nan  1.  1.  1.  1. nan  1.\n",
      "  1.  1.  1. nan  1.  1.  1.  1. nan  1.  1.  1.  1. nan  1.  1.  1.  1.\n",
      " nan  1.  1.  1.  1. nan  1.  1.  1.  1. nan  1.  1.  1.  1. nan  1.  1.\n",
      "  1.  1. nan  1.  1.  1.  1. nan  1.  1.  1.  1. nan  1.  1.  1.  1. nan\n",
      "  1.  1.  1.  1. nan  1.  1.  1.  1. nan  1.  1.  1.  1. nan  1.  1.  1.\n",
      "  1. nan  1.  1.  1.  1. nan  1.  1.  1.  1. nan  1.  1.  1.  1. nan  1.\n",
      "  1.  1.  1. nan  1.  1.  1.  1. nan  1.  1.  1.  1. nan  1.  1.  1.  1.\n",
      " nan  1.  1.  1.  1. nan  1.  1.  1.  1. nan  1.  1.  1.  1. nan  1.  1.\n",
      "  1.  1. nan  1.  1.  1.  1. nan  1.  1.  1.  1. nan  1.  1.  1.  1. nan\n",
      "  1.  1.  1.  1. nan  1.  1.  1.  1. nan  1.  1.  1.  1. nan  1.  1.  1.\n",
      "  1. nan  1.  1.  1.  1. nan  1.  1.  1.  1. nan  1.  1.  1.  1. nan  1.\n",
      "  1.  1.  1. nan  1.  1.  1.  1. nan  1.  1.  1.  1. nan  1.  1.  1.  1.\n",
      " nan  1.  1.  1.  1. nan  1.  1.  1.  1. nan  1.  1.  1.  1. nan  1.  1.\n",
      "  1.  1. nan  1.  1.  1.  1. nan  1.  1.  1.  1. nan  1.  1.  1.  1. nan\n",
      "  1.  1.  1.  1. nan  1.  1.  1.  1. nan  1.  1.  1.  1. nan  1.  1.  1.\n",
      "  1. nan  1.  1.  1.  1. nan  1.  1.  1.  1. nan  1.  1.  1.  1. nan  1.\n",
      "  1.  1.  1. nan  1.  1.  1.  1. nan  1.  1.  1.  1. nan  1.  1.  1.  1.\n",
      " nan  1.  1.  1.  1. nan  1.  1.  1.  1. nan  1.  1.  1.  1. nan  1.  1.\n",
      "  1.  1. nan  1.  1.  1.  1. nan  1.  1.  1.  1. nan  1.  1.  1.  1. nan\n",
      "  1.  1.  1.  1. nan  1.  1.  1.  1. nan  1.  1.  1.  1. nan  1.  1.  1.\n",
      "  1. nan  1.  1.  1.  1. nan  1.  1.  1.  1. nan  1.  1.  1.  1. nan  1.\n",
      "  1.  1.  1. nan  1.  1.  1.  1. nan  1.  1.  1.  1. nan  1.  1.  1.  1.\n",
      " nan  1.  1.  1.  1. nan  1.  1.  1.  1.]\n",
      "  warnings.warn(\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training:  1.0\n",
      "26\n",
      "Fitting 5 folds for each of 640 candidates, totalling 3200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "640 fits failed out of a total of 3200.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "640 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [    nan 0.59375 0.59375 0.59375 0.59375     nan 0.59375 0.59375 0.59375\n",
      " 0.59375     nan 0.6     0.6     0.6     0.6         nan 0.6     0.6\n",
      " 0.6     0.6         nan 0.6     0.6     0.6     0.6         nan 0.6\n",
      " 0.6     0.6     0.6         nan 0.6     0.6     0.6     0.6         nan\n",
      " 0.6     0.6     0.6     0.6         nan 0.59375 0.59375 0.59375 0.59375\n",
      "     nan 0.5875  0.5875  0.5875  0.5875      nan 0.5875  0.5875  0.5875\n",
      " 0.5875      nan 0.5875  0.5875  0.5875  0.5875      nan 0.59375 0.59375\n",
      " 0.59375 0.59375     nan 0.6     0.6     0.6     0.6         nan 0.6\n",
      " 0.6     0.6     0.6         nan 0.6     0.6     0.6     0.6         nan\n",
      " 0.5625  0.5625  0.5625  0.58125     nan 0.55    0.55    0.55    0.56875\n",
      "     nan 0.5625  0.5625  0.5625  0.58125     nan 0.5875  0.5875  0.5875\n",
      " 0.5875      nan 0.59375 0.59375 0.59375 0.59375     nan 0.6     0.6\n",
      " 0.6     0.6         nan 0.6     0.6     0.6     0.6         nan 0.6\n",
      " 0.6     0.6     0.6         nan 0.5625  0.5625  0.55625 0.575       nan\n",
      " 0.55    0.55    0.55    0.56875     nan 0.5625  0.5625  0.5625  0.58125\n",
      "     nan 0.5875  0.5875  0.5875  0.5875      nan 0.59375 0.59375 0.59375\n",
      " 0.59375     nan 0.6     0.6     0.6     0.6         nan 0.6     0.6\n",
      " 0.6     0.6         nan 0.6     0.6     0.6     0.6         nan 0.56875\n",
      " 0.56875 0.55625 0.575       nan 0.54375 0.54375 0.55    0.56875     nan\n",
      " 0.5625  0.5625  0.5625  0.58125     nan 0.5875  0.5875  0.5875  0.5875\n",
      "     nan 0.59375 0.59375 0.59375 0.59375     nan 0.6     0.6     0.6\n",
      " 0.6         nan 0.6     0.6     0.6     0.6         nan 0.6     0.6\n",
      " 0.6     0.6         nan 0.55    0.55625 0.54375 0.5625      nan 0.5375\n",
      " 0.5375  0.54375 0.5625      nan 0.55625 0.55625 0.55625 0.575       nan\n",
      " 0.5875  0.5875  0.5875  0.5875      nan 0.59375 0.59375 0.59375 0.59375\n",
      "     nan 0.6     0.6     0.6     0.6         nan 0.6     0.6     0.6\n",
      " 0.6         nan 0.6     0.6     0.6     0.6         nan 0.55    0.55625\n",
      " 0.54375 0.5625      nan 0.5375  0.5375  0.54375 0.5625      nan 0.55625\n",
      " 0.55625 0.55625 0.575       nan 0.5875  0.5875  0.5875  0.5875      nan\n",
      " 0.59375 0.59375 0.59375 0.59375     nan 0.6     0.6     0.6     0.6\n",
      "     nan 0.6     0.6     0.6     0.6         nan 0.6     0.6     0.6\n",
      " 0.6         nan 0.55    0.55625 0.54375 0.5625      nan 0.5375  0.5375\n",
      " 0.54375 0.5625      nan 0.55625 0.55625 0.55625 0.575       nan 0.5875\n",
      " 0.5875  0.5875  0.5875      nan 0.59375 0.59375 0.59375 0.59375     nan\n",
      " 0.6     0.6     0.6     0.6         nan 0.6     0.6     0.6     0.6\n",
      "     nan 0.6     0.6     0.6     0.6         nan 0.55    0.55625 0.54375\n",
      " 0.5625      nan 0.5375  0.5375  0.54375 0.5625      nan 0.55625 0.55625\n",
      " 0.55625 0.575       nan 0.5875  0.5875  0.5875  0.5875      nan 0.59375\n",
      " 0.59375 0.59375 0.59375     nan 0.6     0.6     0.6     0.6         nan\n",
      " 0.6     0.6     0.6     0.6         nan 0.6     0.6     0.6     0.6\n",
      "     nan 0.55    0.55625 0.54375 0.5625      nan 0.5375  0.5375  0.54375\n",
      " 0.5625      nan 0.55625 0.55625 0.55625 0.575       nan 0.5875  0.5875\n",
      " 0.5875  0.5875      nan 0.59375 0.59375 0.59375 0.59375     nan 0.6\n",
      " 0.6     0.6     0.6         nan 0.6     0.6     0.6     0.6         nan\n",
      " 0.6     0.6     0.6     0.6         nan 0.55    0.55625 0.54375 0.5625\n",
      "     nan 0.5375  0.5375  0.54375 0.5625      nan 0.55625 0.55625 0.55625\n",
      " 0.575       nan 0.5875  0.5875  0.5875  0.5875      nan 0.59375 0.59375\n",
      " 0.59375 0.59375     nan 0.6     0.6     0.6     0.6         nan 0.6\n",
      " 0.6     0.6     0.6         nan 0.6     0.6     0.6     0.6         nan\n",
      " 0.55    0.55625 0.54375 0.5625      nan 0.5375  0.5375  0.54375 0.5625\n",
      "     nan 0.55625 0.55625 0.55625 0.575       nan 0.5875  0.5875  0.5875\n",
      " 0.5875      nan 0.59375 0.59375 0.59375 0.59375     nan 0.6     0.6\n",
      " 0.6     0.6         nan 0.6     0.6     0.6     0.6         nan 0.6\n",
      " 0.6     0.6     0.6         nan 0.55    0.55625 0.54375 0.5625      nan\n",
      " 0.5375  0.5375  0.54375 0.5625      nan 0.55625 0.55625 0.55625 0.575\n",
      "     nan 0.5875  0.5875  0.5875  0.5875      nan 0.59375 0.59375 0.59375\n",
      " 0.59375     nan 0.6     0.6     0.6     0.6         nan 0.6     0.6\n",
      " 0.6     0.6         nan 0.6     0.6     0.6     0.6         nan 0.55\n",
      " 0.55625 0.54375 0.5625      nan 0.5375  0.5375  0.54375 0.5625      nan\n",
      " 0.55625 0.55625 0.55625 0.575       nan 0.5875  0.5875  0.5875  0.5875\n",
      "     nan 0.59375 0.59375 0.59375 0.59375     nan 0.6     0.6     0.6\n",
      " 0.6         nan 0.6     0.6     0.6     0.6         nan 0.6     0.6\n",
      " 0.6     0.6         nan 0.55    0.55625 0.54375 0.5625      nan 0.5375\n",
      " 0.5375  0.54375 0.5625      nan 0.55625 0.55625 0.55625 0.575       nan\n",
      " 0.5875  0.5875  0.5875  0.5875      nan 0.59375 0.59375 0.59375 0.59375\n",
      "     nan 0.6     0.6     0.6     0.6         nan 0.6     0.6     0.6\n",
      " 0.6         nan 0.6     0.6     0.6     0.6         nan 0.55    0.55625\n",
      " 0.54375 0.5625      nan 0.5375  0.5375  0.54375 0.5625      nan 0.55625\n",
      " 0.55625 0.55625 0.575       nan 0.5875  0.5875  0.5875  0.5875      nan\n",
      " 0.59375 0.59375 0.59375 0.59375     nan 0.6     0.6     0.6     0.6\n",
      "     nan 0.6     0.6     0.6     0.6         nan 0.6     0.6     0.6\n",
      " 0.6    ]\n",
      "  warnings.warn(\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training:  0.6\n",
      "27\n",
      "Fitting 5 folds for each of 640 candidates, totalling 3200 fits\n",
      "Accuracy on training:  0.3670886075949367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "640 fits failed out of a total of 3200.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "640 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/kushagra/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan 0.31583333 0.31583333 0.31583333 0.31583333        nan\n",
      " 0.31583333 0.31583333 0.31583333 0.31583333        nan 0.31583333\n",
      " 0.31583333 0.31583333 0.31583333        nan 0.31583333 0.31583333\n",
      " 0.31583333 0.31583333        nan 0.31583333 0.31583333 0.31583333\n",
      " 0.31583333        nan 0.31583333 0.31583333 0.31583333 0.31583333\n",
      "        nan 0.31583333 0.31583333 0.31583333 0.31583333        nan\n",
      " 0.31583333 0.31583333 0.31583333 0.31583333        nan 0.255\n",
      " 0.255      0.255      0.255             nan 0.18916667 0.18916667\n",
      " 0.18916667 0.18916667        nan 0.17666667 0.17666667 0.17666667\n",
      " 0.17666667        nan 0.15       0.15       0.15       0.15\n",
      "        nan 0.1625     0.1625     0.1625     0.1625            nan\n",
      " 0.1625     0.1625     0.1625     0.1625            nan 0.175\n",
      " 0.175      0.175      0.175             nan 0.175      0.175\n",
      " 0.175      0.175             nan 0.22833333 0.22833333 0.22833333\n",
      " 0.22833333        nan 0.26583333 0.26583333 0.26583333 0.26583333\n",
      "        nan 0.24083333 0.24083333 0.24083333 0.24083333        nan\n",
      " 0.25333333 0.25333333 0.25333333 0.25333333        nan 0.25333333\n",
      " 0.25333333 0.25333333 0.25333333        nan 0.2125     0.2125\n",
      " 0.2125     0.2125            nan 0.175      0.175      0.175\n",
      " 0.175             nan 0.175      0.175      0.175      0.175\n",
      "        nan 0.1875     0.1875     0.1875     0.1875            nan\n",
      " 0.22833333 0.22833333 0.21583333 0.21583333        nan 0.21583333\n",
      " 0.21583333 0.21583333 0.21583333        nan 0.26583333 0.26583333\n",
      " 0.26583333 0.26583333        nan 0.25333333 0.25333333 0.25333333\n",
      " 0.25333333        nan 0.2125     0.2125     0.2125     0.2125\n",
      "        nan 0.175      0.175      0.175      0.175             nan\n",
      " 0.175      0.175      0.175      0.175             nan 0.24083333\n",
      " 0.24083333 0.22833333 0.22833333        nan 0.24083333 0.24083333\n",
      " 0.21583333 0.21583333        nan 0.21583333 0.21583333 0.21583333\n",
      " 0.20333333        nan 0.26583333 0.26583333 0.26583333 0.26583333\n",
      "        nan 0.25333333 0.25333333 0.25333333 0.25333333        nan\n",
      " 0.2125     0.2125     0.2125     0.2125            nan 0.175\n",
      " 0.175      0.175      0.175             nan 0.175      0.175\n",
      " 0.175      0.175             nan 0.24083333 0.24083333 0.22833333\n",
      " 0.20333333        nan 0.25333333 0.25333333 0.22833333 0.21583333\n",
      "        nan 0.21583333 0.21583333 0.21583333 0.20333333        nan\n",
      " 0.26583333 0.26583333 0.26583333 0.26583333        nan 0.25333333\n",
      " 0.25333333 0.25333333 0.25333333        nan 0.2125     0.2125\n",
      " 0.2125     0.2125            nan 0.175      0.175      0.175\n",
      " 0.175             nan 0.175      0.175      0.175      0.175\n",
      "        nan 0.24083333 0.24083333 0.22833333 0.20333333        nan\n",
      " 0.25333333 0.25333333 0.22833333 0.21583333        nan 0.21583333\n",
      " 0.21583333 0.21583333 0.20333333        nan 0.26583333 0.26583333\n",
      " 0.26583333 0.26583333        nan 0.25333333 0.25333333 0.25333333\n",
      " 0.25333333        nan 0.2125     0.2125     0.2125     0.2125\n",
      "        nan 0.175      0.175      0.175      0.175             nan\n",
      " 0.175      0.175      0.175      0.175             nan 0.24083333\n",
      " 0.24083333 0.22833333 0.20333333        nan 0.25333333 0.25333333\n",
      " 0.22833333 0.21583333        nan 0.21583333 0.21583333 0.21583333\n",
      " 0.20333333        nan 0.26583333 0.26583333 0.26583333 0.26583333\n",
      "        nan 0.25333333 0.25333333 0.25333333 0.25333333        nan\n",
      " 0.2125     0.2125     0.2125     0.2125            nan 0.175\n",
      " 0.175      0.175      0.175             nan 0.175      0.175\n",
      " 0.175      0.175             nan 0.24083333 0.24083333 0.22833333\n",
      " 0.20333333        nan 0.25333333 0.25333333 0.22833333 0.21583333\n",
      "        nan 0.21583333 0.21583333 0.21583333 0.20333333        nan\n",
      " 0.26583333 0.26583333 0.26583333 0.26583333        nan 0.25333333\n",
      " 0.25333333 0.25333333 0.25333333        nan 0.2125     0.2125\n",
      " 0.2125     0.2125            nan 0.175      0.175      0.175\n",
      " 0.175             nan 0.175      0.175      0.175      0.175\n",
      "        nan 0.24083333 0.24083333 0.22833333 0.20333333        nan\n",
      " 0.25333333 0.25333333 0.22833333 0.21583333        nan 0.21583333\n",
      " 0.21583333 0.21583333 0.20333333        nan 0.26583333 0.26583333\n",
      " 0.26583333 0.26583333        nan 0.25333333 0.25333333 0.25333333\n",
      " 0.25333333        nan 0.2125     0.2125     0.2125     0.2125\n",
      "        nan 0.175      0.175      0.175      0.175             nan\n",
      " 0.175      0.175      0.175      0.175             nan 0.24083333\n",
      " 0.24083333 0.22833333 0.20333333        nan 0.25333333 0.25333333\n",
      " 0.22833333 0.21583333        nan 0.21583333 0.21583333 0.21583333\n",
      " 0.20333333        nan 0.26583333 0.26583333 0.26583333 0.26583333\n",
      "        nan 0.25333333 0.25333333 0.25333333 0.25333333        nan\n",
      " 0.2125     0.2125     0.2125     0.2125            nan 0.175\n",
      " 0.175      0.175      0.175             nan 0.175      0.175\n",
      " 0.175      0.175             nan 0.24083333 0.24083333 0.22833333\n",
      " 0.20333333        nan 0.25333333 0.25333333 0.22833333 0.21583333\n",
      "        nan 0.21583333 0.21583333 0.21583333 0.20333333        nan\n",
      " 0.26583333 0.26583333 0.26583333 0.26583333        nan 0.25333333\n",
      " 0.25333333 0.25333333 0.25333333        nan 0.2125     0.2125\n",
      " 0.2125     0.2125            nan 0.175      0.175      0.175\n",
      " 0.175             nan 0.175      0.175      0.175      0.175\n",
      "        nan 0.24083333 0.24083333 0.22833333 0.20333333        nan\n",
      " 0.25333333 0.25333333 0.22833333 0.21583333        nan 0.21583333\n",
      " 0.21583333 0.21583333 0.20333333        nan 0.26583333 0.26583333\n",
      " 0.26583333 0.26583333        nan 0.25333333 0.25333333 0.25333333\n",
      " 0.25333333        nan 0.2125     0.2125     0.2125     0.2125\n",
      "        nan 0.175      0.175      0.175      0.175             nan\n",
      " 0.175      0.175      0.175      0.175             nan 0.24083333\n",
      " 0.24083333 0.22833333 0.20333333        nan 0.25333333 0.25333333\n",
      " 0.22833333 0.21583333        nan 0.21583333 0.21583333 0.21583333\n",
      " 0.20333333        nan 0.26583333 0.26583333 0.26583333 0.26583333\n",
      "        nan 0.25333333 0.25333333 0.25333333 0.25333333        nan\n",
      " 0.2125     0.2125     0.2125     0.2125            nan 0.175\n",
      " 0.175      0.175      0.175             nan 0.175      0.175\n",
      " 0.175      0.175             nan 0.24083333 0.24083333 0.22833333\n",
      " 0.20333333        nan 0.25333333 0.25333333 0.22833333 0.21583333\n",
      "        nan 0.21583333 0.21583333 0.21583333 0.20333333        nan\n",
      " 0.26583333 0.26583333 0.26583333 0.26583333        nan 0.25333333\n",
      " 0.25333333 0.25333333 0.25333333        nan 0.2125     0.2125\n",
      " 0.2125     0.2125            nan 0.175      0.175      0.175\n",
      " 0.175             nan 0.175      0.175      0.175      0.175\n",
      "        nan 0.24083333 0.24083333 0.22833333 0.20333333        nan\n",
      " 0.25333333 0.25333333 0.22833333 0.21583333        nan 0.21583333\n",
      " 0.21583333 0.21583333 0.20333333        nan 0.26583333 0.26583333\n",
      " 0.26583333 0.26583333        nan 0.25333333 0.25333333 0.25333333\n",
      " 0.25333333        nan 0.2125     0.2125     0.2125     0.2125\n",
      "        nan 0.175      0.175      0.175      0.175             nan\n",
      " 0.175      0.175      0.175      0.175     ]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Implement DT\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "models_DT = []\n",
    "Y_Test_StateWise = []\n",
    "f1_DT = dict()\n",
    "\n",
    "# Grid Search\n",
    "for ind in range(len(state)):\n",
    "\tprint(ind)\n",
    "\tmodel = DecisionTreeClassifier(random_state=10,criterion='entropy')\n",
    "\tif(len(X_Train_StateWise[ind]) <= 15):\n",
    "\t\tmodel.fit(X_Train_StateWise[ind], Y_Train_StateWise[ind])\n",
    "\t\tmodels_DT.append(model)\n",
    "\t\tY_Test_StateWise.append(model.predict(X_Test_StateWise[ind]))\n",
    "\telse:\n",
    "\t\tmodel.fit(X_Train_StateWise[ind], Y_Train_StateWise[ind])\n",
    "\t\t# Create the parameter grid based on the results of random search\n",
    "\t\tmax_depth = []\n",
    "\t\tmax_features = []\n",
    "\t\tmin_samples_split = []\n",
    "\t\tmin_samples_leaf = []\n",
    "\t\tfor j in range(1, 40, 5):\n",
    "\t\t\tmax_depth.append(j)\n",
    "\t\tfor j in range(1,10):\n",
    "\t\t\tmin_samples_split.append(j)\n",
    "\t\tfor j in range(1,10):\n",
    "\t\t\tmin_samples_leaf.append(j)\n",
    "\t\n",
    "\t\tparameter_grid = {\n",
    "\t\t\t'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "\t\t\t'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "\t\t\t'max_depth': max_depth,\n",
    "\t\t}\n",
    "\t\tparams = dict()\n",
    "\t\tprint(i)\n",
    "\t\tfor p in max_depth:\n",
    "\t\t\tfor q in max_features:\n",
    "\t\t\t\tfor r in ['gini', 'entropy']:\n",
    "\t\t\t\t\tfor s in ['best', 'random']:\n",
    "\t\t\t\t\t\tmodel = DecisionTreeClassifier(max_depth=p, max_features=q, random_state=10, criterion=r, splitter=s)\n",
    "\t\t\t\t\t\tmodel.fit(X_Train_StateWise[i], Y_Train_StateWise[i])\n",
    "\t\t\t\t\t\ty = model.predict(X_Test_StateWise[i])\n",
    "\t\t\t\t\t\tscoring = calculate_accuracy(y, answer_statewise[i])[2]\n",
    "\t\t\t\t\t\tparams[(p, q, r, s)] = scoring\n",
    "\t\t\n",
    "\t\tmax_params = max(params, key=params.get)\n",
    "\t\tmodel = DecisionTreeClassifier(max_depth=max_params[0], max_features=max_params[1], splitter=s,criterion=r, random_state=10)\n",
    "\t\tmodel.fit(X_Train_StateWise[i], Y_Train_StateWise[i])\n",
    "\t\tmodels_DT.append(model)\n",
    "\t\tY_Test_StateWise.append(model.predict(X_Test_StateWise[i]))\n",
    "\tf1 = calculate_accuracy(Y_Test_StateWise[ind], answer_statewise[ind])[2]\n",
    "\t# f1_DT[i] = f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.50632911392405\n",
      "35.22727272727273\n",
      "33.75\n",
      "27.906976744186046\n",
      "23.728813559322035\n",
      "36.84210526315789\n",
      "20.454545454545457\n",
      "23.300970873786408\n",
      "20.0\n",
      "29.629629629629626\n",
      "27.77777777777778\n",
      "32.432432432432435\n",
      "35.483870967741936\n",
      "29.03225806451613\n",
      "28.57142857142857\n",
      "17.647058823529413\n",
      "24.418604651162788\n",
      "38.23529411764706\n",
      "45.0\n",
      "33.33333333333333\n",
      "21.91780821917808\n",
      "37.5\n",
      "23.333333333333332\n",
      "37.93103448275862\n",
      "53.333333333333336\n",
      "100.0\n",
      "33.33333333333333\n",
      "14.285714285714285\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "global_correct_count = 0\n",
    "for i in range(len(state)):\n",
    "    print(calculate_accuracy(Y_Test_StateWise[i],answer_statewise[i])[0])\n",
    "    global_correct_count += calculate_accuracy(Y_Test_StateWise[i],answer_statewise[i])[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  30.05822416302766\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: ', global_correct_count/len(answer) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.254062996725961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dq/bh64zxfx1nn4xlf98w20zj0h0000gn/T/ipykernel_45140/2357261873.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y_Final[i]['Education'] = Y_Test_StateWise[i]\n",
      "/var/folders/dq/bh64zxfx1nn4xlf98w20zj0h0000gn/T/ipykernel_45140/2357261873.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y_Final[i]['Education'] = Y_Test_StateWise[i]\n",
      "/var/folders/dq/bh64zxfx1nn4xlf98w20zj0h0000gn/T/ipykernel_45140/2357261873.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y_Final[i]['Education'] = Y_Test_StateWise[i]\n",
      "/var/folders/dq/bh64zxfx1nn4xlf98w20zj0h0000gn/T/ipykernel_45140/2357261873.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y_Final[i]['Education'] = Y_Test_StateWise[i]\n",
      "/var/folders/dq/bh64zxfx1nn4xlf98w20zj0h0000gn/T/ipykernel_45140/2357261873.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y_Final[i]['Education'] = Y_Test_StateWise[i]\n",
      "/var/folders/dq/bh64zxfx1nn4xlf98w20zj0h0000gn/T/ipykernel_45140/2357261873.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y_Final[i]['Education'] = Y_Test_StateWise[i]\n",
      "/var/folders/dq/bh64zxfx1nn4xlf98w20zj0h0000gn/T/ipykernel_45140/2357261873.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y_Final[i]['Education'] = Y_Test_StateWise[i]\n",
      "/var/folders/dq/bh64zxfx1nn4xlf98w20zj0h0000gn/T/ipykernel_45140/2357261873.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y_Final[i]['Education'] = Y_Test_StateWise[i]\n",
      "/var/folders/dq/bh64zxfx1nn4xlf98w20zj0h0000gn/T/ipykernel_45140/2357261873.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y_Final[i]['Education'] = Y_Test_StateWise[i]\n",
      "/var/folders/dq/bh64zxfx1nn4xlf98w20zj0h0000gn/T/ipykernel_45140/2357261873.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y_Final[i]['Education'] = Y_Test_StateWise[i]\n",
      "/var/folders/dq/bh64zxfx1nn4xlf98w20zj0h0000gn/T/ipykernel_45140/2357261873.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y_Final[i]['Education'] = Y_Test_StateWise[i]\n",
      "/var/folders/dq/bh64zxfx1nn4xlf98w20zj0h0000gn/T/ipykernel_45140/2357261873.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y_Final[i]['Education'] = Y_Test_StateWise[i]\n",
      "/var/folders/dq/bh64zxfx1nn4xlf98w20zj0h0000gn/T/ipykernel_45140/2357261873.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y_Final[i]['Education'] = Y_Test_StateWise[i]\n",
      "/var/folders/dq/bh64zxfx1nn4xlf98w20zj0h0000gn/T/ipykernel_45140/2357261873.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y_Final[i]['Education'] = Y_Test_StateWise[i]\n",
      "/var/folders/dq/bh64zxfx1nn4xlf98w20zj0h0000gn/T/ipykernel_45140/2357261873.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y_Final[i]['Education'] = Y_Test_StateWise[i]\n",
      "/var/folders/dq/bh64zxfx1nn4xlf98w20zj0h0000gn/T/ipykernel_45140/2357261873.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y_Final[i]['Education'] = Y_Test_StateWise[i]\n",
      "/var/folders/dq/bh64zxfx1nn4xlf98w20zj0h0000gn/T/ipykernel_45140/2357261873.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y_Final[i]['Education'] = Y_Test_StateWise[i]\n",
      "/var/folders/dq/bh64zxfx1nn4xlf98w20zj0h0000gn/T/ipykernel_45140/2357261873.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y_Final[i]['Education'] = Y_Test_StateWise[i]\n",
      "/var/folders/dq/bh64zxfx1nn4xlf98w20zj0h0000gn/T/ipykernel_45140/2357261873.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y_Final[i]['Education'] = Y_Test_StateWise[i]\n",
      "/var/folders/dq/bh64zxfx1nn4xlf98w20zj0h0000gn/T/ipykernel_45140/2357261873.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y_Final[i]['Education'] = Y_Test_StateWise[i]\n",
      "/var/folders/dq/bh64zxfx1nn4xlf98w20zj0h0000gn/T/ipykernel_45140/2357261873.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y_Final[i]['Education'] = Y_Test_StateWise[i]\n",
      "/var/folders/dq/bh64zxfx1nn4xlf98w20zj0h0000gn/T/ipykernel_45140/2357261873.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y_Final[i]['Education'] = Y_Test_StateWise[i]\n",
      "/var/folders/dq/bh64zxfx1nn4xlf98w20zj0h0000gn/T/ipykernel_45140/2357261873.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y_Final[i]['Education'] = Y_Test_StateWise[i]\n",
      "/var/folders/dq/bh64zxfx1nn4xlf98w20zj0h0000gn/T/ipykernel_45140/2357261873.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y_Final[i]['Education'] = Y_Test_StateWise[i]\n",
      "/var/folders/dq/bh64zxfx1nn4xlf98w20zj0h0000gn/T/ipykernel_45140/2357261873.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y_Final[i]['Education'] = Y_Test_StateWise[i]\n",
      "/var/folders/dq/bh64zxfx1nn4xlf98w20zj0h0000gn/T/ipykernel_45140/2357261873.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y_Final[i]['Education'] = Y_Test_StateWise[i]\n",
      "/var/folders/dq/bh64zxfx1nn4xlf98w20zj0h0000gn/T/ipykernel_45140/2357261873.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y_Final[i]['Education'] = Y_Test_StateWise[i]\n",
      "/var/folders/dq/bh64zxfx1nn4xlf98w20zj0h0000gn/T/ipykernel_45140/2357261873.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y_Final[i]['Education'] = Y_Test_StateWise[i]\n"
     ]
    }
   ],
   "source": [
    "Y_Final = []\n",
    "for i in range(len(state)):\n",
    "\tY_Final.append(X_Test[X_Test['state'] == i])\n",
    "\n",
    "\n",
    "for i in range(len(state)):\n",
    "\tY_Final[i]['Education'] = Y_Test_StateWise[i]\n",
    "\n",
    "reverse_education = {value: key for key, value in education.items()}\n",
    "\n",
    "answer_csv_to_write = []\n",
    "for i in range(len(state)):\n",
    "    for index, value in Y_Final[i]['Education'].items():\n",
    "        answer_csv_to_write.append([index,reverse_education[value]])\n",
    "answer_csv_to_write.sort()\n",
    "yrt = []\n",
    "for i in range(len(answer_csv_to_write)):\n",
    "    yrt.append(education[answer_csv_to_write[i][1]])\n",
    "f1 = f1_score(answer['Education'], yrt, average='weighted')\n",
    "print(f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.254062996725961\n"
     ]
    }
   ],
   "source": [
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('answer_knn_statewise.csv', 'w') as f:\n",
    "    f.write('ID,Education\\n')\n",
    "    for item in answer_csv_to_write:\n",
    "        f.write(f\"{item[0]},{item[1]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.3188918470641225,\n",
       " 1: 0.4244444444444445,\n",
       " 2: 0.337675978217023,\n",
       " 3: 0.3470607812955028,\n",
       " 4: 0.27217746854471037,\n",
       " 5: 0.42067751918313767,\n",
       " 6: 0.27611861822388134,\n",
       " 7: 0.3489472693256099,\n",
       " 8: 0.4104706046641531,\n",
       " 9: 0.5667254556143445,\n",
       " 10: 0.4583333333333333,\n",
       " 11: 0.3652197652197652,\n",
       " 12: 0.36754417060019773,\n",
       " 13: 0.4950146627565982,\n",
       " 14: 0.3558181697716582,\n",
       " 15: 0.504201680672269,\n",
       " 16: 0.30606060606060603,\n",
       " 17: 0.3589169000933707,\n",
       " 18: 0.6666666666666666,\n",
       " 19: 0.37749287749287747,\n",
       " 20: 0.293260495047273,\n",
       " 21: 0.5361111111111111,\n",
       " 22: 0.338235294117647,\n",
       " 23: 0.43103448275862066,\n",
       " 24: 0.4423529411764706,\n",
       " 25: 1.0,\n",
       " 26: 0.3929824561403508,\n",
       " 27: 0.4081632653061225}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.22539317222861524,\n",
       " 1: 0.27318640955004586,\n",
       " 2: 0.2426056338028169,\n",
       " 3: 0.37209302325581395,\n",
       " 4: 0.3864406779661017,\n",
       " 5: 0.3544575725026853,\n",
       " 6: 0.3451628585318425,\n",
       " 7: 0.2954230235783633,\n",
       " 8: 0.35052160953800293,\n",
       " 9: 0.21442495126705652,\n",
       " 10: 0.2857142857142857,\n",
       " 11: 0.31678189817724706,\n",
       " 12: 0.2139784946236559,\n",
       " 13: 0.15053763440860216,\n",
       " 14: 0.23729357062690395,\n",
       " 15: 0.35000000000000003,\n",
       " 16: 0.1662015503875969,\n",
       " 17: 0.08954248366013072,\n",
       " 18: 0.31428571428571417,\n",
       " 19: 0.10130718954248365,\n",
       " 20: 0.12002349117032464,\n",
       " 21: 0.47619047619047616,\n",
       " 22: 0.5,\n",
       " 23: 0.12903225806451613,\n",
       " 24: 0.27692307692307694,\n",
       " 25: 0.16666666666666666,\n",
       " 26: 0.3714285714285714,\n",
       " 27: 0.2285714285714286}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_KMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_final = []\n",
    "for i in range(len(state)):\n",
    "    if(f1_KNN[i] > f1_KMC[i]):\n",
    "        models_final.append(models_KNN[i])\n",
    "    else:\n",
    "        models_final.append(models_KMC[i])\n",
    "\n",
    "for i in range(len(state)):\n",
    "    Y_Test_StateWise[i] = models_final[i].predict(X_Test_StateWise[i])\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.37974683544304\n",
      "36.36363636363637\n",
      "31.25\n",
      "23.25581395348837\n",
      "24.576271186440678\n",
      "30.82706766917293\n",
      "22.727272727272727\n",
      "28.155339805825243\n",
      "36.36363636363637\n",
      "48.148148148148145\n",
      "33.33333333333333\n",
      "32.432432432432435\n",
      "35.483870967741936\n",
      "38.70967741935484\n",
      "31.746031746031743\n",
      "35.294117647058826\n",
      "24.418604651162788\n",
      "29.411764705882355\n",
      "50.0\n",
      "27.77777777777778\n",
      "24.65753424657534\n",
      "50.0\n",
      "33.33333333333333\n",
      "41.37931034482759\n",
      "40.0\n",
      "100.0\n",
      "26.666666666666668\n",
      "28.57142857142857\n",
      "Accuracy:  30.858806404657933\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "global_correct_count = 0\n",
    "for i in range(len(state)):\n",
    "    print(calculate_accuracy(Y_Test_StateWise[i],answer_statewise[i])[0])\n",
    "    global_correct_count += calculate_accuracy(Y_Test_StateWise[i],answer_statewise[i])[1]\n",
    "print('Accuracy: ', global_correct_count/len(answer) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dq/bh64zxfx1nn4xlf98w20zj0h0000gn/T/ipykernel_40717/2357261873.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y_Final[i]['Education'] = Y_Test_StateWise[i]\n",
      "/var/folders/dq/bh64zxfx1nn4xlf98w20zj0h0000gn/T/ipykernel_40717/2357261873.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y_Final[i]['Education'] = Y_Test_StateWise[i]\n",
      "/var/folders/dq/bh64zxfx1nn4xlf98w20zj0h0000gn/T/ipykernel_40717/2357261873.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y_Final[i]['Education'] = Y_Test_StateWise[i]\n",
      "/var/folders/dq/bh64zxfx1nn4xlf98w20zj0h0000gn/T/ipykernel_40717/2357261873.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y_Final[i]['Education'] = Y_Test_StateWise[i]\n",
      "/var/folders/dq/bh64zxfx1nn4xlf98w20zj0h0000gn/T/ipykernel_40717/2357261873.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y_Final[i]['Education'] = Y_Test_StateWise[i]\n",
      "/var/folders/dq/bh64zxfx1nn4xlf98w20zj0h0000gn/T/ipykernel_40717/2357261873.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y_Final[i]['Education'] = Y_Test_StateWise[i]\n",
      "/var/folders/dq/bh64zxfx1nn4xlf98w20zj0h0000gn/T/ipykernel_40717/2357261873.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y_Final[i]['Education'] = Y_Test_StateWise[i]\n",
      "/var/folders/dq/bh64zxfx1nn4xlf98w20zj0h0000gn/T/ipykernel_40717/2357261873.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y_Final[i]['Education'] = Y_Test_StateWise[i]\n",
      "/var/folders/dq/bh64zxfx1nn4xlf98w20zj0h0000gn/T/ipykernel_40717/2357261873.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y_Final[i]['Education'] = Y_Test_StateWise[i]\n",
      "/var/folders/dq/bh64zxfx1nn4xlf98w20zj0h0000gn/T/ipykernel_40717/2357261873.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y_Final[i]['Education'] = Y_Test_StateWise[i]\n",
      "/var/folders/dq/bh64zxfx1nn4xlf98w20zj0h0000gn/T/ipykernel_40717/2357261873.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y_Final[i]['Education'] = Y_Test_StateWise[i]\n",
      "/var/folders/dq/bh64zxfx1nn4xlf98w20zj0h0000gn/T/ipykernel_40717/2357261873.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y_Final[i]['Education'] = Y_Test_StateWise[i]\n",
      "/var/folders/dq/bh64zxfx1nn4xlf98w20zj0h0000gn/T/ipykernel_40717/2357261873.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y_Final[i]['Education'] = Y_Test_StateWise[i]\n",
      "/var/folders/dq/bh64zxfx1nn4xlf98w20zj0h0000gn/T/ipykernel_40717/2357261873.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y_Final[i]['Education'] = Y_Test_StateWise[i]\n",
      "/var/folders/dq/bh64zxfx1nn4xlf98w20zj0h0000gn/T/ipykernel_40717/2357261873.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y_Final[i]['Education'] = Y_Test_StateWise[i]\n",
      "/var/folders/dq/bh64zxfx1nn4xlf98w20zj0h0000gn/T/ipykernel_40717/2357261873.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y_Final[i]['Education'] = Y_Test_StateWise[i]\n",
      "/var/folders/dq/bh64zxfx1nn4xlf98w20zj0h0000gn/T/ipykernel_40717/2357261873.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y_Final[i]['Education'] = Y_Test_StateWise[i]\n",
      "/var/folders/dq/bh64zxfx1nn4xlf98w20zj0h0000gn/T/ipykernel_40717/2357261873.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y_Final[i]['Education'] = Y_Test_StateWise[i]\n",
      "/var/folders/dq/bh64zxfx1nn4xlf98w20zj0h0000gn/T/ipykernel_40717/2357261873.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y_Final[i]['Education'] = Y_Test_StateWise[i]\n",
      "/var/folders/dq/bh64zxfx1nn4xlf98w20zj0h0000gn/T/ipykernel_40717/2357261873.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y_Final[i]['Education'] = Y_Test_StateWise[i]\n",
      "/var/folders/dq/bh64zxfx1nn4xlf98w20zj0h0000gn/T/ipykernel_40717/2357261873.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y_Final[i]['Education'] = Y_Test_StateWise[i]\n",
      "/var/folders/dq/bh64zxfx1nn4xlf98w20zj0h0000gn/T/ipykernel_40717/2357261873.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y_Final[i]['Education'] = Y_Test_StateWise[i]\n",
      "/var/folders/dq/bh64zxfx1nn4xlf98w20zj0h0000gn/T/ipykernel_40717/2357261873.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y_Final[i]['Education'] = Y_Test_StateWise[i]\n",
      "/var/folders/dq/bh64zxfx1nn4xlf98w20zj0h0000gn/T/ipykernel_40717/2357261873.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y_Final[i]['Education'] = Y_Test_StateWise[i]\n",
      "/var/folders/dq/bh64zxfx1nn4xlf98w20zj0h0000gn/T/ipykernel_40717/2357261873.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y_Final[i]['Education'] = Y_Test_StateWise[i]\n",
      "/var/folders/dq/bh64zxfx1nn4xlf98w20zj0h0000gn/T/ipykernel_40717/2357261873.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y_Final[i]['Education'] = Y_Test_StateWise[i]\n",
      "/var/folders/dq/bh64zxfx1nn4xlf98w20zj0h0000gn/T/ipykernel_40717/2357261873.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y_Final[i]['Education'] = Y_Test_StateWise[i]\n",
      "/var/folders/dq/bh64zxfx1nn4xlf98w20zj0h0000gn/T/ipykernel_40717/2357261873.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y_Final[i]['Education'] = Y_Test_StateWise[i]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "13",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(state)):\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m index, value \u001b[38;5;129;01min\u001b[39;00m Y_Final[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEducation\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m---> 14\u001b[0m         answer_csv_to_write\u001b[38;5;241m.\u001b[39mappend([index,\u001b[43mreverse_education\u001b[49m\u001b[43m[\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m]\u001b[49m])\n\u001b[1;32m     15\u001b[0m answer_csv_to_write\u001b[38;5;241m.\u001b[39msort()\n\u001b[1;32m     16\u001b[0m yrt \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mKeyError\u001b[0m: 13"
     ]
    }
   ],
   "source": [
    "Y_Final = []\n",
    "for i in range(len(state)):\n",
    "\tY_Final.append(X_Test[X_Test['state'] == i])\n",
    "\n",
    "\n",
    "for i in range(len(state)):\n",
    "\tY_Final[i]['Education'] = Y_Test_StateWise[i]\n",
    "\n",
    "reverse_education = {value: key for key, value in education.items()}\n",
    "\n",
    "answer_csv_to_write = []\n",
    "for i in range(len(state)):\n",
    "    for index, value in Y_Final[i]['Education'].items():\n",
    "        answer_csv_to_write.append([index,reverse_education[value]])\n",
    "answer_csv_to_write.sort()\n",
    "yrt = []\n",
    "for i in range(len(answer_csv_to_write)):\n",
    "    yrt.append(education[answer_csv_to_write[i][1]])\n",
    "f1 = f1_score(answer['Education'], yrt, average='weighted')\n",
    "print(f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2285714285714286\n"
     ]
    }
   ],
   "source": [
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
